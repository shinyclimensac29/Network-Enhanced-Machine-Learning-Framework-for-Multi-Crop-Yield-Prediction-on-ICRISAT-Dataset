{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kY4UCS9G6Bs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXDMm42zG_ye"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2avLhkaWHAOE",
        "outputId": "2c2995ff-e6cb-4cb0-8298-316c5aab76dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicate (Dist Code, Year) rows: 0\n",
            "Key (Dist Code, Year) is unique.\n",
            "\n",
            "===== BASIC EDA =====\n",
            "Rows: 16146, Columns: 80\n",
            "Time range: 1966 - 2017\n",
            "Unique States: 20\n",
            "Unique Districts: 311\n",
            "Detected crops (count=29): ['BARLEY', 'CASTOR', 'CHICKPEA', 'COTTON', 'FINGER MILLET', 'FODDER', 'FRUITS', 'FRUITS AND VEGETABLES', 'GROUNDNUT', 'KHARIF SORGHUM', 'LINSEED', 'MAIZE', 'MINOR PULSES', 'OILSEEDS', 'ONION', 'PEARL MILLET', 'PIGEONPEA', 'POTATOES', 'RABI SORGHUM', 'RAPESEED AND MUSTARD']...\n",
            "\n",
            "Yield missingness (% of NaN):\n",
            "                         YieldColumn  MissingPct\n",
            "20        OILSEEDS YIELD (Kg per ha)   10.361699\n",
            "11    MINOR PULSES YIELD (Kg per ha)    8.794748\n",
            "15       SAFFLOWER YIELD (Kg per ha)    2.991453\n",
            "17         LINSEED YIELD (Kg per ha)    1.591726\n",
            "21       SUGARCANE YIELD (Kg per ha)    1.492630\n",
            "16          CASTOR YIELD (Kg per ha)    0.514059\n",
            "5     PEARL MILLET YIELD (Kg per ha)    0.334448\n",
            "13         SESAMUM YIELD (Kg per ha)    0.272513\n",
            "9         CHICKPEA YIELD (Kg per ha)    0.260126\n",
            "19        SOYABEAN YIELD (Kg per ha)    0.247739\n",
            "18       SUNFLOWER YIELD (Kg per ha)    0.247739\n",
            "2   KHARIF SORGHUM YIELD (Kg per ha)    0.247739\n",
            "3     RABI SORGHUM YIELD (Kg per ha)    0.247739\n",
            "4          SORGHUM YIELD (Kg per ha)    0.247739\n",
            "1            WHEAT YIELD (Kg per ha)    0.216772\n",
            "10       PIGEONPEA YIELD (Kg per ha)    0.210578\n",
            "6            MAIZE YIELD (Kg per ha)    0.173418\n",
            "0             RICE YIELD (Kg per ha)    0.136257\n",
            "7    FINGER MILLET YIELD (Kg per ha)    0.123870\n",
            "8           BARLEY YIELD (Kg per ha)    0.123870\n",
            "\n",
            "Summary for RICE yield:\n",
            "count    16124.000000\n",
            "mean      1488.954947\n",
            "std        955.255364\n",
            "min          0.000000\n",
            "25%        802.277500\n",
            "50%       1333.330000\n",
            "75%       2114.152500\n",
            "max       5653.830000\n",
            "Name: RICE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for WHEAT yield:\n",
            "count    16111.000000\n",
            "mean      1495.664207\n",
            "std       1080.183846\n",
            "min          0.000000\n",
            "25%        755.740000\n",
            "50%       1350.030000\n",
            "75%       2133.160000\n",
            "max       5541.520000\n",
            "Name: WHEAT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for MAIZE yield:\n",
            "count    16118.000000\n",
            "mean      1411.212242\n",
            "std       1191.278525\n",
            "min          0.000000\n",
            "25%        700.000000\n",
            "50%       1162.075000\n",
            "75%       1864.860000\n",
            "max      21428.570000\n",
            "Name: MAIZE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for GROUNDNUT yield:\n",
            "count    16136.000000\n",
            "mean       766.422954\n",
            "std        627.617769\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%        775.055000\n",
            "75%       1085.835000\n",
            "max       8500.000000\n",
            "Name: GROUNDNUT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for COTTON yield:\n",
            "count    16131.000000\n",
            "mean       124.761659\n",
            "std        207.742327\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%        202.425000\n",
            "max       5000.000000\n",
            "Name: COTTON YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for SUGARCANE yield:\n",
            "count    15905.000000\n",
            "mean      4568.356637\n",
            "std       3128.354591\n",
            "min          0.000000\n",
            "25%       2214.290000\n",
            "50%       4556.960000\n",
            "75%       6750.000000\n",
            "max      22062.300000\n",
            "Name: SUGARCANE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "===== CLEANING DATA =====\n",
            "Clipped BARLEY yield: old max=14441.86, new max=3759.66\n",
            "Clipped CASTOR yield: old max=4600.00, new max=2507.14\n",
            "Clipped CHICKPEA yield: old max=58363.64, new max=1761.37\n",
            "Clipped COTTON yield: old max=5000.00, new max=897.34\n",
            "Clipped FINGER MILLET yield: old max=9286.86, new max=2766.17\n",
            "Clipped GROUNDNUT yield: old max=8500.00, new max=2725.94\n",
            "Clipped KHARIF SORGHUM yield: old max=6531.25, new max=2384.25\n",
            "Clipped LINSEED yield: old max=7000.00, new max=1095.64\n",
            "Clipped MAIZE yield: old max=21428.57, new max=6111.05\n",
            "Clipped MINOR PULSES yield: old max=18888.89, new max=1918.01\n",
            "Clipped OILSEEDS yield: old max=25500.00, new max=2048.96\n",
            "Clipped PEARL MILLET yield: old max=10000.00, new max=2493.63\n",
            "Clipped PIGEONPEA yield: old max=12402.60, new max=2231.10\n",
            "Clipped RABI SORGHUM yield: old max=9578.95, new max=4467.59\n",
            "Clipped RAPESEED AND MUSTARD yield: old max=7000.00, new max=1830.51\n",
            "Clipped RICE yield: old max=5653.83, new max=4127.30\n",
            "Clipped SAFFLOWER yield: old max=4166.67, new max=1300.89\n",
            "Clipped SESAMUM yield: old max=4400.00, new max=1000.00\n",
            "Clipped SORGHUM yield: old max=5742.59, new max=2365.10\n",
            "Clipped SOYABEAN yield: old max=3884.06, new max=2136.81\n",
            "Clipped SUGARCANE yield: old max=22062.30, new max=12228.49\n",
            "Clipped SUNFLOWER yield: old max=4282.05, new max=2160.20\n",
            "Clipped WHEAT yield: old max=5541.52, new max=4550.54\n",
            "\n",
            "Top 15 crops by non-missing yield fraction:\n",
            "                    Crop  NonMissingFrac\n",
            "15                  RICE        0.930881\n",
            "17               SESAMUM        0.884615\n",
            "8                  MAIZE        0.883562\n",
            "9           MINOR PULSES        0.876874\n",
            "2               CHICKPEA        0.874086\n",
            "22                 WHEAT        0.855134\n",
            "20             SUGARCANE        0.839527\n",
            "12             PIGEONPEA        0.823486\n",
            "10              OILSEEDS        0.822247\n",
            "14  RAPESEED AND MUSTARD        0.766258\n",
            "5              GROUNDNUT        0.762418\n",
            "18               SORGHUM        0.731884\n",
            "6         KHARIF SORGHUM        0.713923\n",
            "11          PEARL MILLET        0.634584\n",
            "3                 COTTON        0.538647\n",
            "\n",
            "===== COMPUTING DIVERSIFICATION =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2696958754.py:242: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[share_col] = df[col].clip(lower=0) / denom\n",
            "/tmp/ipython-input-2696958754.py:242: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[share_col] = df[col].clip(lower=0) / denom\n",
            "/tmp/ipython-input-2696958754.py:242: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[share_col] = df[col].clip(lower=0) / denom\n",
            "/tmp/ipython-input-2696958754.py:242: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[share_col] = df[col].clip(lower=0) / denom\n",
            "/tmp/ipython-input-2696958754.py:242: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[share_col] = df[col].clip(lower=0) / denom\n",
            "/tmp/ipython-input-2696958754.py:242: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[share_col] = df[col].clip(lower=0) / denom\n",
            "/tmp/ipython-input-2696958754.py:242: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[share_col] = df[col].clip(lower=0) / denom\n",
            "/tmp/ipython-input-2696958754.py:242: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[share_col] = df[col].clip(lower=0) / denom\n",
            "/tmp/ipython-input-2696958754.py:242: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[share_col] = df[col].clip(lower=0) / denom\n",
            "/tmp/ipython-input-2696958754.py:246: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"HERFINDAHL\"] = (df[share_cols] ** 2).sum(axis=1)\n",
            "/tmp/ipython-input-2696958754.py:247: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[\"DIVERSIFICATION_INDEX\"] = 1.0 - df[\"HERFINDAHL\"]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== BUILDING DISTRICT SIMILARITY NETWORK =====\n",
            "Network reference window: 2008-2017\n",
            "District network: 311 nodes, 1555 edges\n",
            "\n",
            "===== BUILDING CROP-COOCCURRENCE NETWORK =====\n",
            "Crop network: 29 nodes, 406 edges\n",
            "\n",
            "Saved cleaned dataset with features to: /content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\n",
            "\n",
            "===== BUILDING SUPERVISED DATA FOR RICE =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2696958754.py:539: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved supervised panel for RICE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_rice.csv\n",
            "\n",
            "===== MODELING RICE =====\n",
            "RICE | Naive | Fold 1: MAE=324.00, RMSE=447.30, MAPE=39.32, R2=0.619\n",
            "RICE | Naive | Fold 2: MAE=294.57, RMSE=408.97, MAPE=28.50, R2=0.702\n",
            "RICE | Naive | Fold 3: MAE=261.94, RMSE=354.96, MAPE=22.04, R2=0.808\n",
            "RICE | Ridge | Fold 1: MAE=370.17, RMSE=471.12, MAPE=52.54, R2=0.577\n",
            "RICE | Ridge | Fold 2: MAE=267.07, RMSE=361.38, MAPE=30.33, R2=0.767\n",
            "RICE | Ridge | Fold 3: MAE=212.04, RMSE=294.96, MAPE=19.37, R2=0.867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=1.14513e-26): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=2.07077e-26): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=7.47876e-26): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RICE | RandomForest | Fold 1: MAE=282.05, RMSE=385.69, MAPE=38.03, R2=0.716\n",
            "RICE | RandomForest | Fold 2: MAE=271.64, RMSE=366.51, MAPE=29.67, R2=0.761\n",
            "RICE | RandomForest | Fold 3: MAE=223.67, RMSE=307.84, MAPE=18.87, R2=0.855\n",
            "RICE | GradientBoosting | Fold 1: MAE=301.92, RMSE=417.60, MAPE=40.64, R2=0.668\n",
            "RICE | GradientBoosting | Fold 2: MAE=272.60, RMSE=366.80, MAPE=30.79, R2=0.760\n",
            "RICE | GradientBoosting | Fold 3: MAE=239.30, RMSE=328.39, MAPE=21.45, R2=0.836\n",
            "\n",
            "Performance summary for RICE:\n",
            "   Crop             Model    MAE_mean    MAE_std   RMSE_mean   RMSE_std  \\\n",
            "2  RICE      RandomForest  259.119013  25.422581  353.346299  33.118859   \n",
            "3  RICE  GradientBoosting  271.270428  25.582548  370.930083  36.535532   \n",
            "1  RICE             Ridge  283.094724  65.545166  375.817681  72.636583   \n",
            "0  RICE             Naive  293.503114  25.349894  403.742642  37.879725   \n",
            "\n",
            "   MAPE_mean   MAPE_std   R2_mean    R2_std  \n",
            "2  28.854188   7.843378  0.777575  0.057970  \n",
            "3  30.961897   7.834813  0.754515  0.068672  \n",
            "1  34.079445  13.799063  0.737237  0.120442  \n",
            "0  29.949841   7.128250  0.709546  0.077405  \n",
            "\n",
            "===== BUILDING SUPERVISED DATA FOR WHEAT =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2696958754.py:539: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved supervised panel for WHEAT to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_wheat.csv\n",
            "\n",
            "===== MODELING WHEAT =====\n",
            "WHEAT | Naive | Fold 1: MAE=268.97, RMSE=381.76, MAPE=22.21, R2=0.650\n",
            "WHEAT | Naive | Fold 2: MAE=292.54, RMSE=399.37, MAPE=22.88, R2=0.721\n",
            "WHEAT | Naive | Fold 3: MAE=279.64, RMSE=388.98, MAPE=19.37, R2=0.766\n",
            "WHEAT | Ridge | Fold 1: MAE=292.82, RMSE=369.98, MAPE=30.20, R2=0.671\n",
            "WHEAT | Ridge | Fold 2: MAE=321.89, RMSE=406.16, MAPE=32.00, R2=0.711\n",
            "WHEAT | Ridge | Fold 3: MAE=232.77, RMSE=320.71, MAPE=17.62, R2=0.841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=2.27837e-26): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=4.65562e-26): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=1.5671e-25): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WHEAT | RandomForest | Fold 1: MAE=248.23, RMSE=338.69, MAPE=22.49, R2=0.725\n",
            "WHEAT | RandomForest | Fold 2: MAE=272.35, RMSE=364.28, MAPE=24.00, R2=0.768\n",
            "WHEAT | RandomForest | Fold 3: MAE=227.50, RMSE=319.95, MAPE=16.76, R2=0.842\n",
            "WHEAT | GradientBoosting | Fold 1: MAE=240.11, RMSE=329.11, MAPE=21.90, R2=0.740\n",
            "WHEAT | GradientBoosting | Fold 2: MAE=273.18, RMSE=361.37, MAPE=23.74, R2=0.771\n",
            "WHEAT | GradientBoosting | Fold 3: MAE=244.13, RMSE=336.17, MAPE=18.10, R2=0.826\n",
            "\n",
            "Performance summary for WHEAT:\n",
            "    Crop             Model    MAE_mean    MAE_std   RMSE_mean   RMSE_std  \\\n",
            "2  WHEAT      RandomForest  249.358384  18.330216  340.973053  18.169002   \n",
            "3  WHEAT  GradientBoosting  252.474913  14.734440  342.213594  13.846132   \n",
            "0  WHEAT             Naive  280.384168   9.637490  390.038367   7.228805   \n",
            "1  WHEAT             Ridge  282.492933  37.107591  365.618249  35.022188   \n",
            "\n",
            "   MAPE_mean  MAPE_std   R2_mean    R2_std  \n",
            "2  21.081392  3.120834  0.778165  0.048438  \n",
            "3  21.245790  2.345691  0.779042  0.035317  \n",
            "0  21.484869  1.521501  0.712531  0.047814  \n",
            "1  26.607601  6.398883  0.741351  0.072483  \n",
            "\n",
            "===== BUILDING SUPERVISED DATA FOR MAIZE =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2696958754.py:539: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved supervised panel for MAIZE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_maize.csv\n",
            "\n",
            "===== MODELING MAIZE =====\n",
            "MAIZE | Naive | Fold 1: MAE=393.83, RMSE=613.08, MAPE=34.57, R2=0.501\n",
            "MAIZE | Naive | Fold 2: MAE=460.17, RMSE=696.80, MAPE=45.01, R2=-0.134\n",
            "MAIZE | Naive | Fold 3: MAE=437.57, RMSE=636.15, MAPE=33.71, R2=0.252\n",
            "MAIZE | Ridge | Fold 1: MAE=360.27, RMSE=570.65, MAPE=34.77, R2=0.568\n",
            "MAIZE | Ridge | Fold 2: MAE=565.99, RMSE=721.72, MAPE=67.58, R2=-0.217\n",
            "MAIZE | Ridge | Fold 3: MAE=386.88, RMSE=549.15, MAPE=28.28, R2=0.443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=9.11728e-29): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=6.44929e-27): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=3.15249e-26): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAIZE | RandomForest | Fold 1: MAE=385.90, RMSE=613.45, MAPE=34.34, R2=0.500\n",
            "MAIZE | RandomForest | Fold 2: MAE=455.49, RMSE=654.05, MAPE=49.48, R2=0.001\n",
            "MAIZE | RandomForest | Fold 3: MAE=378.39, RMSE=543.47, MAPE=29.82, R2=0.454\n",
            "MAIZE | GradientBoosting | Fold 1: MAE=376.22, RMSE=602.87, MAPE=33.45, R2=0.518\n",
            "MAIZE | GradientBoosting | Fold 2: MAE=464.94, RMSE=652.28, MAPE=51.73, R2=0.006\n",
            "MAIZE | GradientBoosting | Fold 3: MAE=387.51, RMSE=558.36, MAPE=30.27, R2=0.424\n",
            "\n",
            "Performance summary for MAIZE:\n",
            "    Crop             Model    MAE_mean    MAE_std   RMSE_mean   RMSE_std  \\\n",
            "2  MAIZE      RandomForest  406.591066  34.710027  603.655000  45.669331   \n",
            "3  MAIZE  GradientBoosting  409.554875  39.431504  604.503715  38.359581   \n",
            "0  MAIZE             Naive  430.522837  27.539048  648.675672  35.307942   \n",
            "1  MAIZE             Ridge  437.715420  91.354043  613.840112  76.789026   \n",
            "\n",
            "   MAPE_mean   MAPE_std   R2_mean    R2_std  \n",
            "2  37.880649   8.410516  0.318400  0.225536  \n",
            "3  38.483908   9.457380  0.315783  0.222395  \n",
            "0  37.761783   5.136261  0.206277  0.261435  \n",
            "1  43.539117  17.201800  0.264490  0.344249  \n",
            "\n",
            "===== BUILDING SUPERVISED DATA FOR GROUNDNUT =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2696958754.py:539: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved supervised panel for GROUNDNUT to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_groundnut.csv\n",
            "\n",
            "===== MODELING GROUNDNUT =====\n",
            "GROUNDNUT | Naive | Fold 1: MAE=298.68, RMSE=417.78, MAPE=40.12, R2=-0.164\n",
            "GROUNDNUT | Naive | Fold 2: MAE=282.66, RMSE=397.54, MAPE=36.04, R2=-0.042\n",
            "GROUNDNUT | Naive | Fold 3: MAE=285.48, RMSE=391.44, MAPE=33.06, R2=-0.102\n",
            "GROUNDNUT | Ridge | Fold 1: MAE=253.10, RMSE=337.99, MAPE=32.08, R2=0.238\n",
            "GROUNDNUT | Ridge | Fold 2: MAE=264.00, RMSE=349.18, MAPE=36.10, R2=0.196\n",
            "GROUNDNUT | Ridge | Fold 3: MAE=232.15, RMSE=308.51, MAPE=29.12, R2=0.316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=4.77509e-27): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=4.01424e-26): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=8.01271e-26): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GROUNDNUT | RandomForest | Fold 1: MAE=253.40, RMSE=348.81, MAPE=32.44, R2=0.189\n",
            "GROUNDNUT | RandomForest | Fold 2: MAE=269.88, RMSE=353.21, MAPE=34.99, R2=0.178\n",
            "GROUNDNUT | RandomForest | Fold 3: MAE=246.20, RMSE=324.73, MAPE=30.82, R2=0.242\n",
            "GROUNDNUT | GradientBoosting | Fold 1: MAE=259.69, RMSE=360.37, MAPE=32.18, R2=0.134\n",
            "GROUNDNUT | GradientBoosting | Fold 2: MAE=274.72, RMSE=359.33, MAPE=37.52, R2=0.149\n",
            "GROUNDNUT | GradientBoosting | Fold 3: MAE=245.76, RMSE=330.53, MAPE=31.92, R2=0.214\n",
            "\n",
            "Performance summary for GROUNDNUT:\n",
            "        Crop             Model    MAE_mean    MAE_std   RMSE_mean   RMSE_std  \\\n",
            "1  GROUNDNUT             Ridge  249.746595  13.216991  331.892627  17.156525   \n",
            "2  GROUNDNUT      RandomForest  256.494067   9.910354  342.250030  12.517754   \n",
            "3  GROUNDNUT  GradientBoosting  260.055738  11.828703  350.078800  13.826110   \n",
            "0  GROUNDNUT             Naive  288.938569   6.981009  402.252971  11.255066   \n",
            "\n",
            "   MAPE_mean  MAPE_std   R2_mean    R2_std  \n",
            "1  32.429968  2.860932  0.250038  0.049487  \n",
            "2  32.752161  1.717154  0.202680  0.028039  \n",
            "3  33.872645  2.579613  0.165757  0.034962  \n",
            "0  36.406125  2.891585 -0.102475  0.049804  \n",
            "\n",
            "===== BUILDING SUPERVISED DATA FOR COTTON =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2696958754.py:539: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved supervised panel for COTTON to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_cotton.csv\n",
            "\n",
            "===== MODELING COTTON =====\n",
            "COTTON | Naive | Fold 1: MAE=53.53, RMSE=105.40, MAPE=27.61, R2=0.377\n",
            "COTTON | Naive | Fold 2: MAE=94.68, RMSE=153.75, MAPE=40.42, R2=-0.018\n",
            "COTTON | Naive | Fold 3: MAE=95.51, RMSE=153.52, MAPE=38.00, R2=-0.054\n",
            "COTTON | Ridge | Fold 1: MAE=51.54, RMSE=88.21, MAPE=24.61, R2=0.564\n",
            "COTTON | Ridge | Fold 2: MAE=85.49, RMSE=131.69, MAPE=32.08, R2=0.253\n",
            "COTTON | Ridge | Fold 3: MAE=75.36, RMSE=110.96, MAPE=24.19, R2=0.449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=8.47465e-32): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=4.91502e-27): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=1.92234e-26): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COTTON | RandomForest | Fold 1: MAE=52.70, RMSE=96.63, MAPE=24.54, R2=0.476\n",
            "COTTON | RandomForest | Fold 2: MAE=86.45, RMSE=135.30, MAPE=33.36, R2=0.211\n",
            "COTTON | RandomForest | Fold 3: MAE=73.51, RMSE=114.34, MAPE=24.60, R2=0.415\n",
            "COTTON | GradientBoosting | Fold 1: MAE=55.39, RMSE=99.40, MAPE=26.54, R2=0.446\n",
            "COTTON | GradientBoosting | Fold 2: MAE=87.69, RMSE=138.42, MAPE=34.47, R2=0.175\n",
            "COTTON | GradientBoosting | Fold 3: MAE=75.93, RMSE=119.23, MAPE=25.17, R2=0.364\n",
            "\n",
            "Performance summary for COTTON:\n",
            "     Crop             Model   MAE_mean    MAE_std   RMSE_mean   RMSE_std  \\\n",
            "1  COTTON             Ridge  70.797446  14.231711  110.286841  17.758815   \n",
            "2  COTTON      RandomForest  70.888036  13.905589  115.423294  15.804578   \n",
            "3  COTTON  GradientBoosting  73.003030  13.346880  119.018462  15.930482   \n",
            "0  COTTON             Naive  81.238336  19.597172  137.557850  22.737742   \n",
            "\n",
            "   MAPE_mean  MAPE_std   R2_mean    R2_std  \n",
            "1  26.960121  3.625313  0.421916  0.128314  \n",
            "2  27.498192  4.146366  0.367627  0.113240  \n",
            "3  28.729545  4.098026  0.328161  0.113601  \n",
            "0  35.342800  5.559236  0.101438  0.195273  \n",
            "\n",
            "===== BUILDING SUPERVISED DATA FOR SUGARCANE =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2696958754.py:539: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved supervised panel for SUGARCANE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_sugarcane.csv\n",
            "\n",
            "===== MODELING SUGARCANE =====\n",
            "SUGARCANE | Naive | Fold 1: MAE=991.85, RMSE=1428.87, MAPE=25.42, R2=0.712\n",
            "SUGARCANE | Naive | Fold 2: MAE=958.69, RMSE=1437.96, MAPE=25.06, R2=0.710\n",
            "SUGARCANE | Naive | Fold 3: MAE=937.47, RMSE=1436.10, MAPE=25.00, R2=0.690\n",
            "SUGARCANE | Ridge | Fold 1: MAE=941.71, RMSE=1329.05, MAPE=25.50, R2=0.751\n",
            "SUGARCANE | Ridge | Fold 2: MAE=890.85, RMSE=1256.90, MAPE=29.87, R2=0.779\n",
            "SUGARCANE | Ridge | Fold 3: MAE=822.24, RMSE=1191.91, MAPE=30.83, R2=0.786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=2.86218e-27): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=1.94711e-26): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=7.79147e-26): result may not be accurate.\n",
            "  return f(*arrays, *other_args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SUGARCANE | RandomForest | Fold 1: MAE=888.80, RMSE=1261.09, MAPE=24.84, R2=0.776\n",
            "SUGARCANE | RandomForest | Fold 2: MAE=880.86, RMSE=1273.30, MAPE=25.71, R2=0.773\n",
            "SUGARCANE | RandomForest | Fold 3: MAE=813.81, RMSE=1187.51, MAPE=26.16, R2=0.788\n",
            "SUGARCANE | GradientBoosting | Fold 1: MAE=943.62, RMSE=1331.84, MAPE=24.91, R2=0.750\n",
            "SUGARCANE | GradientBoosting | Fold 2: MAE=860.54, RMSE=1254.25, MAPE=25.18, R2=0.779\n",
            "SUGARCANE | GradientBoosting | Fold 3: MAE=817.84, RMSE=1175.57, MAPE=25.99, R2=0.792\n",
            "\n",
            "Performance summary for SUGARCANE:\n",
            "        Crop             Model    MAE_mean    MAE_std    RMSE_mean   RMSE_std  \\\n",
            "2  SUGARCANE      RandomForest  861.156849  33.637094  1240.635356  37.895316   \n",
            "3  SUGARCANE  GradientBoosting  874.000138  52.224834  1253.885854  63.800912   \n",
            "1  SUGARCANE             Ridge  884.932768  48.953727  1259.285276  56.016105   \n",
            "0  SUGARCANE             Naive  962.668924  22.377003  1434.307049   3.920844   \n",
            "\n",
            "   MAPE_mean  MAPE_std   R2_mean    R2_std  \n",
            "2  25.569770  0.544227  0.778828  0.006613  \n",
            "3  25.362884  0.456592  0.773870  0.017744  \n",
            "1  28.734286  2.319024  0.771970  0.015221  \n",
            "0  25.159166  0.183604  0.704075  0.010006  \n",
            "\n",
            "Saved model performance summary to: /content/drive/MyDrive/Shiny/ICRISAT/Results/model_performance_summary.csv\n",
            "\n",
            "===== DIAGNOSTIC PLOTS FOR RICE (RandomForest) =====\n",
            "\n",
            "===== FINAL SUMMARY =====\n",
            "Rows after cleaning: 16146\n",
            "Years: 1966 - 2017\n",
            "Number of districts: 311\n",
            "Crops modeled: ['RICE', 'WHEAT', 'MAIZE', 'GROUNDNUT', 'COTTON', 'SUGARCANE']\n",
            "Best model per crop (by MAE_mean):\n",
            "  RICE: RandomForest\n",
            "  WHEAT: RandomForest\n",
            "  MAIZE: RandomForest\n",
            "  GROUNDNUT: Ridge\n",
            "  COTTON: Ridge\n",
            "  SUGARCANE: RandomForest\n",
            "Cleaned dataset with features: /content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\n",
            "Model performance summary: /content/drive/MyDrive/Shiny/ICRISAT/Results/model_performance_summary.csv\n",
            "Supervised panel CSV prefix: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_\n",
            "Key PDF plots saved in OUTPUT_DIR (yield trends, distributions, network overview, diagnostics).\n"
          ]
        }
      ],
      "source": [
        "# SINGLE-CELL END-TO-END PIPELINE FOR ICRISAT-STYLE DATASET\n",
        "# ----------------------------------------------------------\n",
        "# This cell implements:\n",
        "# - Loading and basic EDA\n",
        "# - Cleaning and outlier handling\n",
        "# - Crop share and diversification computation\n",
        "# - District-level similarity network + metrics\n",
        "# - Crop-crop co-occurrence network + metrics\n",
        "# - Supervised ML dataset construction for selected crops\n",
        "# - STL-based leakage-free temporal features\n",
        "# - Time-aware expanding-window CV\n",
        "# - Model training and evaluation (Naive, Ridge, RF, GB)\n",
        "# - Plots and saving outputs\n",
        "# ----------------------------------------------------------\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "from statsmodels.tsa.seasonal import STL\n",
        "\n",
        "# Global configuration\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Path to data (adjust as needed in Colab)\n",
        "DATA_PATH = \"/content/drive/MyDrive/Shiny/ICRISAT/ICRISAT-District Level Data.csv\"\n",
        "\n",
        "# Output paths\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Shiny/ICRISAT/Results\"\n",
        "\n",
        "# Ensure output directory exists\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "CLEANED_DATA_PATH = os.path.join(OUTPUT_DIR, \"icrisat_cleaned_with_features.csv\")\n",
        "MODEL_PERF_PATH = os.path.join(OUTPUT_DIR, \"model_performance_summary.csv\")\n",
        "SUP_DATA_PREFIX = os.path.join(OUTPUT_DIR, \"supervised_panel_\")  # crop name will be appended\n",
        "\n",
        "# Target crops to attempt modeling (if present)\n",
        "TARGET_CROPS = [\"RICE\", \"WHEAT\", \"MAIZE\", \"GROUNDNUT\", \"COTTON\", \"SUGARCANE\"]\n",
        "\n",
        "# -------------------------\n",
        "# Helper functions\n",
        "# -------------------------\n",
        "\n",
        "def load_data(path):\n",
        "    \"\"\"Load dataset and perform initial type conversions.\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Data file not found at: {path}\")\n",
        "    df = pd.read_csv(path)\n",
        "    # Convert -1 to NaN in numeric columns\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    df[num_cols] = df[num_cols].replace(-1, np.nan)\n",
        "    # Ensure Year is integer\n",
        "    if \"Year\" in df.columns:\n",
        "        df[\"Year\"] = df[\"Year\"].astype(int)\n",
        "    else:\n",
        "        raise KeyError(\"Column 'Year' not found in dataset.\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def detect_crop_columns(df):\n",
        "    \"\"\"Detect area, production, yield columns and derive crop names.\"\"\"\n",
        "    area_cols = [c for c in df.columns if c.endswith(\"AREA (1000 ha)\")]\n",
        "    prod_cols = [c for c in df.columns if c.endswith(\"PRODUCTION (1000 tons)\")]\n",
        "    yield_cols = [c for c in df.columns if c.endswith(\"YIELD (Kg per ha)\")]\n",
        "    crops = set()\n",
        "    for col in area_cols + prod_cols + yield_cols:\n",
        "        if \" AREA (1000 ha)\" in col:\n",
        "            crop = col.replace(\" AREA (1000 ha)\", \"\").strip()\n",
        "        elif \" PRODUCTION (1000 tons)\" in col:\n",
        "            crop = col.replace(\" PRODUCTION (1000 tons)\", \"\").strip()\n",
        "        elif \" YIELD (Kg per ha)\" in col:\n",
        "            crop = col.replace(\" YIELD (Kg per ha)\", \"\").strip()\n",
        "        else:\n",
        "            continue\n",
        "        crops.add(crop)\n",
        "    crops = sorted(list(crops))\n",
        "    return crops, area_cols, prod_cols, yield_cols\n",
        "\n",
        "\n",
        "def verify_keys(df):\n",
        "    \"\"\"Verify uniqueness of (Dist Code, Year).\"\"\"\n",
        "    if \"Dist Code\" not in df.columns:\n",
        "        raise KeyError(\"Column 'Dist Code' not found in dataset.\")\n",
        "    dup_mask = df.duplicated(subset=[\"Dist Code\", \"Year\"])\n",
        "    num_dups = dup_mask.sum()\n",
        "    print(f\"Duplicate (Dist Code, Year) rows: {num_dups}\")\n",
        "    if num_dups == 0:\n",
        "        print(\"Key (Dist Code, Year) is unique.\")\n",
        "    else:\n",
        "        print(\"WARNING: (Dist Code, Year) is not unique; duplicates exist.\")\n",
        "\n",
        "\n",
        "def basic_eda(df, crops, yield_cols):\n",
        "    \"\"\"Basic exploratory statistics and plots.\"\"\"\n",
        "    print(\"\\n===== BASIC EDA =====\")\n",
        "    print(f\"Rows: {len(df)}, Columns: {len(df.columns)}\")\n",
        "    print(f\"Time range: {df['Year'].min()} - {df['Year'].max()}\")\n",
        "    print(f\"Unique States: {df['State Name'].nunique() if 'State Name' in df.columns else 'N/A'}\")\n",
        "    print(f\"Unique Districts: {df['Dist Name'].nunique() if 'Dist Name' in df.columns else 'N/A'}\")\n",
        "    print(f\"Detected crops (count={len(crops)}): {crops[:20]}{'...' if len(crops) > 20 else ''}\")\n",
        "\n",
        "    # Missingness summary for yields\n",
        "    print(\"\\nYield missingness (% of NaN):\")\n",
        "    miss_data = []\n",
        "    for yc in yield_cols:\n",
        "        miss_pct = df[yc].isna().mean() * 100\n",
        "        miss_data.append((yc, miss_pct))\n",
        "    miss_df = pd.DataFrame(miss_data, columns=[\"YieldColumn\", \"MissingPct\"]).sort_values(\"MissingPct\", ascending=False)\n",
        "    print(miss_df.head(20))\n",
        "\n",
        "    # Summary stats for some key crops if present\n",
        "    def summarize_crop(crop):\n",
        "        y_col = f\"{crop} YIELD (Kg per ha)\"\n",
        "        if y_col in df.columns:\n",
        "            print(f\"\\nSummary for {crop} yield:\")\n",
        "            print(df[y_col].describe())\n",
        "\n",
        "    for crop in [\"RICE\", \"WHEAT\", \"MAIZE\", \"GROUNDNUT\", \"COTTON\", \"SUGARCANE\"]:\n",
        "        summarize_crop(crop)\n",
        "\n",
        "    # Plots: average yields over years for RICE and WHEAT (if available)\n",
        "    try:\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plotted = False\n",
        "        for crop, color in [(\"RICE\", \"tab:blue\"), (\"WHEAT\", \"tab:orange\")]:\n",
        "            y_col = f\"{crop} YIELD (Kg per ha)\"\n",
        "            if y_col in df.columns:\n",
        "                avg_y = df.groupby(\"Year\")[y_col].mean()\n",
        "                plt.plot(avg_y.index, avg_y.values, label=crop, alpha=0.8)\n",
        "                plotted = True\n",
        "        if plotted:\n",
        "            plt.xlabel(\"Year\")\n",
        "            plt.ylabel(\"Average Yield (kg/ha)\")\n",
        "            plt.title(\"Average Yield Over Time (National)\")\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(OUTPUT_DIR, \"avg_yield_rice_wheat_over_time.pdf\"), bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to create/save avg yield plot: {e}\")\n",
        "\n",
        "    # Histogram/KDE for one major crop\n",
        "    for crop in [\"RICE\", \"WHEAT\", \"MAIZE\"]:\n",
        "        y_col = f\"{crop} YIELD (Kg per ha)\"\n",
        "        if y_col in df.columns:\n",
        "            try:\n",
        "                plt.figure(figsize=(7, 4))\n",
        "                sns.histplot(df[y_col].dropna(), kde=True, bins=40)\n",
        "                plt.xlabel(f\"{crop} Yield (kg/ha)\")\n",
        "                plt.title(f\"Distribution of {crop} Yield\")\n",
        "                plt.tight_layout()\n",
        "                fname = f\"{crop.lower()}_yield_distribution.pdf\"\n",
        "                plt.savefig(os.path.join(OUTPUT_DIR, fname), bbox_inches=\"tight\")\n",
        "                plt.close()\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to create/save distribution plot for {crop}: {e}\")\n",
        "            break\n",
        "\n",
        "\n",
        "def clean_data(df, crops, area_cols, prod_cols, yield_cols):\n",
        "    \"\"\"Clean data: handle invalid yields, clip outliers, basic quality report.\"\"\"\n",
        "    print(\"\\n===== CLEANING DATA =====\")\n",
        "\n",
        "    # Map crop -> col names\n",
        "    crop_cols = {}\n",
        "    for crop in crops:\n",
        "        area_col = f\"{crop} AREA (1000 ha)\"\n",
        "        prod_col = f\"{crop} PRODUCTION (1000 tons)\"\n",
        "        yield_col = f\"{crop} YIELD (Kg per ha)\"\n",
        "        crop_cols[crop] = {\n",
        "            \"area\": area_col if area_col in df.columns else None,\n",
        "            \"prod\": prod_col if prod_col in df.columns else None,\n",
        "            \"yield\": yield_col if yield_col in df.columns else None,\n",
        "        }\n",
        "\n",
        "    # Invalidate yields and production when area <= 0\n",
        "    for crop, cols in crop_cols.items():\n",
        "        a, p, y = cols[\"area\"], cols[\"prod\"], cols[\"yield\"]\n",
        "        if a is None:\n",
        "            continue\n",
        "        area_series = df[a]\n",
        "        invalid_mask = area_series <= 0\n",
        "        if y is not None:\n",
        "            df.loc[invalid_mask, y] = np.nan\n",
        "        if p is not None:\n",
        "            df.loc[invalid_mask, p] = np.nan\n",
        "\n",
        "    # Clip yield outliers\n",
        "    for crop, cols in crop_cols.items():\n",
        "        y = cols[\"yield\"]\n",
        "        if y is None or y not in df.columns:\n",
        "            continue\n",
        "        series = df[y]\n",
        "        if series.notna().sum() < 50:\n",
        "            continue  # too few values for robust percentiles\n",
        "        p1, p99 = np.nanpercentile(series, [1, 99])\n",
        "        old_max = series.max()\n",
        "        df[y] = np.clip(series, p1, p99)\n",
        "        new_max = df[y].max()\n",
        "        print(f\"Clipped {crop} yield: old max={old_max:.2f}, new max={new_max:.2f}\")\n",
        "\n",
        "    # Data quality: non-missing fraction per crop yield\n",
        "    quality = []\n",
        "    for crop, cols in crop_cols.items():\n",
        "        y = cols[\"yield\"]\n",
        "        if y is not None and y in df.columns:\n",
        "            frac = df[y].notna().mean()\n",
        "            quality.append((crop, frac))\n",
        "    qdf = pd.DataFrame(quality, columns=[\"Crop\", \"NonMissingFrac\"]).sort_values(\"NonMissingFrac\", ascending=False)\n",
        "    print(\"\\nTop 15 crops by non-missing yield fraction:\")\n",
        "    print(qdf.head(15))\n",
        "    return df, crop_cols\n",
        "\n",
        "\n",
        "def compute_diversification(df, area_cols):\n",
        "    \"\"\"Compute total area, area shares, Herfindahl and diversification index.\"\"\"\n",
        "    print(\"\\n===== COMPUTING DIVERSIFICATION =====\")\n",
        "    if not area_cols:\n",
        "        raise ValueError(\"No area columns detected; cannot compute diversification.\")\n",
        "\n",
        "    # Total cropped area\n",
        "    df[\"TOTAL_AREA_1000_HA\"] = df[area_cols].clip(lower=0).sum(axis=1, min_count=1)\n",
        "\n",
        "    # Area shares\n",
        "    share_cols = []\n",
        "    for col in area_cols:\n",
        "        share_col = col.replace(\" AREA (1000 ha)\", \" AREA_SHARE\")\n",
        "        share_cols.append(share_col)\n",
        "        denom = df[\"TOTAL_AREA_1000_HA\"].replace(0, np.nan)\n",
        "        df[share_col] = df[col].clip(lower=0) / denom\n",
        "        df[share_col] = df[share_col].fillna(0.0)\n",
        "\n",
        "    # Herfindahl and diversification index\n",
        "    df[\"HERFINDAHL\"] = (df[share_cols] ** 2).sum(axis=1)\n",
        "    df[\"DIVERSIFICATION_INDEX\"] = 1.0 - df[\"HERFINDAHL\"]\n",
        "\n",
        "    # Plot diversification over time for a few states if available\n",
        "    if \"State Name\" in df.columns:\n",
        "        try:\n",
        "            top_states = df[\"State Name\"].value_counts().index[:3]\n",
        "            plt.figure(figsize=(8, 5))\n",
        "            for st in top_states:\n",
        "                sub = df[df[\"State Name\"] == st].groupby(\"Year\")[\"DIVERSIFICATION_INDEX\"].mean()\n",
        "                plt.plot(sub.index, sub.values, label=st)\n",
        "            plt.xlabel(\"Year\")\n",
        "            plt.ylabel(\"Diversification Index (1 - Herfindahl)\")\n",
        "            plt.title(\"Average Diversification by State\")\n",
        "            plt.legend()\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(os.path.join(OUTPUT_DIR, \"diversification_by_state.pdf\"), bbox_inches=\"tight\")\n",
        "            plt.close()\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to create/save diversification plot: {e}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def build_district_network(df, area_cols, k_neighbors=5):\n",
        "    \"\"\"Build district-level similarity network based on crop-share vectors.\"\"\"\n",
        "    print(\"\\n===== BUILDING DISTRICT SIMILARITY NETWORK =====\")\n",
        "    if not area_cols:\n",
        "        raise ValueError(\"No area columns; cannot build district network.\")\n",
        "\n",
        "    # Identify share columns\n",
        "    share_cols = [c for c in df.columns if c.endswith(\"AREA_SHARE\")]\n",
        "    if not share_cols:\n",
        "        raise ValueError(\"No share columns found; ensure compute_diversification was run.\")\n",
        "\n",
        "    # Reference window: last 10 years (or less if data shorter)\n",
        "    max_year = df[\"Year\"].max()\n",
        "    min_year = df[\"Year\"].min()\n",
        "    window = 10\n",
        "    start_win = max(min_year, max_year - window + 1)\n",
        "    df_win = df[(df[\"Year\"] >= start_win) & (df[\"Year\"] <= max_year)].copy()\n",
        "    print(f\"Network reference window: {start_win}-{max_year}\")\n",
        "\n",
        "    # Compute mean crop shares per district over window\n",
        "    group_cols = [\"Dist Code\"]\n",
        "    share_means = df_win.groupby(group_cols)[share_cols + [\"TOTAL_AREA_1000_HA\"]].mean()\n",
        "    share_means = share_means.rename(columns={\"TOTAL_AREA_1000_HA\": \"MEAN_TOTAL_AREA_1000_HA\"})\n",
        "    share_means = share_means[share_means[\"MEAN_TOTAL_AREA_1000_HA\"] > 0]\n",
        "    if share_means.empty:\n",
        "        raise ValueError(\"No districts with positive total area in reference window.\")\n",
        "\n",
        "    dist_codes = share_means.index.to_list()\n",
        "    X = share_means[share_cols].values\n",
        "    cos_sim = cosine_similarity(X)\n",
        "\n",
        "    # Build k-NN graph\n",
        "    G = nx.Graph()\n",
        "    # Add nodes with attributes\n",
        "    meta_cols = [\"Dist Name\", \"State Name\"]\n",
        "    meta_df = df.drop_duplicates(subset=[\"Dist Code\"])[[\"Dist Code\"] + [c for c in meta_cols if c in df.columns]].set_index(\"Dist Code\")\n",
        "    for dc in dist_codes:\n",
        "        attrs = {}\n",
        "        if dc in meta_df.index:\n",
        "            for c in meta_cols:\n",
        "                if c in meta_df.columns:\n",
        "                    attrs[c] = meta_df.loc[dc, c]\n",
        "        G.add_node(dc, **attrs)\n",
        "\n",
        "    # Add edges based on top-k cosine similarity\n",
        "    n = len(dist_codes)\n",
        "    for i in range(n):\n",
        "        sims = cos_sim[i]\n",
        "        idx_sorted = np.argsort(-sims)\n",
        "        added = 0\n",
        "        for j in idx_sorted:\n",
        "            if i == j:\n",
        "                continue\n",
        "            if sims[j] <= 0:\n",
        "                continue\n",
        "            u = dist_codes[i]\n",
        "            v = dist_codes[j]\n",
        "            w = float(sims[j])\n",
        "            if G.has_edge(u, v):\n",
        "                continue\n",
        "            G.add_edge(u, v, weight=w)\n",
        "            added += 1\n",
        "            if added >= k_neighbors:\n",
        "                break\n",
        "\n",
        "    print(f\"District network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "\n",
        "    # Network metrics\n",
        "    strength = dict(G.degree(weight=\"weight\"))\n",
        "    betw = nx.betweenness_centrality(G, normalized=True, weight=None)\n",
        "    try:\n",
        "        eig = nx.eigenvector_centrality_numpy(G, weight=\"weight\")\n",
        "    except Exception as e:\n",
        "        print(f\"Eigenvector centrality failed ({e}); using degree as fallback.\")\n",
        "        eig = {n: strength.get(n, 0.0) for n in G.nodes()}\n",
        "    clust = nx.clustering(G, weight=\"weight\")\n",
        "\n",
        "    metrics_df = pd.DataFrame({\n",
        "        \"Dist Code\": list(G.nodes()),\n",
        "        \"NET_STRENGTH\": [strength.get(n, 0.0) for n in G.nodes()],\n",
        "        \"NET_BETWEENNESS\": [betw.get(n, 0.0) for n in G.nodes()],\n",
        "        \"NET_EIGENVECTOR\": [eig.get(n, 0.0) for n in G.nodes()],\n",
        "        \"NET_CLUSTERING\": [clust.get(n, 0.0) for n in G.nodes()],\n",
        "    })\n",
        "\n",
        "    # Merge back to main df\n",
        "    df = df.merge(metrics_df, on=\"Dist Code\", how=\"left\")\n",
        "\n",
        "    # Simple network visualization\n",
        "    try:\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        pos = nx.spring_layout(G, seed=RANDOM_STATE)\n",
        "        node_sizes = np.array([strength.get(n, 0.0) for n in G.nodes()])\n",
        "        node_sizes = 100 + 400 * (node_sizes - node_sizes.min()) / (node_sizes.max() - node_sizes.min() + 1e-6)\n",
        "        nx.draw_networkx_nodes(G, pos, node_size=node_sizes, alpha=0.7)\n",
        "        nx.draw_networkx_edges(G, pos, alpha=0.3)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\"District Similarity Network (Strength-scaled Nodes)\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(OUTPUT_DIR, \"district_network_overview.pdf\"), bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Network plot failed: {e}\")\n",
        "\n",
        "    return df, G, share_means, share_cols\n",
        "\n",
        "\n",
        "def build_crop_network(share_means, share_cols):\n",
        "    \"\"\"Build crop-crop co-occurrence network from district-level mean shares.\"\"\"\n",
        "    print(\"\\n===== BUILDING CROP-COOCCURRENCE NETWORK =====\")\n",
        "    if share_means is None or share_means.empty:\n",
        "        print(\"No share means provided; skipping crop network.\")\n",
        "        return None, None\n",
        "\n",
        "    # Presence matrix: district x crop\n",
        "    share_array = share_means[share_cols].values\n",
        "    presence = (share_array > 0).astype(int)\n",
        "    if presence.size == 0:\n",
        "        print(\"No non-zero shares; skipping crop network.\")\n",
        "        return None, None\n",
        "\n",
        "    # Co-occurrence matrix\n",
        "    coocc = presence.T @ presence  # crops x crops\n",
        "    crop_names = [c.replace(\" AREA_SHARE\", \"\").strip() for c in share_cols]\n",
        "\n",
        "    Gc = nx.Graph()\n",
        "    for i, ci in enumerate(crop_names):\n",
        "        Gc.add_node(ci)\n",
        "    n_crops = len(crop_names)\n",
        "    for i in range(n_crops):\n",
        "        for j in range(i + 1, n_crops):\n",
        "            w = int(coocc[i, j])\n",
        "            if w > 0:\n",
        "                Gc.add_edge(crop_names[i], crop_names[j], weight=float(w))\n",
        "\n",
        "    print(f\"Crop network: {Gc.number_of_nodes()} nodes, {Gc.number_of_edges()} edges\")\n",
        "\n",
        "    # Metrics\n",
        "    degree = dict(Gc.degree(weight=\"weight\"))\n",
        "    try:\n",
        "        eig = nx.eigenvector_centrality_numpy(Gc, weight=\"weight\")\n",
        "    except Exception as e:\n",
        "        print(f\"Crop eigenvector centrality failed ({e}); using degree as fallback.\")\n",
        "        eig = {n: degree.get(n, 0.0) for n in Gc.nodes()}\n",
        "\n",
        "    crop_metrics = pd.DataFrame({\n",
        "        \"Crop\": list(Gc.nodes()),\n",
        "        \"CROP_DEGREE\": [degree.get(n, 0.0) for n in Gc.nodes()],\n",
        "        \"CROP_EIGENVECTOR\": [eig.get(n, 0.0) for n in Gc.nodes()],\n",
        "    }).set_index(\"Crop\")\n",
        "\n",
        "    return Gc, crop_metrics\n",
        "\n",
        "\n",
        "def add_stl_features_to_group(group, target_col, min_len=5):\n",
        "    \"\"\"Add STL-based trend and residual features to a district-crop group.\"\"\"\n",
        "    group = group.sort_values(\"Year\").copy()\n",
        "    y = group[target_col].values\n",
        "    trend = np.zeros_like(y, dtype=float)\n",
        "    resid = np.zeros_like(y, dtype=float)\n",
        "\n",
        "    for i in range(len(y)):\n",
        "        series = y[:i+1]\n",
        "        if np.isnan(series).all():\n",
        "            trend[i] = np.nan\n",
        "            resid[i] = np.nan\n",
        "            continue\n",
        "        valid_idx = ~np.isnan(series)\n",
        "        series_valid = series[valid_idx]\n",
        "        if len(series_valid) < min_len:\n",
        "            trend[i] = series_valid[-1]\n",
        "            resid[i] = 0.0\n",
        "        else:\n",
        "            period = min(10, max(2, len(series_valid) // 2))\n",
        "            try:\n",
        "                stl = STL(series_valid, period=period, robust=True)\n",
        "                res = stl.fit()\n",
        "                trend[i] = res.trend[-1]\n",
        "                resid[i] = res.resid[-1]\n",
        "            except Exception:\n",
        "                trend[i] = series_valid[-1]\n",
        "                resid[i] = 0.0\n",
        "\n",
        "    group[\"STL_TREND\"] = trend\n",
        "    group[\"STL_RESID\"] = resid\n",
        "    return group\n",
        "\n",
        "\n",
        "def construct_supervised_dataset_for_crop(df, crop, crop_cols, crop_metrics=None):\n",
        "    \"\"\"Construct supervised dataset for yield prediction for a given crop.\"\"\"\n",
        "    print(f\"\\n===== BUILDING SUPERVISED DATA FOR {crop} =====\")\n",
        "\n",
        "    cols = crop_cols.get(crop, {})\n",
        "    area_col = cols.get(\"area\")\n",
        "    prod_col = cols.get(\"prod\")\n",
        "    yield_col = cols.get(\"yield\")\n",
        "\n",
        "    if yield_col is None or yield_col not in df.columns:\n",
        "        print(f\"Yield column for {crop} not found; skipping.\")\n",
        "        return None\n",
        "\n",
        "    # Basic columns\n",
        "    base_cols = [\"Dist Code\", \"Year\"]\n",
        "    if \"State Name\" in df.columns:\n",
        "        base_cols.append(\"State Name\")\n",
        "    if \"Dist Name\" in df.columns:\n",
        "        base_cols.append(\"Dist Name\")\n",
        "\n",
        "    feat_cols = []\n",
        "    for c in [\"TOTAL_AREA_1000_HA\", \"DIVERSIFICATION_INDEX\",\n",
        "              \"NET_STRENGTH\", \"NET_BETWEENNESS\", \"NET_EIGENVECTOR\", \"NET_CLUSTERING\"]:\n",
        "        if c in df.columns:\n",
        "            feat_cols.append(c)\n",
        "\n",
        "    use_cols = base_cols.copy()\n",
        "    if area_col is not None and area_col in df.columns:\n",
        "        use_cols.append(area_col)\n",
        "    if prod_col is not None and prod_col in df.columns:\n",
        "        use_cols.append(prod_col)\n",
        "    use_cols.append(yield_col)\n",
        "    use_cols += feat_cols\n",
        "\n",
        "    use_cols = list(dict.fromkeys(use_cols))\n",
        "\n",
        "    sub = df[use_cols].copy()\n",
        "    sub = sub[sub[yield_col].notna()]\n",
        "    if sub.empty:\n",
        "        print(f\"No non-missing yield data for {crop}; skipping.\")\n",
        "        return None\n",
        "\n",
        "    # Add crop-level metrics (constant per crop)\n",
        "    if crop_metrics is not None and crop in crop_metrics.index:\n",
        "        sub[\"CROP_DEGREE\"] = crop_metrics.loc[crop, \"CROP_DEGREE\"]\n",
        "        sub[\"CROP_EIGENVECTOR\"] = crop_metrics.loc[crop, \"CROP_EIGENVECTOR\"]\n",
        "\n",
        "    # Group by district and construct temporal features\n",
        "    def process_group(g):\n",
        "        g = g.sort_values(\"Year\").copy()\n",
        "        # Lag features for yield\n",
        "        g[f\"{crop}_Y_LAG1\"] = g[yield_col].shift(1)\n",
        "        g[f\"{crop}_Y_LAG2\"] = g[yield_col].shift(2)\n",
        "\n",
        "        # Lag features for area & production if present\n",
        "        if area_col is not None and area_col in g.columns:\n",
        "            g[f\"{crop}_A_LAG1\"] = g[area_col].shift(1)\n",
        "        if prod_col is not None and prod_col in g.columns:\n",
        "            g[f\"{crop}_P_LAG1\"] = g[prod_col].shift(1)\n",
        "\n",
        "        # Rolling statistics (using only past values)\n",
        "        g[f\"{crop}_Y_ROLL_MEAN3\"] = g[yield_col].shift(1).rolling(window=3, min_periods=1).mean()\n",
        "        g[f\"{crop}_Y_ROLL_STD3\"] = g[yield_col].shift(1).rolling(window=3, min_periods=2).std()\n",
        "        g[f\"{crop}_Y_ROLL_CV3\"] = g[f\"{crop}_Y_ROLL_STD3\"] / (g[f\"{crop}_Y_ROLL_MEAN3\"].abs() + 1e-6)\n",
        "\n",
        "        # Time index features\n",
        "        year0 = g[\"Year\"].min()\n",
        "        g[\"YEAR_CENTERED\"] = g[\"Year\"] - year0\n",
        "        g[\"YEAR_CENTERED2\"] = g[\"YEAR_CENTERED\"] ** 2\n",
        "\n",
        "        # STL-based features\n",
        "        g = add_stl_features_to_group(g, yield_col)\n",
        "\n",
        "        # Target: next-year yield\n",
        "        g[\"TARGET_YIELD_NEXT\"] = g[yield_col].shift(-1)\n",
        "\n",
        "        # Drop last year (where target is NaN)\n",
        "        g = g[g[\"TARGET_YIELD_NEXT\"].notna()]\n",
        "\n",
        "        return g\n",
        "\n",
        "    sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n",
        "    if sup.empty:\n",
        "        print(f\"Supervised dataset for {crop} is empty after processing; skipping.\")\n",
        "        return None\n",
        "\n",
        "    # Drop rows with missing predictors or target\n",
        "    sup_clean = sup.dropna()\n",
        "    if sup_clean.empty:\n",
        "        print(f\"Supervised dataset for {crop} has no fully non-missing rows; skipping.\")\n",
        "        return None\n",
        "\n",
        "    # Save supervised panel\n",
        "    out_path = f\"{SUP_DATA_PREFIX}{crop.lower()}.csv\"\n",
        "    sup_clean.to_csv(out_path, index=False)\n",
        "    print(f\"Saved supervised panel for {crop} to: {out_path}\")\n",
        "\n",
        "    return sup_clean, yield_col\n",
        "\n",
        "\n",
        "def expanding_time_splits(years, n_splits=3, min_train_years=10, test_window_years=5):\n",
        "    \"\"\"Generate expanding-window time-series splits based on years.\"\"\"\n",
        "    unique_years = np.sort(np.unique(years))\n",
        "    if len(unique_years) < min_train_years + 2:\n",
        "        return []\n",
        "\n",
        "    min_year = unique_years[0]\n",
        "    max_year = unique_years[-1]\n",
        "    splits = []\n",
        "    for i in range(n_splits):\n",
        "        train_end = min_year + min_train_years - 1 + i * test_window_years\n",
        "        test_start = train_end + 1\n",
        "        test_end = test_start + test_window_years - 1\n",
        "        if test_start >= max_year:\n",
        "            break\n",
        "        train_end = min(train_end, max_year - 1)\n",
        "        test_end = min(test_end, max_year)\n",
        "        train_mask = (years <= train_end)\n",
        "        test_mask = (years >= test_start) & (years <= test_end)\n",
        "        train_idx = np.where(train_mask)[0]\n",
        "        test_idx = np.where(test_mask)[0]\n",
        "        if len(train_idx) == 0 or len(test_idx) == 0:\n",
        "            continue\n",
        "        splits.append((train_idx, test_idx))\n",
        "    return splits\n",
        "\n",
        "\n",
        "def compute_metrics(y_true, y_pred, mape_threshold=100.0):\n",
        "    \"\"\"Compute MAE, RMSE, MAPE (modified), R2.\"\"\"\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mask = np.abs(y_true) > mape_threshold\n",
        "    if mask.sum() > 0:\n",
        "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100.0\n",
        "    else:\n",
        "        mape = np.nan\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return mae, rmse, mape, r2\n",
        "\n",
        "\n",
        "def evaluate_models_for_crop(sup_df, crop, yield_col):\n",
        "    \"\"\"Evaluate baseline and ML models for a given crop with time-aware CV.\"\"\"\n",
        "    print(f\"\\n===== MODELING {crop} =====\")\n",
        "    exclude_cols = [\"Dist Code\", \"Year\", \"TARGET_YIELD_NEXT\"]\n",
        "    id_cols = [c for c in [\"State Name\", \"Dist Name\"] if c in sup_df.columns]\n",
        "    exclude_cols += id_cols\n",
        "    feature_cols = [c for c in sup_df.columns if c not in exclude_cols]\n",
        "    feature_cols = [c for c in feature_cols if not c.endswith(yield_col)]\n",
        "\n",
        "    X = sup_df[feature_cols].values.astype(float)\n",
        "    y = sup_df[\"TARGET_YIELD_NEXT\"].values.astype(float)\n",
        "    years = sup_df[\"Year\"].values.astype(int)\n",
        "\n",
        "    splits = expanding_time_splits(years, n_splits=3, min_train_years=10, test_window_years=5)\n",
        "    if not splits:\n",
        "        print(f\"Not enough temporal range to create CV folds for {crop}; skipping modeling.\")\n",
        "        return None\n",
        "\n",
        "    models = {\n",
        "        \"Naive\": None,\n",
        "        \"Ridge\": Pipeline([\n",
        "            (\"scaler\", RobustScaler()),\n",
        "            (\"model\", Ridge(alpha=1.0, random_state=RANDOM_STATE))\n",
        "        ]),\n",
        "        \"RandomForest\": Pipeline([\n",
        "            (\"scaler\", RobustScaler()),\n",
        "            (\"model\", RandomForestRegressor(\n",
        "                n_estimators=200,\n",
        "                max_depth=7,\n",
        "                random_state=RANDOM_STATE,\n",
        "                n_jobs=-1\n",
        "            ))\n",
        "        ]),\n",
        "        \"GradientBoosting\": Pipeline([\n",
        "            (\"scaler\", RobustScaler()),\n",
        "            (\"model\", GradientBoostingRegressor(\n",
        "                n_estimators=300,\n",
        "                learning_rate=0.05,\n",
        "                max_depth=3,\n",
        "                random_state=RANDOM_STATE\n",
        "            ))\n",
        "        ])\n",
        "    }\n",
        "\n",
        "    perf_records = []\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        fold_mae, fold_rmse, fold_mape, fold_r2 = [], [], [], []\n",
        "        for fold_id, (train_idx, test_idx) in enumerate(splits):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            if model_name == \"Naive\":\n",
        "                lag1_name = f\"{crop}_Y_LAG1\"\n",
        "                if lag1_name in feature_cols:\n",
        "                    lag1_idx = feature_cols.index(lag1_name)\n",
        "                    y_pred = X_test[:, lag1_idx]\n",
        "                    mean_train_y = np.nanmean(y_train)\n",
        "                    y_pred = np.where(np.isnan(y_pred), mean_train_y, y_pred)\n",
        "                else:\n",
        "                    y_pred = np.repeat(np.mean(y_train), len(y_test))\n",
        "            else:\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred = model.predict(X_test)\n",
        "\n",
        "            mae, rmse, mape, r2 = compute_metrics(y_test, y_pred)\n",
        "            fold_mae.append(mae)\n",
        "            fold_rmse.append(rmse)\n",
        "            fold_mape.append(mape)\n",
        "            fold_r2.append(r2)\n",
        "\n",
        "            print(f\"{crop} | {model_name} | Fold {fold_id+1}: MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.2f}, R2={r2:.3f}\")\n",
        "\n",
        "        perf_records.append({\n",
        "            \"Crop\": crop,\n",
        "            \"Model\": model_name,\n",
        "            \"MAE_mean\": np.nanmean(fold_mae),\n",
        "            \"MAE_std\": np.nanstd(fold_mae),\n",
        "            \"RMSE_mean\": np.nanmean(fold_rmse),\n",
        "            \"RMSE_std\": np.nanstd(fold_rmse),\n",
        "            \"MAPE_mean\": np.nanmean(fold_mape),\n",
        "            \"MAPE_std\": np.nanstd(fold_mape),\n",
        "            \"R2_mean\": np.nanmean(fold_r2),\n",
        "            \"R2_std\": np.nanstd(fold_r2),\n",
        "        })\n",
        "\n",
        "    perf_df = pd.DataFrame(perf_records)\n",
        "    print(f\"\\nPerformance summary for {crop}:\")\n",
        "    print(perf_df.sort_values([\"MAE_mean\"]))\n",
        "\n",
        "    return perf_df\n",
        "\n",
        "\n",
        "def diagnostic_plots_for_crop(sup_df, crop, yield_col, best_model_name):\n",
        "    \"\"\"Create diagnostic plots (true vs pred and time-series) for a selected crop.\"\"\"\n",
        "    print(f\"\\n===== DIAGNOSTIC PLOTS FOR {crop} ({best_model_name}) =====\")\n",
        "\n",
        "    exclude_cols = [\"Dist Code\", \"Year\", \"TARGET_YIELD_NEXT\"]\n",
        "    id_cols = [c for c in [\"State Name\", \"Dist Name\"] if c in sup_df.columns]\n",
        "    exclude_cols += id_cols\n",
        "    feature_cols = [c for c in sup_df.columns if c not in exclude_cols]\n",
        "    feature_cols = [c for c in feature_cols if not c.endswith(yield_col)]\n",
        "\n",
        "    X = sup_df[feature_cols].values.astype(float)\n",
        "    y = sup_df[\"TARGET_YIELD_NEXT\"].values.astype(float)\n",
        "    years = sup_df[\"Year\"].values.astype(int)\n",
        "\n",
        "    splits = expanding_time_splits(years, n_splits=3, min_train_years=10, test_window_years=5)\n",
        "    if not splits:\n",
        "        print(\"Not enough data for diagnostic plots.\")\n",
        "        return\n",
        "\n",
        "    models = {\n",
        "        \"Ridge\": Pipeline([\n",
        "            (\"scaler\", RobustScaler()),\n",
        "            (\"model\", Ridge(alpha=1.0, random_state=RANDOM_STATE))\n",
        "        ]),\n",
        "        \"RandomForest\": Pipeline([\n",
        "            (\"scaler\", RobustScaler()),\n",
        "            (\"model\", RandomForestRegressor(\n",
        "                n_estimators=200,\n",
        "                max_depth=7,\n",
        "                random_state=RANDOM_STATE,\n",
        "                n_jobs=-1\n",
        "            ))\n",
        "        ]),\n",
        "        \"GradientBoosting\": Pipeline([\n",
        "            (\"scaler\", RobustScaler()),\n",
        "            (\"model\", GradientBoostingRegressor(\n",
        "                n_estimators=300,\n",
        "                learning_rate=0.05,\n",
        "                max_depth=3,\n",
        "                random_state=RANDOM_STATE\n",
        "            ))\n",
        "        ])\n",
        "    }\n",
        "    if best_model_name not in models:\n",
        "        print(f\"Best model {best_model_name} not in available models for diagnostics.\")\n",
        "        return\n",
        "\n",
        "    model = models[best_model_name]\n",
        "\n",
        "    train_idx, test_idx = splits[-1]\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # True vs predicted scatter\n",
        "    try:\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "        lims = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]\n",
        "        plt.plot(lims, lims, \"r--\")\n",
        "        plt.xlabel(\"True Yield (kg/ha)\")\n",
        "        plt.ylabel(\"Predicted Yield (kg/ha)\")\n",
        "        plt.title(f\"{crop}: True vs Predicted ({best_model_name})\")\n",
        "        plt.tight_layout()\n",
        "        fname_scatter = os.path.join(OUTPUT_DIR, f\"{crop.lower()}_yield_true_vs_pred.pdf\")\n",
        "        plt.savefig(fname_scatter, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to create/save true-vs-pred plot for {crop}: {e}\")\n",
        "\n",
        "    # Time-series plot for a few example districts\n",
        "    try:\n",
        "        sup_df = sup_df.reset_index(drop=True)\n",
        "        sup_df[\"PRED_TEMP\"] = np.nan\n",
        "        sup_df.loc[test_idx, \"PRED_TEMP\"] = y_pred\n",
        "\n",
        "        if \"Dist Code\" not in sup_df.columns:\n",
        "            return\n",
        "        test_districts = sup_df.loc[test_idx, \"Dist Code\"].dropna().unique()\n",
        "        if len(test_districts) == 0:\n",
        "            return\n",
        "        np.random.seed(RANDOM_STATE)\n",
        "        sample_dists = np.random.choice(test_districts, size=min(3, len(test_districts)), replace=False)\n",
        "\n",
        "        plt.figure(figsize=(9, 6))\n",
        "        for d in sample_dists:\n",
        "            g = sup_df[sup_df[\"Dist Code\"] == d].sort_values(\"Year\")\n",
        "            plt.plot(g[\"Year\"], g[\"TARGET_YIELD_NEXT\"], \"-o\", label=f\"True (Dist {d})\", alpha=0.7)\n",
        "            plt.plot(g[\"Year\"], g[\"PRED_TEMP\"], \"--x\", label=f\"Pred (Dist {d})\", alpha=0.7)\n",
        "        plt.xlabel(\"Year\")\n",
        "        plt.ylabel(\"Next-Year Yield (kg/ha)\")\n",
        "        plt.title(f\"{crop}: True vs Predicted Over Time ({best_model_name})\")\n",
        "        plt.legend(fontsize=8)\n",
        "        plt.tight_layout()\n",
        "        fname_ts = os.path.join(OUTPUT_DIR, f\"{crop.lower()}_yield_timeseries_example.pdf\")\n",
        "        plt.savefig(fname_ts, bbox_inches=\"tight\")\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to create/save time-series plot for {crop}: {e}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Ensure output directory exists (defensive)\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    # Load data\n",
        "    df = load_data(DATA_PATH)\n",
        "\n",
        "    # Verify key uniqueness\n",
        "    verify_keys(df)\n",
        "\n",
        "    # Detect crops and columns\n",
        "    crops, area_cols, prod_cols, yield_cols = detect_crop_columns(df)\n",
        "\n",
        "    # Basic EDA\n",
        "    basic_eda(df, crops, yield_cols)\n",
        "\n",
        "    # Cleaning and outlier handling\n",
        "    df, crop_cols = clean_data(df, crops, area_cols, prod_cols, yield_cols)\n",
        "\n",
        "    # Diversification\n",
        "    df = compute_diversification(df, area_cols)\n",
        "\n",
        "    # District network\n",
        "    try:\n",
        "        df, G_district, share_means, share_cols = build_district_network(df, area_cols, k_neighbors=5)\n",
        "    except Exception as e:\n",
        "        print(f\"District network construction failed: {e}\")\n",
        "        G_district, share_means, share_cols = None, None, None\n",
        "\n",
        "    # Crop network\n",
        "    if share_means is not None and share_cols is not None:\n",
        "        G_crop, crop_metrics = build_crop_network(share_means, share_cols)\n",
        "    else:\n",
        "        G_crop, crop_metrics = None, None\n",
        "\n",
        "    # Save cleaned data with features\n",
        "    df.to_csv(CLEANED_DATA_PATH, index=False)\n",
        "    print(f\"\\nSaved cleaned dataset with features to: {CLEANED_DATA_PATH}\")\n",
        "\n",
        "    # Supervised datasets and modeling\n",
        "    all_perf = []\n",
        "    modeled_crops = []\n",
        "    best_models_per_crop = {}\n",
        "    sup_datasets = {}\n",
        "\n",
        "    for crop in TARGET_CROPS:\n",
        "        sup_res = construct_supervised_dataset_for_crop(df, crop, crop_cols, crop_metrics=crop_metrics)\n",
        "        if sup_res is None:\n",
        "            continue\n",
        "        sup_df, yield_col = sup_res\n",
        "        sup_datasets[crop] = (sup_df, yield_col)\n",
        "        perf_df = evaluate_models_for_crop(sup_df, crop, yield_col)\n",
        "        if perf_df is not None and not perf_df.empty:\n",
        "            all_perf.append(perf_df)\n",
        "            modeled_crops.append(crop)\n",
        "            best_row = perf_df.loc[perf_df[\"MAE_mean\"].idxmin()]\n",
        "            best_model_name = best_row[\"Model\"]\n",
        "            best_models_per_crop[crop] = best_model_name\n",
        "\n",
        "    if all_perf:\n",
        "        perf_all_df = pd.concat(all_perf, ignore_index=True)\n",
        "        perf_all_df.to_csv(MODEL_PERF_PATH, index=False)\n",
        "        print(f\"\\nSaved model performance summary to: {MODEL_PERF_PATH}\")\n",
        "    else:\n",
        "        perf_all_df = pd.DataFrame()\n",
        "        print(\"\\nNo models were successfully evaluated; performance summary not created.\")\n",
        "\n",
        "    # Diagnostic plots for one crop (e.g., first modeled crop)\n",
        "    if modeled_crops:\n",
        "        crop_for_plots = modeled_crops[0]\n",
        "        best_model_name = best_models_per_crop.get(crop_for_plots, \"RandomForest\")\n",
        "        sup_df_plot, yield_col_plot = sup_datasets[crop_for_plots]\n",
        "        diagnostic_plots_for_crop(sup_df_plot, crop_for_plots, yield_col_plot, best_model_name)\n",
        "\n",
        "    # Final console summary\n",
        "    print(\"\\n===== FINAL SUMMARY =====\")\n",
        "    print(f\"Rows after cleaning: {len(df)}\")\n",
        "    print(f\"Years: {df['Year'].min()} - {df['Year'].max()}\")\n",
        "    print(f\"Number of districts: {df['Dist Code'].nunique() if 'Dist Code' in df.columns else 'N/A'}\")\n",
        "    print(f\"Crops modeled: {modeled_crops}\")\n",
        "    if best_models_per_crop:\n",
        "        print(\"Best model per crop (by MAE_mean):\")\n",
        "        for c, m in best_models_per_crop.items():\n",
        "            print(f\"  {c}: {m}\")\n",
        "    print(f\"Cleaned dataset with features: {CLEANED_DATA_PATH}\")\n",
        "    print(f\"Model performance summary: {MODEL_PERF_PATH if not perf_all_df.empty else 'N/A'}\")\n",
        "    print(f\"Supervised panel CSV prefix: {SUP_DATA_PREFIX}\")\n",
        "    print(\"Key PDF plots saved in OUTPUT_DIR (yield trends, distributions, network overview, diagnostics).\")\n",
        "\n",
        "\n",
        "# Run main\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdzv-G3xf2l5",
        "outputId": "8fd1087d-1ecb-4a13-e07c-c3f1b413f968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicate (Dist Code, Year) rows: 0\n",
            "Key (Dist Code, Year) is unique.\n",
            "\n",
            "===== BASIC EDA =====\n",
            "Rows: 16146, Columns: 80\n",
            "Time range: 1966 - 2017\n",
            "Unique States: 20\n",
            "Unique Districts: 311\n",
            "Detected crops (count=23): ['RICE', 'WHEAT', 'KHARIF SORGHUM', 'RABI SORGHUM', 'SORGHUM', 'PEARL MILLET', 'MAIZE', 'FINGER MILLET', 'BARLEY', 'CHICKPEA', 'PIGEONPEA', 'MINOR PULSES', 'GROUNDNUT', 'SESAMUM', 'RAPESEED AND MUSTARD', 'SAFFLOWER', 'CASTOR', 'LINSEED', 'SUNFLOWER', 'SOYABEAN']...\n",
            "\n",
            "Yield missingness (% of NaN):\n",
            "                         YieldColumn  MissingPct\n",
            "20        OILSEEDS YIELD (Kg per ha)   10.361699\n",
            "11    MINOR PULSES YIELD (Kg per ha)    8.794748\n",
            "15       SAFFLOWER YIELD (Kg per ha)    2.991453\n",
            "17         LINSEED YIELD (Kg per ha)    1.591726\n",
            "21       SUGARCANE YIELD (Kg per ha)    1.492630\n",
            "16          CASTOR YIELD (Kg per ha)    0.514059\n",
            "5     PEARL MILLET YIELD (Kg per ha)    0.334448\n",
            "13         SESAMUM YIELD (Kg per ha)    0.272513\n",
            "9         CHICKPEA YIELD (Kg per ha)    0.260126\n",
            "19        SOYABEAN YIELD (Kg per ha)    0.247739\n",
            "18       SUNFLOWER YIELD (Kg per ha)    0.247739\n",
            "2   KHARIF SORGHUM YIELD (Kg per ha)    0.247739\n",
            "3     RABI SORGHUM YIELD (Kg per ha)    0.247739\n",
            "4          SORGHUM YIELD (Kg per ha)    0.247739\n",
            "1            WHEAT YIELD (Kg per ha)    0.216772\n",
            "10       PIGEONPEA YIELD (Kg per ha)    0.210578\n",
            "6            MAIZE YIELD (Kg per ha)    0.173418\n",
            "0             RICE YIELD (Kg per ha)    0.136257\n",
            "7    FINGER MILLET YIELD (Kg per ha)    0.123870\n",
            "8           BARLEY YIELD (Kg per ha)    0.123870\n",
            "\n",
            "Summary for RICE yield:\n",
            "count    16124.000000\n",
            "mean      1488.954947\n",
            "std        955.255364\n",
            "min          0.000000\n",
            "25%        802.277500\n",
            "50%       1333.330000\n",
            "75%       2114.152500\n",
            "max       5653.830000\n",
            "Name: RICE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for WHEAT yield:\n",
            "count    16111.000000\n",
            "mean      1495.664207\n",
            "std       1080.183846\n",
            "min          0.000000\n",
            "25%        755.740000\n",
            "50%       1350.030000\n",
            "75%       2133.160000\n",
            "max       5541.520000\n",
            "Name: WHEAT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for MAIZE yield:\n",
            "count    16118.000000\n",
            "mean      1411.212242\n",
            "std       1191.278525\n",
            "min          0.000000\n",
            "25%        700.000000\n",
            "50%       1162.075000\n",
            "75%       1864.860000\n",
            "max      21428.570000\n",
            "Name: MAIZE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for GROUNDNUT yield:\n",
            "count    16136.000000\n",
            "mean       766.422954\n",
            "std        627.617769\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%        775.055000\n",
            "75%       1085.835000\n",
            "max       8500.000000\n",
            "Name: GROUNDNUT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for COTTON yield:\n",
            "count    16131.000000\n",
            "mean       124.761659\n",
            "std        207.742327\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%        202.425000\n",
            "max       5000.000000\n",
            "Name: COTTON YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for SUGARCANE yield:\n",
            "count    15905.000000\n",
            "mean      4568.356637\n",
            "std       3128.354591\n",
            "min          0.000000\n",
            "25%       2214.290000\n",
            "50%       4556.960000\n",
            "75%       6750.000000\n",
            "max      22062.300000\n",
            "Name: SUGARCANE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "===== CLEANING DATA =====\n",
            "Clipped RICE yield: old max=5653.83, new max=4127.34\n",
            "Clipped WHEAT yield: old max=5541.52, new max=4551.12\n",
            "Clipped KHARIF SORGHUM yield: old max=6531.25, new max=2402.74\n",
            "Clipped RABI SORGHUM yield: old max=9578.95, new max=4475.66\n",
            "Clipped SORGHUM yield: old max=5742.59, new max=2381.63\n",
            "Clipped PEARL MILLET yield: old max=10000.00, new max=2500.00\n",
            "Clipped MAIZE yield: old max=21428.57, new max=6128.06\n",
            "Clipped FINGER MILLET yield: old max=9286.86, new max=2802.39\n",
            "Clipped BARLEY yield: old max=14441.86, new max=3767.70\n",
            "Clipped CHICKPEA yield: old max=58363.64, new max=1775.46\n",
            "Clipped PIGEONPEA yield: old max=12402.60, new max=2239.42\n",
            "Clipped MINOR PULSES yield: old max=18888.89, new max=1942.42\n",
            "Clipped GROUNDNUT yield: old max=8500.00, new max=2747.12\n",
            "Clipped SESAMUM yield: old max=4400.00, new max=1000.00\n",
            "Clipped RAPESEED AND MUSTARD yield: old max=7000.00, new max=1844.06\n",
            "Clipped SAFFLOWER yield: old max=4166.67, new max=1333.33\n",
            "Clipped CASTOR yield: old max=4600.00, new max=2543.67\n",
            "Clipped LINSEED yield: old max=7000.00, new max=1161.33\n",
            "Clipped SUNFLOWER yield: old max=4282.05, new max=2184.27\n",
            "Clipped SOYABEAN yield: old max=3884.06, new max=2149.71\n",
            "Clipped OILSEEDS yield: old max=25500.00, new max=2054.90\n",
            "Clipped SUGARCANE yield: old max=22062.30, new max=12253.60\n",
            "Clipped COTTON yield: old max=5000.00, new max=934.46\n",
            "\n",
            "Top 15 crops by non-missing yield fraction:\n",
            "                    Crop  NonMissingFrac\n",
            "0                   RICE        0.927660\n",
            "6                  MAIZE        0.875511\n",
            "9               CHICKPEA        0.857612\n",
            "11          MINOR PULSES        0.852285\n",
            "1                  WHEAT        0.850427\n",
            "21             SUGARCANE        0.835563\n",
            "13               SESAMUM        0.820017\n",
            "10             PIGEONPEA        0.806206\n",
            "20              OILSEEDS        0.793076\n",
            "12             GROUNDNUT        0.744952\n",
            "14  RAPESEED AND MUSTARD        0.719993\n",
            "4                SORGHUM        0.715224\n",
            "2         KHARIF SORGHUM        0.695033\n",
            "5           PEARL MILLET        0.616004\n",
            "8                 BARLEY        0.490400\n",
            "\n",
            "===== COMPUTING DIVERSIFICATION =====\n",
            "\n",
            "===== BUILDING DISTRICT SIMILARITY NETWORK =====\n",
            "Network reference window: 2008-2017\n",
            "District network: 311 nodes, 1097 edges\n",
            "\n",
            "===== BUILDING CROP-COOCCURRENCE NETWORK =====\n",
            "Crop network: 29 nodes, 406 edges\n",
            "\n",
            "Saved cleaned dataset with features to: /content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\n",
            "\n",
            "===== BUILDING SUPERVISED DATA FOR RICE =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2510352981.py:510: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved supervised panel for RICE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_rice.csv\n",
            "\n",
            "===== MODELING RICE | Feature set: no_network =====\n",
            "RICE | Naive | no_network | Fold 1: MAE=963.02, RMSE=964.12, MAPE=63.41, MedAE=963.02, R2=-3.421\n",
            "RICE | Naive | no_network | Fold 2: MAE=963.02, RMSE=964.12, MAPE=63.41, MedAE=963.02, R2=-3.421\n",
            "RICE | Naive | no_network | Fold 3: MAE=963.02, RMSE=964.12, MAPE=63.41, MedAE=963.02, R2=-3.421\n",
            "RICE | RollingMean3 | no_network | Fold 1: MAE=542.54, RMSE=548.48, MAPE=34.70, MedAE=542.54, R2=-0.431\n",
            "RICE | RollingMean3 | no_network | Fold 2: MAE=542.54, RMSE=548.48, MAPE=34.70, MedAE=542.54, R2=-0.431\n",
            "RICE | RollingMean3 | no_network | Fold 3: MAE=542.54, RMSE=548.48, MAPE=34.70, MedAE=542.54, R2=-0.431\n",
            "RICE | Ridge | no_network | Fold 1: MAE=462.00, RMSE=467.58, MAPE=32.19, MedAE=462.00, R2=-0.040\n",
            "RICE | Ridge | no_network | Fold 2: MAE=462.00, RMSE=467.58, MAPE=32.19, MedAE=462.00, R2=-0.040\n",
            "RICE | Ridge | no_network | Fold 3: MAE=462.00, RMSE=467.58, MAPE=32.19, MedAE=462.00, R2=-0.040\n",
            "RICE | RandomForest | no_network | Fold 1: MAE=425.65, RMSE=470.47, MAPE=24.64, MedAE=425.65, R2=-0.053\n",
            "RICE | RandomForest | no_network | Fold 2: MAE=425.65, RMSE=470.47, MAPE=24.64, MedAE=425.65, R2=-0.053\n",
            "RICE | RandomForest | no_network | Fold 3: MAE=425.65, RMSE=470.47, MAPE=24.64, MedAE=425.65, R2=-0.053\n",
            "RICE | GradientBoosting | no_network | Fold 1: MAE=443.95, RMSE=578.47, MAPE=22.66, MedAE=443.95, R2=-0.592\n",
            "RICE | GradientBoosting | no_network | Fold 2: MAE=443.95, RMSE=578.47, MAPE=22.66, MedAE=443.95, R2=-0.592\n",
            "RICE | GradientBoosting | no_network | Fold 3: MAE=443.95, RMSE=578.47, MAPE=22.66, MedAE=443.95, R2=-0.592\n",
            "\n",
            "Performance summary for RICE (no_network):\n",
            "   Crop             Model  FeatureSet    MAE_mean  MAE_std   RMSE_mean  \\\n",
            "0  RICE      RandomForest  no_network  425.653800      0.0  470.471766   \n",
            "1  RICE  GradientBoosting  no_network  443.948464      0.0  578.468878   \n",
            "2  RICE             Ridge  no_network  461.997124      0.0  467.580234   \n",
            "3  RICE      RollingMean3  no_network  542.536667      0.0  548.479755   \n",
            "4  RICE             Naive  no_network  963.025000      0.0  964.122280   \n",
            "\n",
            "   RMSE_std  MAPE_mean      MAPE_std  MedAE_mean  MedAE_std   R2_mean  R2_std  \n",
            "0       0.0  24.641385  3.552714e-15  425.653800        0.0 -0.052811     0.0  \n",
            "1       0.0  22.657132  0.000000e+00  443.948464        0.0 -0.591635     0.0  \n",
            "2       0.0  32.190394  0.000000e+00  461.997124        0.0 -0.039910     0.0  \n",
            "3       0.0  34.697012  0.000000e+00  542.536667        0.0 -0.430885     0.0  \n",
            "4       0.0  63.411699  0.000000e+00  963.025000        0.0 -3.421276     0.0  \n",
            "\n",
            "===== MODELING RICE | Feature set: with_network =====\n",
            "RICE | Naive | with_network | Fold 1: MAE=963.02, RMSE=964.12, MAPE=63.41, MedAE=963.02, R2=-3.421\n",
            "RICE | Naive | with_network | Fold 2: MAE=963.02, RMSE=964.12, MAPE=63.41, MedAE=963.02, R2=-3.421\n",
            "RICE | Naive | with_network | Fold 3: MAE=963.02, RMSE=964.12, MAPE=63.41, MedAE=963.02, R2=-3.421\n",
            "RICE | RollingMean3 | with_network | Fold 1: MAE=542.54, RMSE=548.48, MAPE=34.70, MedAE=542.54, R2=-0.431\n",
            "RICE | RollingMean3 | with_network | Fold 2: MAE=542.54, RMSE=548.48, MAPE=34.70, MedAE=542.54, R2=-0.431\n",
            "RICE | RollingMean3 | with_network | Fold 3: MAE=542.54, RMSE=548.48, MAPE=34.70, MedAE=542.54, R2=-0.431\n",
            "RICE | Ridge | with_network | Fold 1: MAE=463.67, RMSE=468.17, MAPE=32.17, MedAE=463.67, R2=-0.043\n",
            "RICE | Ridge | with_network | Fold 2: MAE=463.67, RMSE=468.17, MAPE=32.17, MedAE=463.67, R2=-0.043\n",
            "RICE | Ridge | with_network | Fold 3: MAE=463.67, RMSE=468.17, MAPE=32.17, MedAE=463.67, R2=-0.043\n",
            "RICE | RandomForest | with_network | Fold 1: MAE=429.29, RMSE=456.78, MAPE=25.72, MedAE=429.29, R2=0.008\n",
            "RICE | RandomForest | with_network | Fold 2: MAE=429.29, RMSE=456.78, MAPE=25.72, MedAE=429.29, R2=0.008\n",
            "RICE | RandomForest | with_network | Fold 3: MAE=429.29, RMSE=456.78, MAPE=25.72, MedAE=429.29, R2=0.008\n",
            "RICE | GradientBoosting | with_network | Fold 1: MAE=397.40, RMSE=511.36, MAPE=20.47, MedAE=397.40, R2=-0.244\n",
            "RICE | GradientBoosting | with_network | Fold 2: MAE=397.40, RMSE=511.36, MAPE=20.47, MedAE=397.40, R2=-0.244\n",
            "RICE | GradientBoosting | with_network | Fold 3: MAE=397.40, RMSE=511.36, MAPE=20.47, MedAE=397.40, R2=-0.244\n",
            "\n",
            "Performance summary for RICE (with_network):\n",
            "   Crop             Model    FeatureSet    MAE_mean       MAE_std   RMSE_mean  \\\n",
            "0  RICE  GradientBoosting  with_network  397.400528  0.000000e+00  511.359520   \n",
            "1  RICE      RandomForest  with_network  429.288625  5.684342e-14  456.781825   \n",
            "2  RICE             Ridge  with_network  463.667536  0.000000e+00  468.174317   \n",
            "3  RICE      RollingMean3  with_network  542.536667  0.000000e+00  548.479755   \n",
            "4  RICE             Naive  with_network  963.025000  0.000000e+00  964.122280   \n",
            "\n",
            "   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean     MedAE_std   R2_mean  R2_std  \n",
            "0       0.0  20.472675       0.0  397.400528  0.000000e+00 -0.243759     0.0  \n",
            "1       0.0  25.717529       0.0  429.288625  5.684342e-14  0.007567     0.0  \n",
            "2       0.0  32.165798       0.0  463.667536  0.000000e+00 -0.042554     0.0  \n",
            "3       0.0  34.697012       0.0  542.536667  0.000000e+00 -0.430885     0.0  \n",
            "4       0.0  63.411699       0.0  963.025000  0.000000e+00 -3.421276     0.0  \n",
            "Best model for RICE: GradientBoosting (FeatureSet=with_network), MAE_mean=397.40\n",
            "\n",
            "===== DIAGNOSTIC PLOTS FOR RICE (GradientBoosting, feature set=with network) =====\n",
            "\n",
            "===== BUILDING SUPERVISED DATA FOR WHEAT =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2510352981.py:510: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved supervised panel for WHEAT to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_wheat.csv\n",
            "\n",
            "===== MODELING WHEAT | Feature set: no_network =====\n",
            "WHEAT | Naive | no_network | Fold 1: MAE=126.29, RMSE=127.37, MAPE=10.41, MedAE=126.29, R2=-4.385\n",
            "WHEAT | Naive | no_network | Fold 2: MAE=126.29, RMSE=127.37, MAPE=10.41, MedAE=126.29, R2=-4.385\n",
            "WHEAT | Naive | no_network | Fold 3: MAE=126.29, RMSE=127.37, MAPE=10.41, MedAE=126.29, R2=-4.385\n",
            "WHEAT | RollingMean3 | no_network | Fold 1: MAE=91.64, RMSE=113.41, MAPE=7.35, MedAE=91.64, R2=-3.269\n",
            "WHEAT | RollingMean3 | no_network | Fold 2: MAE=91.64, RMSE=113.41, MAPE=7.35, MedAE=91.64, R2=-3.269\n",
            "WHEAT | RollingMean3 | no_network | Fold 3: MAE=91.64, RMSE=113.41, MAPE=7.35, MedAE=91.64, R2=-3.269\n",
            "WHEAT | Ridge | no_network | Fold 1: MAE=160.05, RMSE=166.05, MAPE=13.10, MedAE=160.05, R2=-8.152\n",
            "WHEAT | Ridge | no_network | Fold 2: MAE=160.05, RMSE=166.05, MAPE=13.10, MedAE=160.05, R2=-8.152\n",
            "WHEAT | Ridge | no_network | Fold 3: MAE=160.05, RMSE=166.05, MAPE=13.10, MedAE=160.05, R2=-8.152\n",
            "WHEAT | RandomForest | no_network | Fold 1: MAE=104.88, RMSE=116.59, MAPE=8.50, MedAE=104.88, R2=-3.511\n",
            "WHEAT | RandomForest | no_network | Fold 2: MAE=104.88, RMSE=116.59, MAPE=8.50, MedAE=104.88, R2=-3.511\n",
            "WHEAT | RandomForest | no_network | Fold 3: MAE=104.88, RMSE=116.59, MAPE=8.50, MedAE=104.88, R2=-3.511\n",
            "WHEAT | GradientBoosting | no_network | Fold 1: MAE=107.02, RMSE=109.77, MAPE=8.78, MedAE=107.02, R2=-2.999\n",
            "WHEAT | GradientBoosting | no_network | Fold 2: MAE=107.02, RMSE=109.77, MAPE=8.78, MedAE=107.02, R2=-2.999\n",
            "WHEAT | GradientBoosting | no_network | Fold 3: MAE=107.02, RMSE=109.77, MAPE=8.78, MedAE=107.02, R2=-2.999\n",
            "\n",
            "Performance summary for WHEAT (no_network):\n",
            "    Crop             Model  FeatureSet    MAE_mean       MAE_std   RMSE_mean  \\\n",
            "0  WHEAT      RollingMean3  no_network   91.638333  0.000000e+00  113.410001   \n",
            "1  WHEAT      RandomForest  no_network  104.877575  5.380143e-14  116.587406   \n",
            "2  WHEAT  GradientBoosting  no_network  107.023546  0.000000e+00  109.765963   \n",
            "3  WHEAT             Naive  no_network  126.295000  0.000000e+00  127.370217   \n",
            "4  WHEAT             Ridge  no_network  160.045622  0.000000e+00  166.050450   \n",
            "\n",
            "       RMSE_std  MAPE_mean      MAPE_std  MedAE_mean     MedAE_std   R2_mean  \\\n",
            "0  1.421085e-14   7.345914  0.000000e+00   91.638333  0.000000e+00 -3.268903   \n",
            "1  7.429618e-14   8.503372  4.351168e-15  104.877575  5.380143e-14 -3.511457   \n",
            "2  1.421085e-14   8.781222  0.000000e+00  107.023546  0.000000e+00 -2.998977   \n",
            "3  0.000000e+00  10.408589  0.000000e+00  126.295000  0.000000e+00 -4.384549   \n",
            "4  0.000000e+00  13.102330  0.000000e+00  160.045622  0.000000e+00 -8.151529   \n",
            "\n",
            "         R2_std  \n",
            "0  0.000000e+00  \n",
            "1  5.863547e-15  \n",
            "2  0.000000e+00  \n",
            "3  0.000000e+00  \n",
            "4  0.000000e+00  \n",
            "\n",
            "===== MODELING WHEAT | Feature set: with_network =====\n",
            "WHEAT | Naive | with_network | Fold 1: MAE=126.29, RMSE=127.37, MAPE=10.41, MedAE=126.29, R2=-4.385\n",
            "WHEAT | Naive | with_network | Fold 2: MAE=126.29, RMSE=127.37, MAPE=10.41, MedAE=126.29, R2=-4.385\n",
            "WHEAT | Naive | with_network | Fold 3: MAE=126.29, RMSE=127.37, MAPE=10.41, MedAE=126.29, R2=-4.385\n",
            "WHEAT | RollingMean3 | with_network | Fold 1: MAE=91.64, RMSE=113.41, MAPE=7.35, MedAE=91.64, R2=-3.269\n",
            "WHEAT | RollingMean3 | with_network | Fold 2: MAE=91.64, RMSE=113.41, MAPE=7.35, MedAE=91.64, R2=-3.269\n",
            "WHEAT | RollingMean3 | with_network | Fold 3: MAE=91.64, RMSE=113.41, MAPE=7.35, MedAE=91.64, R2=-3.269\n",
            "WHEAT | Ridge | with_network | Fold 1: MAE=159.60, RMSE=165.45, MAPE=13.07, MedAE=159.60, R2=-8.085\n",
            "WHEAT | Ridge | with_network | Fold 2: MAE=159.60, RMSE=165.45, MAPE=13.07, MedAE=159.60, R2=-8.085\n",
            "WHEAT | Ridge | with_network | Fold 3: MAE=159.60, RMSE=165.45, MAPE=13.07, MedAE=159.60, R2=-8.085\n",
            "WHEAT | RandomForest | with_network | Fold 1: MAE=102.76, RMSE=114.65, MAPE=8.33, MedAE=102.76, R2=-3.362\n",
            "WHEAT | RandomForest | with_network | Fold 2: MAE=102.76, RMSE=114.65, MAPE=8.33, MedAE=102.76, R2=-3.362\n",
            "WHEAT | RandomForest | with_network | Fold 3: MAE=102.76, RMSE=114.65, MAPE=8.33, MedAE=102.76, R2=-3.362\n",
            "WHEAT | GradientBoosting | with_network | Fold 1: MAE=107.08, RMSE=109.27, MAPE=8.80, MedAE=107.08, R2=-2.963\n",
            "WHEAT | GradientBoosting | with_network | Fold 2: MAE=107.08, RMSE=109.27, MAPE=8.80, MedAE=107.08, R2=-2.963\n",
            "WHEAT | GradientBoosting | with_network | Fold 3: MAE=107.08, RMSE=109.27, MAPE=8.80, MedAE=107.08, R2=-2.963\n",
            "\n",
            "Performance summary for WHEAT (with_network):\n",
            "    Crop             Model    FeatureSet    MAE_mean  MAE_std   RMSE_mean  \\\n",
            "0  WHEAT      RollingMean3  with_network   91.638333      0.0  113.410001   \n",
            "1  WHEAT      RandomForest  with_network  102.762100      0.0  114.646187   \n",
            "2  WHEAT  GradientBoosting  with_network  107.077405      0.0  109.270524   \n",
            "3  WHEAT             Naive  with_network  126.295000      0.0  127.370217   \n",
            "4  WHEAT             Ridge  with_network  159.598067      0.0  165.447902   \n",
            "\n",
            "       RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean  \\\n",
            "0  1.421085e-14   7.345914       0.0   91.638333        0.0 -3.268903   \n",
            "1  0.000000e+00   8.328340       0.0  102.762100        0.0 -3.362473   \n",
            "2  0.000000e+00   8.795478       0.0  107.077405        0.0 -2.962959   \n",
            "3  0.000000e+00  10.408589       0.0  126.295000        0.0 -4.384549   \n",
            "4  0.000000e+00  13.067654       0.0  159.598067        0.0 -8.085233   \n",
            "\n",
            "         R2_std  \n",
            "0  0.000000e+00  \n",
            "1  4.440892e-16  \n",
            "2  0.000000e+00  \n",
            "3  0.000000e+00  \n",
            "4  0.000000e+00  \n",
            "Best model for WHEAT: RollingMean3 (FeatureSet=no_network), MAE_mean=91.64\n",
            "\n",
            "===== DIAGNOSTIC PLOTS FOR WHEAT (RollingMean3, feature set=no network) =====\n",
            "\n",
            "===== BUILDING SUPERVISED DATA FOR MAIZE =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2510352981.py:510: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved supervised panel for MAIZE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_maize.csv\n",
            "\n",
            "===== MODELING MAIZE | Feature set: no_network =====\n",
            "MAIZE | Naive | no_network | Fold 1: MAE=316.88, RMSE=400.20, MAPE=15.69, MedAE=316.88, R2=-121.049\n",
            "MAIZE | Naive | no_network | Fold 2: MAE=316.88, RMSE=400.20, MAPE=15.69, MedAE=316.88, R2=-121.049\n",
            "MAIZE | Naive | no_network | Fold 3: MAE=316.88, RMSE=400.20, MAPE=15.69, MedAE=316.88, R2=-121.049\n",
            "MAIZE | RollingMean3 | no_network | Fold 1: MAE=390.87, RMSE=399.78, MAPE=19.55, MedAE=390.87, R2=-120.792\n",
            "MAIZE | RollingMean3 | no_network | Fold 2: MAE=390.87, RMSE=399.78, MAPE=19.55, MedAE=390.87, R2=-120.792\n",
            "MAIZE | RollingMean3 | no_network | Fold 3: MAE=390.87, RMSE=399.78, MAPE=19.55, MedAE=390.87, R2=-120.792\n",
            "MAIZE | Ridge | no_network | Fold 1: MAE=651.67, RMSE=702.00, MAPE=32.48, MedAE=651.67, R2=-374.542\n",
            "MAIZE | Ridge | no_network | Fold 2: MAE=651.67, RMSE=702.00, MAPE=32.48, MedAE=651.67, R2=-374.542\n",
            "MAIZE | Ridge | no_network | Fold 3: MAE=651.67, RMSE=702.00, MAPE=32.48, MedAE=651.67, R2=-374.542\n",
            "MAIZE | RandomForest | no_network | Fold 1: MAE=492.62, RMSE=493.39, MAPE=24.71, MedAE=492.62, R2=-184.506\n",
            "MAIZE | RandomForest | no_network | Fold 2: MAE=492.62, RMSE=493.39, MAPE=24.71, MedAE=492.62, R2=-184.506\n",
            "MAIZE | RandomForest | no_network | Fold 3: MAE=492.62, RMSE=493.39, MAPE=24.71, MedAE=492.62, R2=-184.506\n",
            "MAIZE | GradientBoosting | no_network | Fold 1: MAE=514.33, RMSE=515.00, MAPE=25.80, MedAE=514.33, R2=-201.114\n",
            "MAIZE | GradientBoosting | no_network | Fold 2: MAE=514.33, RMSE=515.00, MAPE=25.80, MedAE=514.33, R2=-201.114\n",
            "MAIZE | GradientBoosting | no_network | Fold 3: MAE=514.33, RMSE=515.00, MAPE=25.80, MedAE=514.33, R2=-201.114\n",
            "\n",
            "Performance summary for MAIZE (no_network):\n",
            "    Crop             Model  FeatureSet    MAE_mean       MAE_std   RMSE_mean  \\\n",
            "0  MAIZE             Naive  no_network  316.880000  0.000000e+00  400.198650   \n",
            "1  MAIZE      RollingMean3  no_network  390.865000  0.000000e+00  399.776302   \n",
            "2  MAIZE      RandomForest  no_network  492.616725  5.684342e-14  493.386311   \n",
            "3  MAIZE  GradientBoosting  no_network  514.329423  0.000000e+00  514.998864   \n",
            "4  MAIZE             Ridge  no_network  651.673632  0.000000e+00  702.000805   \n",
            "\n",
            "       RMSE_std  MAPE_mean      MAPE_std  MedAE_mean     MedAE_std  \\\n",
            "0  5.684342e-14  15.687695  1.776357e-15  316.880000  0.000000e+00   \n",
            "1  0.000000e+00  19.549080  0.000000e+00  390.865000  0.000000e+00   \n",
            "2  5.684342e-14  24.709618  3.552714e-15  492.616725  5.684342e-14   \n",
            "3  0.000000e+00  25.801018  0.000000e+00  514.329423  0.000000e+00   \n",
            "4  0.000000e+00  32.482873  0.000000e+00  651.673632  0.000000e+00   \n",
            "\n",
            "      R2_mean        R2_std  \n",
            "0 -121.049063  1.421085e-14  \n",
            "1 -120.791591  0.000000e+00  \n",
            "2 -184.505762  0.000000e+00  \n",
            "3 -201.113700  0.000000e+00  \n",
            "4 -374.541928  5.684342e-14  \n",
            "\n",
            "===== MODELING MAIZE | Feature set: with_network =====\n",
            "MAIZE | Naive | with_network | Fold 1: MAE=316.88, RMSE=400.20, MAPE=15.69, MedAE=316.88, R2=-121.049\n",
            "MAIZE | Naive | with_network | Fold 2: MAE=316.88, RMSE=400.20, MAPE=15.69, MedAE=316.88, R2=-121.049\n",
            "MAIZE | Naive | with_network | Fold 3: MAE=316.88, RMSE=400.20, MAPE=15.69, MedAE=316.88, R2=-121.049\n",
            "MAIZE | RollingMean3 | with_network | Fold 1: MAE=390.87, RMSE=399.78, MAPE=19.55, MedAE=390.87, R2=-120.792\n",
            "MAIZE | RollingMean3 | with_network | Fold 2: MAE=390.87, RMSE=399.78, MAPE=19.55, MedAE=390.87, R2=-120.792\n",
            "MAIZE | RollingMean3 | with_network | Fold 3: MAE=390.87, RMSE=399.78, MAPE=19.55, MedAE=390.87, R2=-120.792\n",
            "MAIZE | Ridge | with_network | Fold 1: MAE=643.38, RMSE=696.68, MAPE=32.06, MedAE=643.38, R2=-368.871\n",
            "MAIZE | Ridge | with_network | Fold 2: MAE=643.38, RMSE=696.68, MAPE=32.06, MedAE=643.38, R2=-368.871\n",
            "MAIZE | Ridge | with_network | Fold 3: MAE=643.38, RMSE=696.68, MAPE=32.06, MedAE=643.38, R2=-368.871\n",
            "MAIZE | RandomForest | with_network | Fold 1: MAE=498.02, RMSE=498.92, MAPE=24.98, MedAE=498.02, R2=-188.691\n",
            "MAIZE | RandomForest | with_network | Fold 2: MAE=498.02, RMSE=498.92, MAPE=24.98, MedAE=498.02, R2=-188.691\n",
            "MAIZE | RandomForest | with_network | Fold 3: MAE=498.02, RMSE=498.92, MAPE=24.98, MedAE=498.02, R2=-188.691\n",
            "MAIZE | GradientBoosting | with_network | Fold 1: MAE=508.53, RMSE=509.30, MAPE=25.51, MedAE=508.53, R2=-196.664\n",
            "MAIZE | GradientBoosting | with_network | Fold 2: MAE=508.53, RMSE=509.30, MAPE=25.51, MedAE=508.53, R2=-196.664\n",
            "MAIZE | GradientBoosting | with_network | Fold 3: MAE=508.53, RMSE=509.30, MAPE=25.51, MedAE=508.53, R2=-196.664\n",
            "\n",
            "Performance summary for MAIZE (with_network):\n",
            "    Crop             Model    FeatureSet    MAE_mean       MAE_std  \\\n",
            "0  MAIZE             Naive  with_network  316.880000  0.000000e+00   \n",
            "1  MAIZE      RollingMean3  with_network  390.865000  0.000000e+00   \n",
            "2  MAIZE      RandomForest  with_network  498.019900  5.684342e-14   \n",
            "3  MAIZE  GradientBoosting  with_network  508.526538  5.684342e-14   \n",
            "4  MAIZE             Ridge  with_network  643.379163  0.000000e+00   \n",
            "\n",
            "    RMSE_mean      RMSE_std  MAPE_mean      MAPE_std  MedAE_mean  \\\n",
            "0  400.198650  5.684342e-14  15.687695  1.776357e-15  316.880000   \n",
            "1  399.776302  0.000000e+00  19.549080  0.000000e+00  390.865000   \n",
            "2  498.920986  5.684342e-14  24.978702  4.102320e-15  498.019900   \n",
            "3  509.298320  0.000000e+00  25.508026  0.000000e+00  508.526538   \n",
            "4  696.680612  1.136868e-13  32.060695  0.000000e+00  643.379163   \n",
            "\n",
            "      MedAE_std     R2_mean        R2_std  \n",
            "0  0.000000e+00 -121.049063  1.421085e-14  \n",
            "1  0.000000e+00 -120.791591  0.000000e+00  \n",
            "2  5.684342e-14 -188.691013  4.922784e-14  \n",
            "3  5.684342e-14 -196.664055  0.000000e+00  \n",
            "4  0.000000e+00 -368.871323  0.000000e+00  \n",
            "Best model for MAIZE: Naive (FeatureSet=no_network), MAE_mean=316.88\n",
            "\n",
            "===== DIAGNOSTIC PLOTS FOR MAIZE (Naive, feature set=no network) =====\n",
            "\n",
            "===== BUILDING SUPERVISED DATA FOR GROUNDNUT =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2510352981.py:510: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved supervised panel for GROUNDNUT to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_groundnut.csv\n",
            "\n",
            "===== MODELING GROUNDNUT | Feature set: no_network =====\n",
            "GROUNDNUT | Naive | no_network | Fold 1: MAE=314.83, RMSE=315.32, MAPE=16.85, MedAE=314.83, R2=-3.500\n",
            "GROUNDNUT | Naive | no_network | Fold 2: MAE=314.83, RMSE=315.32, MAPE=16.85, MedAE=314.83, R2=-3.500\n",
            "GROUNDNUT | Naive | no_network | Fold 3: MAE=314.83, RMSE=315.32, MAPE=16.85, MedAE=314.83, R2=-3.500\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 1: MAE=182.43, RMSE=222.29, MAPE=9.27, MedAE=182.43, R2=-1.237\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 2: MAE=182.43, RMSE=222.29, MAPE=9.27, MedAE=182.43, R2=-1.237\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 3: MAE=182.43, RMSE=222.29, MAPE=9.27, MedAE=182.43, R2=-1.237\n",
            "GROUNDNUT | Ridge | no_network | Fold 1: MAE=285.04, RMSE=340.49, MAPE=14.53, MedAE=285.04, R2=-4.248\n",
            "GROUNDNUT | Ridge | no_network | Fold 2: MAE=285.04, RMSE=340.49, MAPE=14.53, MedAE=285.04, R2=-4.248\n",
            "GROUNDNUT | Ridge | no_network | Fold 3: MAE=285.04, RMSE=340.49, MAPE=14.53, MedAE=285.04, R2=-4.248\n",
            "GROUNDNUT | RandomForest | no_network | Fold 1: MAE=205.99, RMSE=261.08, MAPE=10.39, MedAE=205.99, R2=-2.085\n",
            "GROUNDNUT | RandomForest | no_network | Fold 2: MAE=205.99, RMSE=261.08, MAPE=10.39, MedAE=205.99, R2=-2.085\n",
            "GROUNDNUT | RandomForest | no_network | Fold 3: MAE=205.99, RMSE=261.08, MAPE=10.39, MedAE=205.99, R2=-2.085\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 1: MAE=185.67, RMSE=256.42, MAPE=9.23, MedAE=185.67, R2=-1.976\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 2: MAE=185.67, RMSE=256.42, MAPE=9.23, MedAE=185.67, R2=-1.976\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 3: MAE=185.67, RMSE=256.42, MAPE=9.23, MedAE=185.67, R2=-1.976\n",
            "\n",
            "Performance summary for GROUNDNUT (no_network):\n",
            "        Crop             Model  FeatureSet    MAE_mean  MAE_std   RMSE_mean  \\\n",
            "0  GROUNDNUT      RollingMean3  no_network  182.430000      0.0  222.286748   \n",
            "1  GROUNDNUT  GradientBoosting  no_network  185.672275      0.0  256.424510   \n",
            "2  GROUNDNUT      RandomForest  no_network  205.992375      0.0  261.082566   \n",
            "3  GROUNDNUT             Ridge  no_network  285.037636      0.0  340.489364   \n",
            "4  GROUNDNUT             Naive  no_network  314.830000      0.0  315.319334   \n",
            "\n",
            "   RMSE_std  MAPE_mean      MAPE_std  MedAE_mean  MedAE_std   R2_mean  R2_std  \n",
            "0       0.0   9.266921  0.000000e+00  182.430000        0.0 -1.236583     0.0  \n",
            "1       0.0   9.228374  0.000000e+00  185.672275        0.0 -1.976301     0.0  \n",
            "2       0.0  10.391233  0.000000e+00  205.992375        0.0 -2.085415     0.0  \n",
            "3       0.0  14.531185  1.776357e-15  285.037636        0.0 -4.247651     0.0  \n",
            "4       0.0  16.853444  0.000000e+00  314.830000        0.0 -3.500482     0.0  \n",
            "\n",
            "===== MODELING GROUNDNUT | Feature set: with_network =====\n",
            "GROUNDNUT | Naive | with_network | Fold 1: MAE=314.83, RMSE=315.32, MAPE=16.85, MedAE=314.83, R2=-3.500\n",
            "GROUNDNUT | Naive | with_network | Fold 2: MAE=314.83, RMSE=315.32, MAPE=16.85, MedAE=314.83, R2=-3.500\n",
            "GROUNDNUT | Naive | with_network | Fold 3: MAE=314.83, RMSE=315.32, MAPE=16.85, MedAE=314.83, R2=-3.500\n",
            "GROUNDNUT | RollingMean3 | with_network | Fold 1: MAE=182.43, RMSE=222.29, MAPE=9.27, MedAE=182.43, R2=-1.237\n",
            "GROUNDNUT | RollingMean3 | with_network | Fold 2: MAE=182.43, RMSE=222.29, MAPE=9.27, MedAE=182.43, R2=-1.237\n",
            "GROUNDNUT | RollingMean3 | with_network | Fold 3: MAE=182.43, RMSE=222.29, MAPE=9.27, MedAE=182.43, R2=-1.237\n",
            "GROUNDNUT | Ridge | with_network | Fold 1: MAE=280.84, RMSE=337.81, MAPE=14.30, MedAE=280.84, R2=-4.165\n",
            "GROUNDNUT | Ridge | with_network | Fold 2: MAE=280.84, RMSE=337.81, MAPE=14.30, MedAE=280.84, R2=-4.165\n",
            "GROUNDNUT | Ridge | with_network | Fold 3: MAE=280.84, RMSE=337.81, MAPE=14.30, MedAE=280.84, R2=-4.165\n",
            "GROUNDNUT | RandomForest | with_network | Fold 1: MAE=205.78, RMSE=257.80, MAPE=10.40, MedAE=205.78, R2=-2.008\n",
            "GROUNDNUT | RandomForest | with_network | Fold 2: MAE=205.78, RMSE=257.80, MAPE=10.40, MedAE=205.78, R2=-2.008\n",
            "GROUNDNUT | RandomForest | with_network | Fold 3: MAE=205.78, RMSE=257.80, MAPE=10.40, MedAE=205.78, R2=-2.008\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 1: MAE=179.66, RMSE=250.58, MAPE=8.91, MedAE=179.66, R2=-1.842\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 2: MAE=179.66, RMSE=250.58, MAPE=8.91, MedAE=179.66, R2=-1.842\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 3: MAE=179.66, RMSE=250.58, MAPE=8.91, MedAE=179.66, R2=-1.842\n",
            "\n",
            "Performance summary for GROUNDNUT (with_network):\n",
            "        Crop             Model    FeatureSet    MAE_mean  MAE_std   RMSE_mean  \\\n",
            "0  GROUNDNUT  GradientBoosting  with_network  179.662039      0.0  250.580242   \n",
            "1  GROUNDNUT      RollingMean3  with_network  182.430000      0.0  222.286748   \n",
            "2  GROUNDNUT      RandomForest  with_network  205.776400      0.0  257.804391   \n",
            "3  GROUNDNUT             Ridge  with_network  280.835952      0.0  337.811593   \n",
            "4  GROUNDNUT             Naive  with_network  314.830000      0.0  315.319334   \n",
            "\n",
            "   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean  R2_std  \n",
            "0       0.0   8.914524       0.0  179.662039        0.0 -1.842179     0.0  \n",
            "1       0.0   9.266921       0.0  182.430000        0.0 -1.236583     0.0  \n",
            "2       0.0  10.401424       0.0  205.776400        0.0 -2.008420     0.0  \n",
            "3       0.0  14.298851       0.0  280.835952        0.0 -4.165435     0.0  \n",
            "4       0.0  16.853444       0.0  314.830000        0.0 -3.500482     0.0  \n",
            "Best model for GROUNDNUT: GradientBoosting (FeatureSet=with_network), MAE_mean=179.66\n",
            "\n",
            "===== DIAGNOSTIC PLOTS FOR GROUNDNUT (GradientBoosting, feature set=with network) =====\n",
            "\n",
            "===== BUILDING SUPERVISED DATA FOR COTTON =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2510352981.py:510: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved supervised panel for COTTON to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_cotton.csv\n",
            "\n",
            "===== MODELING COTTON | Feature set: no_network =====\n",
            "Time-series CV error for COTTON (no_network): Not enough years to build the requested time-series CV splits.\n",
            "\n",
            "===== MODELING COTTON | Feature set: with_network =====\n",
            "Time-series CV error for COTTON (with_network): Not enough years to build the requested time-series CV splits.\n",
            "\n",
            "===== BUILDING SUPERVISED DATA FOR SUGARCANE =====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2510352981.py:510: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved supervised panel for SUGARCANE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_sugarcane.csv\n",
            "\n",
            "===== MODELING SUGARCANE | Feature set: no_network =====\n",
            "SUGARCANE | Naive | no_network | Fold 1: MAE=89.38, RMSE=89.38, MAPE=26.37, MedAE=89.38, R2=-3.000\n",
            "SUGARCANE | Naive | no_network | Fold 2: MAE=89.38, RMSE=89.38, MAPE=26.37, MedAE=89.38, R2=-3.000\n",
            "SUGARCANE | Naive | no_network | Fold 3: MAE=89.38, RMSE=89.38, MAPE=26.37, MedAE=89.38, R2=-3.000\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 1: MAE=70.93, RMSE=92.64, MAPE=23.21, MedAE=70.93, R2=-3.297\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 2: MAE=70.93, RMSE=92.64, MAPE=23.21, MedAE=70.93, R2=-3.297\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 3: MAE=70.93, RMSE=92.64, MAPE=23.21, MedAE=70.93, R2=-3.297\n",
            "SUGARCANE | Ridge | no_network | Fold 1: MAE=272.56, RMSE=290.29, MAPE=84.25, MedAE=272.56, R2=-41.194\n",
            "SUGARCANE | Ridge | no_network | Fold 2: MAE=272.56, RMSE=290.29, MAPE=84.25, MedAE=272.56, R2=-41.194\n",
            "SUGARCANE | Ridge | no_network | Fold 3: MAE=272.56, RMSE=290.29, MAPE=84.25, MedAE=272.56, R2=-41.194\n",
            "SUGARCANE | RandomForest | no_network | Fold 1: MAE=64.16, RMSE=68.60, MAPE=19.86, MedAE=64.16, R2=-1.357\n",
            "SUGARCANE | RandomForest | no_network | Fold 2: MAE=64.16, RMSE=68.60, MAPE=19.86, MedAE=64.16, R2=-1.357\n",
            "SUGARCANE | RandomForest | no_network | Fold 3: MAE=64.16, RMSE=68.60, MAPE=19.86, MedAE=64.16, R2=-1.357\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 1: MAE=85.29, RMSE=95.05, MAPE=26.77, MedAE=85.29, R2=-3.523\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 2: MAE=85.29, RMSE=95.05, MAPE=26.77, MedAE=85.29, R2=-3.523\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 3: MAE=85.29, RMSE=95.05, MAPE=26.77, MedAE=85.29, R2=-3.523\n",
            "\n",
            "Performance summary for SUGARCANE (no_network):\n",
            "        Crop             Model  FeatureSet    MAE_mean  MAE_std   RMSE_mean  \\\n",
            "0  SUGARCANE      RandomForest  no_network   64.159275      0.0   68.604665   \n",
            "1  SUGARCANE      RollingMean3  no_network   70.930000      0.0   92.637119   \n",
            "2  SUGARCANE  GradientBoosting  no_network   85.292972      0.0   95.046227   \n",
            "3  SUGARCANE             Naive  no_network   89.380000      0.0   89.380000   \n",
            "4  SUGARCANE             Ridge  no_network  272.555311      0.0  290.292112   \n",
            "\n",
            "   RMSE_std  MAPE_mean      MAPE_std  MedAE_mean  MedAE_std    R2_mean  \\\n",
            "0       0.0  19.861275  0.000000e+00   64.159275        0.0  -1.356604   \n",
            "1       0.0  23.209367  0.000000e+00   70.930000        0.0  -3.296842   \n",
            "2       0.0  26.772387  3.552714e-15   85.292972        0.0  -3.523234   \n",
            "3       0.0  26.373887  0.000000e+00   89.380000        0.0  -3.000000   \n",
            "4       0.0  84.247021  0.000000e+00  272.555311        0.0 -41.193909   \n",
            "\n",
            "         R2_std  \n",
            "0  2.220446e-16  \n",
            "1  4.440892e-16  \n",
            "2  0.000000e+00  \n",
            "3  0.000000e+00  \n",
            "4  0.000000e+00  \n",
            "\n",
            "===== MODELING SUGARCANE | Feature set: with_network =====\n",
            "SUGARCANE | Naive | with_network | Fold 1: MAE=89.38, RMSE=89.38, MAPE=26.37, MedAE=89.38, R2=-3.000\n",
            "SUGARCANE | Naive | with_network | Fold 2: MAE=89.38, RMSE=89.38, MAPE=26.37, MedAE=89.38, R2=-3.000\n",
            "SUGARCANE | Naive | with_network | Fold 3: MAE=89.38, RMSE=89.38, MAPE=26.37, MedAE=89.38, R2=-3.000\n",
            "SUGARCANE | RollingMean3 | with_network | Fold 1: MAE=70.93, RMSE=92.64, MAPE=23.21, MedAE=70.93, R2=-3.297\n",
            "SUGARCANE | RollingMean3 | with_network | Fold 2: MAE=70.93, RMSE=92.64, MAPE=23.21, MedAE=70.93, R2=-3.297\n",
            "SUGARCANE | RollingMean3 | with_network | Fold 3: MAE=70.93, RMSE=92.64, MAPE=23.21, MedAE=70.93, R2=-3.297\n",
            "SUGARCANE | Ridge | with_network | Fold 1: MAE=271.94, RMSE=288.77, MAPE=83.96, MedAE=271.94, R2=-40.753\n",
            "SUGARCANE | Ridge | with_network | Fold 2: MAE=271.94, RMSE=288.77, MAPE=83.96, MedAE=271.94, R2=-40.753\n",
            "SUGARCANE | Ridge | with_network | Fold 3: MAE=271.94, RMSE=288.77, MAPE=83.96, MedAE=271.94, R2=-40.753\n",
            "SUGARCANE | RandomForest | with_network | Fold 1: MAE=53.79, RMSE=56.74, MAPE=16.56, MedAE=53.79, R2=-0.612\n",
            "SUGARCANE | RandomForest | with_network | Fold 2: MAE=53.79, RMSE=56.74, MAPE=16.56, MedAE=53.79, R2=-0.612\n",
            "SUGARCANE | RandomForest | with_network | Fold 3: MAE=53.79, RMSE=56.74, MAPE=16.56, MedAE=53.79, R2=-0.612\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 1: MAE=63.42, RMSE=63.82, MAPE=18.99, MedAE=63.42, R2=-1.039\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 2: MAE=63.42, RMSE=63.82, MAPE=18.99, MedAE=63.42, R2=-1.039\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 3: MAE=63.42, RMSE=63.82, MAPE=18.99, MedAE=63.42, R2=-1.039\n",
            "\n",
            "Performance summary for SUGARCANE (with_network):\n",
            "        Crop             Model    FeatureSet    MAE_mean  MAE_std   RMSE_mean  \\\n",
            "0  SUGARCANE      RandomForest  with_network   53.789400      0.0   56.735318   \n",
            "1  SUGARCANE  GradientBoosting  with_network   63.423328      0.0   63.822260   \n",
            "2  SUGARCANE      RollingMean3  with_network   70.930000      0.0   92.637119   \n",
            "3  SUGARCANE             Naive  with_network   89.380000      0.0   89.380000   \n",
            "4  SUGARCANE             Ridge  with_network  271.939563      0.0  288.772687   \n",
            "\n",
            "   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std    R2_mean  \\\n",
            "0       0.0  16.562285       0.0   53.789400        0.0  -0.611708   \n",
            "1       0.0  18.987273       0.0   63.423328        0.0  -1.039500   \n",
            "2       0.0  23.209367       0.0   70.930000        0.0  -3.296842   \n",
            "3       0.0  26.373887       0.0   89.380000        0.0  -3.000000   \n",
            "4       0.0  83.959609       0.0  271.939563        0.0 -40.753368   \n",
            "\n",
            "         R2_std  \n",
            "0  0.000000e+00  \n",
            "1  0.000000e+00  \n",
            "2  4.440892e-16  \n",
            "3  0.000000e+00  \n",
            "4  0.000000e+00  \n",
            "Best model for SUGARCANE: RandomForest (FeatureSet=with_network), MAE_mean=53.79\n",
            "\n",
            "===== DIAGNOSTIC PLOTS FOR SUGARCANE (RandomForest, feature set=with network) =====\n",
            "\n",
            "Saved model performance summary to: /content/drive/MyDrive/Shiny/ICRISAT/Results/model_performance_summary.csv\n",
            "\n",
            "===== FINAL SUMMARY =====\n",
            "Rows after cleaning: 16146\n",
            "Years: 1966 - 2017\n",
            "Number of districts: 311\n",
            "Crops modeled: ['RICE', 'WHEAT', 'MAIZE', 'GROUNDNUT', 'COTTON', 'SUGARCANE']\n",
            "Best model per crop (by MAE_mean across feature sets):\n",
            "  RICE: GradientBoosting (FeatureSet=with_network)\n",
            "  WHEAT: RollingMean3 (FeatureSet=no_network)\n",
            "  MAIZE: Naive (FeatureSet=no_network)\n",
            "  GROUNDNUT: GradientBoosting (FeatureSet=with_network)\n",
            "  SUGARCANE: RandomForest (FeatureSet=with_network)\n",
            "Cleaned dataset with features: /content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\n",
            "Model performance summary: /content/drive/MyDrive/Shiny/ICRISAT/Results/model_performance_summary.csv\n",
            "Supervised panel CSV prefix: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_\n",
            "Key PDF plots saved in OUTPUT_DIR (yield trends, distributions, network overview, diagnostics).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error\n",
        "\n",
        "from statsmodels.tsa.seasonal import STL\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Global config\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Paths (adjust as needed in Colab)\n",
        "DATA_PATH = \"/content/drive/MyDrive/Shiny/ICRISAT/ICRISAT-District Level Data.csv\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Shiny/ICRISAT/Results\"\n",
        "\n",
        "# Network and CV configuration\n",
        "NETWORK_WINDOW_YEARS = 10\n",
        "N_SPLITS = 3\n",
        "MIN_TRAIN_YEARS = 5       # smaller to allow CV within 20082017 window\n",
        "TEST_WINDOW_YEARS = 2\n",
        "\n",
        "\n",
        "def ensure_output_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "\n",
        "\n",
        "def detect_crop_columns(df):\n",
        "    area_cols = [c for c in df.columns if \"AREA (1000 ha)\" in c]\n",
        "    prod_cols = [c for c in df.columns if \"PRODUCTION (1000 tons)\" in c]\n",
        "    yield_cols = [c for c in df.columns if \"YIELD (Kg per ha)\" in c]\n",
        "    crops = {}\n",
        "    for ycol in yield_cols:\n",
        "        crop_name = ycol.replace(\" YIELD (Kg per ha)\", \"\").strip()\n",
        "        area_col = f\"{crop_name} AREA (1000 ha)\"\n",
        "        prod_col = f\"{crop_name} PRODUCTION (1000 tons)\"\n",
        "        crops[crop_name] = {\n",
        "            \"yield\": ycol,\n",
        "            \"area\": area_col if area_col in df.columns else None,\n",
        "            \"prod\": prod_col if prod_col in df.columns else None,\n",
        "        }\n",
        "    return crops, area_cols, prod_cols, yield_cols\n",
        "\n",
        "\n",
        "def load_and_basic_eda(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Replace -1 with NaN in numeric columns\n",
        "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    df[num_cols] = df[num_cols].replace(-1, np.nan)\n",
        "\n",
        "    # Ensure Year as int\n",
        "    if \"Year\" not in df.columns:\n",
        "        raise ValueError(\"Year column not found in dataset.\")\n",
        "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
        "\n",
        "    # Uniqueness of (Dist Code, Year)\n",
        "    if \"Dist Code\" not in df.columns:\n",
        "        raise ValueError(\"Dist Code column not found in dataset.\")\n",
        "    dup_count = df.duplicated(subset=[\"Dist Code\", \"Year\"]).sum()\n",
        "    print(f\"Duplicate (Dist Code, Year) rows: {dup_count}\")\n",
        "    print(\"Key (Dist Code, Year) is unique.\" if dup_count == 0 else \"WARNING: Key (Dist Code, Year) is not unique!\")\n",
        "\n",
        "    # Basic EDA\n",
        "    print(\"\\n===== BASIC EDA =====\")\n",
        "    print(f\"Rows: {len(df)}, Columns: {df.shape[1]}\")\n",
        "    print(f\"Time range: {df['Year'].min()} - {df['Year'].max()}\")\n",
        "    if \"State Name\" in df.columns:\n",
        "        print(f\"Unique States: {df['State Name'].nunique()}\")\n",
        "    if \"Dist Name\" in df.columns:\n",
        "        print(f\"Unique Districts: {df['Dist Name'].nunique()}\")\n",
        "\n",
        "    crops, area_cols, prod_cols, yield_cols = detect_crop_columns(df)\n",
        "    crop_names = list(crops.keys())\n",
        "    print(f\"Detected crops (count={len(crop_names)}): {crop_names[:20]}...\")\n",
        "\n",
        "    # Yield missingness\n",
        "    yield_missing = []\n",
        "    for cname, info in crops.items():\n",
        "        ycol = info[\"yield\"]\n",
        "        missing_pct = df[ycol].isna().mean() * 100.0\n",
        "        yield_missing.append((ycol, missing_pct))\n",
        "    miss_df = pd.DataFrame(yield_missing, columns=[\"YieldColumn\", \"MissingPct\"]).sort_values(\"MissingPct\", ascending=False)\n",
        "    print(\"\\nYield missingness (% of NaN):\")\n",
        "    print(miss_df.head(20))\n",
        "\n",
        "    # Summaries for some key crops\n",
        "    for key in [\"RICE\", \"WHEAT\", \"MAIZE\", \"GROUNDNUT\", \"COTTON\", \"SUGARCANE\"]:\n",
        "        if key in crops:\n",
        "            ycol = crops[key][\"yield\"]\n",
        "            print(f\"\\nSummary for {key} yield:\")\n",
        "            print(df[ycol].describe())\n",
        "\n",
        "    # Simple plots\n",
        "    ensure_output_dir(OUTPUT_DIR)\n",
        "    for key in [\"RICE\", \"WHEAT\"]:\n",
        "        if key in crops:\n",
        "            ycol = crops[key][\"yield\"]\n",
        "            tmp = df.groupby(\"Year\")[ycol].mean().reset_index()\n",
        "            plt.figure(figsize=(8, 4))\n",
        "            plt.plot(tmp[\"Year\"], tmp[ycol], marker=\"o\")\n",
        "            plt.title(f\"Average {key} Yield Over Time\")\n",
        "            plt.xlabel(\"Year\")\n",
        "            plt.ylabel(\"Yield (Kg per ha)\")\n",
        "            plt.tight_layout()\n",
        "            fname = os.path.join(OUTPUT_DIR, f\"avg_yield_{key.lower()}_over_time.pdf\")\n",
        "            plt.savefig(fname)\n",
        "            plt.close()\n",
        "\n",
        "    if \"RICE\" in crops:\n",
        "        ycol = crops[\"RICE\"][\"yield\"]\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        sns.histplot(df[ycol].dropna(), bins=40, kde=True)\n",
        "        plt.title(\"Distribution of RICE Yield\")\n",
        "        plt.xlabel(\"Yield (Kg per ha)\")\n",
        "        plt.tight_layout()\n",
        "        fname = os.path.join(OUTPUT_DIR, \"rice_yield_distribution.pdf\")\n",
        "        plt.savefig(fname)\n",
        "        plt.close()\n",
        "\n",
        "    return df, crops, area_cols, prod_cols, yield_cols\n",
        "\n",
        "\n",
        "def clean_data(df, crops):\n",
        "    print(\"\\n===== CLEANING DATA =====\")\n",
        "    df = df.copy()\n",
        "\n",
        "    # Treat 0 yield with positive area as missing\n",
        "    for crop, info in crops.items():\n",
        "        ycol = info[\"yield\"]\n",
        "        acol = info[\"area\"]\n",
        "        pcol = info[\"prod\"]\n",
        "        if acol is not None and ycol in df.columns:\n",
        "            mask = (df[acol] > 0) & (df[ycol] == 0)\n",
        "            if mask.any():\n",
        "                df.loc[mask, ycol] = np.nan\n",
        "                if pcol is not None and pcol in df.columns:\n",
        "                    df.loc[mask, pcol] = np.nan\n",
        "\n",
        "    # If area <=0, set yield and prod to NaN\n",
        "    for crop, info in crops.items():\n",
        "        ycol = info[\"yield\"]\n",
        "        acol = info[\"area\"]\n",
        "        pcol = info[\"prod\"]\n",
        "        if acol is not None and ycol in df.columns:\n",
        "            mask = (df[acol].fillna(0) <= 0)\n",
        "            df.loc[mask, ycol] = np.nan\n",
        "            if pcol is not None and pcol in df.columns:\n",
        "                df.loc[mask, pcol] = np.nan\n",
        "\n",
        "    # Clip outliers in yields\n",
        "    for crop, info in crops.items():\n",
        "        ycol = info[\"yield\"]\n",
        "        if ycol in df.columns:\n",
        "            series = df[ycol].dropna()\n",
        "            if len(series) < 10:\n",
        "                continue\n",
        "            p1 = series.quantile(0.01)\n",
        "            p99 = series.quantile(0.99)\n",
        "            old_max = series.max()\n",
        "            df[ycol] = df[ycol].clip(lower=p1, upper=p99)\n",
        "            new_max = df[ycol].max()\n",
        "            print(f\"Clipped {crop} yield: old max={old_max:.2f}, new max={new_max:.2f}\")\n",
        "\n",
        "    # Data quality: non-missing fraction by crop\n",
        "    stats = []\n",
        "    for crop, info in crops.items():\n",
        "        ycol = info[\"yield\"]\n",
        "        nonmiss_frac = 1.0 - df[ycol].isna().mean()\n",
        "        stats.append((crop, nonmiss_frac))\n",
        "    qual_df = pd.DataFrame(stats, columns=[\"Crop\", \"NonMissingFrac\"]).sort_values(\"NonMissingFrac\", ascending=False)\n",
        "    print(\"\\nTop 15 crops by non-missing yield fraction:\")\n",
        "    print(qual_df.head(15))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_diversification(df, area_cols):\n",
        "    print(\"\\n===== COMPUTING DIVERSIFICATION =====\")\n",
        "    df = df.copy()\n",
        "\n",
        "    # Total cropped area\n",
        "    df[\"TOTAL_AREA_1000_HA\"] = df[area_cols].clip(lower=0).sum(axis=1, min_count=1)\n",
        "\n",
        "    # Construct shares via concat to avoid fragmentation\n",
        "    share_cols = []\n",
        "    share_data = {}\n",
        "    denom = df[\"TOTAL_AREA_1000_HA\"].replace(0, np.nan)\n",
        "    for col in area_cols:\n",
        "        share_col = col.replace(\" AREA (1000 ha)\", \" AREA_SHARE\")\n",
        "        share_data[share_col] = df[col].clip(lower=0) / denom\n",
        "        share_cols.append(share_col)\n",
        "    share_df = pd.DataFrame(share_data, index=df.index)\n",
        "    share_df = share_df.fillna(0.0)\n",
        "    df = pd.concat([df, share_df], axis=1)\n",
        "\n",
        "    # Herfindahl and diversification\n",
        "    df[\"HERFINDAHL\"] = (df[share_cols] ** 2).sum(axis=1)\n",
        "    df[\"DIVERSIFICATION_INDEX\"] = 1.0 - df[\"HERFINDAHL\"]\n",
        "\n",
        "    # Shannon entropy and crop count\n",
        "    shares_np = df[share_cols].values\n",
        "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "        log_shares = np.where(shares_np > 0, np.log(shares_np), 0.0)\n",
        "    shannon = -np.sum(shares_np * log_shares, axis=1)\n",
        "    active_counts = (shares_np > 0).sum(axis=1)\n",
        "    evenness = np.zeros_like(shannon)\n",
        "    mask = active_counts > 1\n",
        "    evenness[mask] = shannon[mask] / np.log(active_counts[mask])\n",
        "    df[\"SHANNON_ENTROPY\"] = shannon\n",
        "    df[\"CROP_COUNT_ACTIVE\"] = active_counts\n",
        "    df[\"ENTROPY_EVENNESS\"] = evenness\n",
        "\n",
        "    # Example plot for diversification index for few random districts\n",
        "    if \"Dist Code\" in df.columns:\n",
        "        example_codes = df[\"Dist Code\"].dropna().unique()\n",
        "        example_codes = example_codes[:5]\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        for dc in example_codes:\n",
        "            sub = df[df[\"Dist Code\"] == dc].sort_values(\"Year\")\n",
        "            plt.plot(sub[\"Year\"], sub[\"DIVERSIFICATION_INDEX\"], alpha=0.6, label=str(dc))\n",
        "        plt.title(\"Diversification Index over Time (sample districts)\")\n",
        "        plt.xlabel(\"Year\")\n",
        "        plt.ylabel(\"1 - Herfindahl\")\n",
        "        plt.tight_layout()\n",
        "        fname = os.path.join(OUTPUT_DIR, \"diversification_index_over_time_sample_districts.pdf\")\n",
        "        plt.savefig(fname)\n",
        "        plt.close()\n",
        "\n",
        "    return df, share_cols\n",
        "\n",
        "\n",
        "def build_district_network(df, share_cols, k=5):\n",
        "    print(\"\\n===== BUILDING DISTRICT SIMILARITY NETWORK =====\")\n",
        "\n",
        "    # Use most recent NETWORK_WINDOW_YEARS for network computation\n",
        "    max_year = df[\"Year\"].max()\n",
        "    start_win = max(max_year - NETWORK_WINDOW_YEARS + 1, df[\"Year\"].min())\n",
        "    print(f\"Network reference window: {start_win}-{max_year}\")\n",
        "    win_df = df[(df[\"Year\"] >= start_win) & (df[\"Year\"] <= max_year)].copy()\n",
        "\n",
        "    # Compute mean share vector per district\n",
        "    group_cols = [\"Dist Code\"]\n",
        "    mean_shares = win_df.groupby(group_cols)[share_cols].mean()\n",
        "\n",
        "    # Filter districts with nonzero total area in window\n",
        "    keep_mask = mean_shares.sum(axis=1) > 0\n",
        "    mean_shares = mean_shares[keep_mask]\n",
        "    districts = mean_shares.index.tolist()\n",
        "\n",
        "    # Normalize share vectors\n",
        "    X = mean_shares.values\n",
        "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
        "    norms[norms == 0] = 1.0\n",
        "    X_norm = X / norms\n",
        "\n",
        "    # Build k-NN cosine similarity graph\n",
        "    G = nx.Graph()\n",
        "    for dc in districts:\n",
        "        G.add_node(dc)\n",
        "    n = len(districts)\n",
        "    for i in range(n):\n",
        "        sims = X_norm @ X_norm[i, :].T\n",
        "        sims[i] = -1\n",
        "        idx_sorted = np.argsort(sims)[::-1]\n",
        "        neighbors_idx = idx_sorted[:k]\n",
        "        for j in neighbors_idx:\n",
        "            if sims[j] <= 0:\n",
        "                continue\n",
        "            u = districts[i]\n",
        "            v = districts[j]\n",
        "            w = float(sims[j])\n",
        "            if G.has_edge(u, v):\n",
        "                if w > G[u][v][\"weight\"]:\n",
        "                    G[u][v][\"weight\"] = w\n",
        "            else:\n",
        "                G.add_edge(u, v, weight=w)\n",
        "\n",
        "    print(f\"District network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "\n",
        "    # Network metrics\n",
        "    strength = {}\n",
        "    for node in G.nodes():\n",
        "        strength[node] = sum(d[\"weight\"] for _, _, d in G.edges(node, data=True))\n",
        "    try:\n",
        "        betweenness = nx.betweenness_centrality(G, weight=\"weight\", normalized=True)\n",
        "    except Exception:\n",
        "        betweenness = {n: 0.0 for n in G.nodes()}\n",
        "    try:\n",
        "        eigen = nx.eigenvector_centrality(G, weight=\"weight\", max_iter=1000)\n",
        "    except Exception:\n",
        "        eigen = {n: 0.0 for n in G.nodes()}\n",
        "    clustering = nx.clustering(G, weight=\"weight\")\n",
        "    avg_neighbor_deg = nx.average_neighbor_degree(G, weight=\"weight\")\n",
        "\n",
        "    # Community detection\n",
        "    try:\n",
        "        from networkx.algorithms import community\n",
        "        comms = list(community.greedy_modularity_communities(G, weight=\"weight\"))\n",
        "        comm_map = {}\n",
        "        for cid, comm in enumerate(comms):\n",
        "            for node in comm:\n",
        "                comm_map[node] = cid\n",
        "    except Exception:\n",
        "        comm_map = {n: -1 for n in G.nodes()}\n",
        "\n",
        "    metrics_rows = []\n",
        "    for node in G.nodes():\n",
        "        metrics_rows.append(\n",
        "            {\n",
        "                \"Dist Code\": node,\n",
        "                \"NET_STRENGTH\": strength.get(node, 0.0),\n",
        "                \"NET_BETWEENNESS\": betweenness.get(node, 0.0),\n",
        "                \"NET_EIGENVECTOR\": eigen.get(node, 0.0),\n",
        "                \"NET_CLUSTERING\": clustering.get(node, 0.0),\n",
        "                \"NET_AVG_NBR_DEGREE\": avg_neighbor_deg.get(node, 0.0),\n",
        "                \"NET_COMMUNITY\": comm_map.get(node, -1),\n",
        "            }\n",
        "        )\n",
        "    metrics_df = pd.DataFrame(metrics_rows)\n",
        "\n",
        "    # Merge back to all years\n",
        "    df = df.merge(metrics_df, on=\"Dist Code\", how=\"left\")\n",
        "    return df, G, start_win, max_year\n",
        "\n",
        "\n",
        "def build_crop_network(df, area_cols, share_cols):\n",
        "    print(\"\\n===== BUILDING CROP-COOCCURRENCE NETWORK =====\")\n",
        "    G = nx.Graph()\n",
        "\n",
        "    # Crop names from area_cols\n",
        "    crops = []\n",
        "    for col in area_cols:\n",
        "        if col.endswith(\" AREA (1000 ha)\"):\n",
        "            cname = col.replace(\" AREA (1000 ha)\", \"\").strip()\n",
        "            crops.append(cname)\n",
        "    crops = sorted(set(crops))\n",
        "    for c in crops:\n",
        "        G.add_node(c)\n",
        "\n",
        "    if not share_cols:\n",
        "        print(\"No share columns found for crop network.\")\n",
        "        return G, pd.DataFrame()\n",
        "\n",
        "    # Use same reference window as district network for consistency\n",
        "    max_year = df[\"Year\"].max()\n",
        "    start_win = max(max_year - NETWORK_WINDOW_YEARS + 1, df[\"Year\"].min())\n",
        "    win_df = df[(df[\"Year\"] >= start_win) & (df[\"Year\"] <= max_year)].copy()\n",
        "\n",
        "    # For each district, mark crop present if mean share > 0\n",
        "    share_cols_by_crop = {}\n",
        "    for col in share_cols:\n",
        "        cname = col.replace(\" AREA_SHARE\", \"\").replace(\" AREA (1000 ha)\", \"\").strip()\n",
        "        share_cols_by_crop.setdefault(cname, []).append(col)\n",
        "\n",
        "    present = {c: set() for c in crops}\n",
        "    if \"Dist Code\" not in df.columns:\n",
        "        return G, pd.DataFrame()\n",
        "\n",
        "    for dc, sub in win_df.groupby(\"Dist Code\"):\n",
        "        for c in crops:\n",
        "            cols = share_cols_by_crop.get(c, [])\n",
        "            if not cols:\n",
        "                continue\n",
        "            mean_share = sub[cols].mean().sum()\n",
        "            if mean_share > 0:\n",
        "                present[c].add(dc)\n",
        "\n",
        "    for i, ci in enumerate(crops):\n",
        "        for cj in crops[i+1:]:\n",
        "            common = len(present[ci].intersection(present[cj]))\n",
        "            if common > 0:\n",
        "                G.add_edge(ci, cj, weight=float(common))\n",
        "\n",
        "    print(f\"Crop network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "\n",
        "    # Simple crop metrics\n",
        "    try:\n",
        "        eigen = nx.eigenvector_centrality(G, weight=\"weight\", max_iter=1000)\n",
        "    except Exception:\n",
        "        eigen = {n: 0.0 for n in G.nodes()}\n",
        "    degree = dict(G.degree(weight=\"weight\"))\n",
        "    crop_metrics = pd.DataFrame(\n",
        "        [\n",
        "            {\"Crop\": c, \"CROP_DEGREE\": degree.get(c, 0.0), \"CROP_EIGENVECTOR\": eigen.get(c, 0.0)}\n",
        "            for c in crops\n",
        "        ]\n",
        "    )\n",
        "    return G, crop_metrics\n",
        "\n",
        "\n",
        "def add_interaction_features(df):\n",
        "    df = df.copy()\n",
        "    if \"DIVERSIFICATION_INDEX\" in df.columns and \"NET_EIGENVECTOR\" in df.columns:\n",
        "        df[\"DIV_NET_EIGEN\"] = df[\"DIVERSIFICATION_INDEX\"] * df[\"NET_EIGENVECTOR\"]\n",
        "    if \"SHANNON_ENTROPY\" in df.columns and \"NET_STRENGTH\" in df.columns:\n",
        "        df[\"ENTROPY_NET_STRENGTH\"] = df[\"SHANNON_ENTROPY\"] * df[\"NET_STRENGTH\"]\n",
        "    if \"TOTAL_AREA_1000_HA\" in df.columns and \"NET_STRENGTH\" in df.columns:\n",
        "        df[\"AREA_NET_STRENGTH\"] = df[\"TOTAL_AREA_1000_HA\"] * df[\"NET_STRENGTH\"]\n",
        "    return df\n",
        "\n",
        "\n",
        "def rolling_stl_features(series, period=10, min_len=5):\n",
        "    # Leakage-free rolling STL: at each time t, use data up to t only\n",
        "    series = series.sort_index()\n",
        "    trend = pd.Series(index=series.index, dtype=float)\n",
        "    resid = pd.Series(index=series.index, dtype=float)\n",
        "    for i, (idx, _) in enumerate(series.items()):  # .items() instead of deprecated .iteritems()\n",
        "        sub = series.iloc[: i + 1]\n",
        "        if sub.notna().sum() < min_len:\n",
        "            trend.iloc[i] = sub.iloc[-1]\n",
        "            resid.iloc[i] = 0.0\n",
        "        else:\n",
        "            try:\n",
        "                stl = STL(sub, period=min(period, len(sub)), robust=True)\n",
        "                res = stl.fit()\n",
        "                trend.iloc[i] = res.trend.iloc[-1]\n",
        "                resid.iloc[i] = res.resid.iloc[-1]\n",
        "            except Exception:\n",
        "                trend.iloc[i] = sub.iloc[-1]\n",
        "                resid.iloc[i] = 0.0\n",
        "    return trend, resid\n",
        "\n",
        "\n",
        "def construct_supervised_dataset_for_crop(df, crop, crop_info, model_min_year=None):\n",
        "    print(f\"\\n===== BUILDING SUPERVISED DATA FOR {crop} =====\")\n",
        "    ycol = crop_info[\"yield\"]\n",
        "    acol = crop_info[\"area\"]\n",
        "    pcol = crop_info[\"prod\"]\n",
        "\n",
        "    use_df = df.copy()\n",
        "    if model_min_year is not None:\n",
        "        use_df = use_df[use_df[\"Year\"] >= model_min_year].copy()\n",
        "\n",
        "    cols = [\"Dist Code\", \"Year\", \"State Name\", \"Dist Name\", ycol]\n",
        "    if acol is not None:\n",
        "        cols.append(acol)\n",
        "    if pcol is not None:\n",
        "        cols.append(pcol)\n",
        "    for extra in [\"DIVERSIFICATION_INDEX\", \"HERFINDAHL\", \"SHANNON_ENTROPY\", \"CROP_COUNT_ACTIVE\", \"ENTROPY_EVENNESS\",\n",
        "                  \"TOTAL_AREA_1000_HA\", \"NET_STRENGTH\", \"NET_BETWEENNESS\", \"NET_EIGENVECTOR\",\n",
        "                  \"NET_CLUSTERING\", \"NET_AVG_NBR_DEGREE\", \"NET_COMMUNITY\",\n",
        "                  \"DIV_NET_EIGEN\", \"ENTROPY_NET_STRENGTH\", \"AREA_NET_STRENGTH\"]:\n",
        "        if extra in use_df.columns:\n",
        "            cols.append(extra)\n",
        "\n",
        "    sub = use_df[cols].dropna(subset=[\"Dist Code\", \"Year\"])\n",
        "    sub = sub.sort_values([\"Dist Code\", \"Year\"]).reset_index(drop=True)\n",
        "\n",
        "    def process_group(g):\n",
        "        g = g.sort_values(\"Year\").copy()\n",
        "        y = g[ycol]\n",
        "\n",
        "        # Lag features\n",
        "        g[f\"{crop}_Y_LAG1\"] = y.shift(1)\n",
        "        g[f\"{crop}_Y_LAG2\"] = y.shift(2)\n",
        "\n",
        "        # Rolling stats\n",
        "        g[f\"{crop}_Y_ROLL_MEAN3\"] = y.rolling(window=3, min_periods=3).mean()\n",
        "        g[f\"{crop}_Y_ROLL_STD3\"] = y.rolling(window=3, min_periods=3).std()\n",
        "        g[f\"{crop}_Y_ROLL_CV3\"] = g[f\"{crop}_Y_ROLL_STD3\"] / (g[f\"{crop}_Y_ROLL_MEAN3\"].abs() + 1e-6)\n",
        "\n",
        "        # Relative changes and shock flags\n",
        "        g[f\"{crop}_Y_DIFF1\"] = y - y.shift(1)\n",
        "        g[f\"{crop}_Y_REL_CHANGE1\"] = g[f\"{crop}_Y_DIFF1\"] / (y.shift(1).abs() + 1e-6)\n",
        "        g[f\"{crop}_Y_SHOCK_FLAG\"] = (g[f\"{crop}_Y_REL_CHANGE1\"].abs() > 0.3).astype(float)\n",
        "\n",
        "        if acol is not None and acol in g.columns:\n",
        "            a = g[acol]\n",
        "            g[f\"{crop}_A_LAG1\"] = a.shift(1)\n",
        "            g[f\"{crop}_A_DIFF1\"] = a - a.shift(1)\n",
        "            g[f\"{crop}_A_REL_CHANGE1\"] = g[f\"{crop}_A_DIFF1\"] / (a.shift(1).abs() + 1e-6)\n",
        "        if pcol is not None and pcol in g.columns:\n",
        "            p = g[pcol]\n",
        "            g[f\"{crop}_P_LAG1\"] = p.shift(1)\n",
        "\n",
        "        # Time index\n",
        "        year0 = g[\"Year\"].min()\n",
        "        g[\"YEAR_CENTERED\"] = g[\"Year\"] - year0\n",
        "        g[\"YEAR_CENTERED_SQ\"] = g[\"YEAR_CENTERED\"] ** 2\n",
        "\n",
        "        # STL decomposition features on yield\n",
        "        y_series = g.set_index(\"Year\")[ycol].dropna()\n",
        "        if len(y_series) > 0:\n",
        "            trend, resid = rolling_stl_features(y_series, period=10, min_len=5)\n",
        "            g = g.set_index(\"Year\")\n",
        "            g[f\"{crop}_STL_TREND\"] = trend\n",
        "            g[f\"{crop}_STL_RESID\"] = resid\n",
        "            g = g.reset_index()\n",
        "        else:\n",
        "            g[f\"{crop}_STL_TREND\"] = np.nan\n",
        "            g[f\"{crop}_STL_RESID\"] = np.nan\n",
        "\n",
        "        # Target: next-year yield\n",
        "        g[\"TARGET_YIELD_NEXT\"] = y.shift(-1)\n",
        "        return g\n",
        "\n",
        "    sup = sub.groupby(\"Dist Code\", group_keys=False).apply(process_group)\n",
        "    sup = sup.dropna(subset=[\"TARGET_YIELD_NEXT\",\n",
        "                             f\"{crop}_Y_LAG1\", f\"{crop}_Y_LAG2\",\n",
        "                             f\"{crop}_Y_ROLL_MEAN3\", f\"{crop}_Y_ROLL_STD3\",\n",
        "                             f\"{crop}_Y_ROLL_CV3\"])\n",
        "    sup = sup.dropna(axis=0, how=\"any\", subset=[ycol])\n",
        "\n",
        "    out_path = os.path.join(OUTPUT_DIR, f\"supervised_panel_{crop.lower()}.csv\")\n",
        "    sup.to_csv(out_path, index=False)\n",
        "    print(f\"Saved supervised panel for {crop} to: {out_path}\")\n",
        "    return sup, ycol\n",
        "\n",
        "\n",
        "def time_series_cv_splits(years, n_splits=3, min_train_years=5, test_window_years=2):\n",
        "    unique_years = np.sort(years.unique())\n",
        "    if len(unique_years) < (min_train_years + test_window_years):\n",
        "        raise ValueError(\"Not enough years to build the requested time-series CV splits.\")\n",
        "\n",
        "    splits = []\n",
        "    start_idx = 0\n",
        "    for split_id in range(n_splits):\n",
        "        train_end_idx = min(start_idx + min_train_years + split_id * test_window_years - 1,\n",
        "                            len(unique_years) - test_window_years - 1)\n",
        "        train_end_year = unique_years[train_end_idx]\n",
        "        test_start_idx = train_end_idx + 1\n",
        "        test_end_idx = min(test_start_idx + test_window_years - 1, len(unique_years) - 1)\n",
        "        test_start_year = unique_years[test_start_idx]\n",
        "        test_end_year = unique_years[test_end_idx]\n",
        "\n",
        "        train_mask = years <= train_end_year\n",
        "        test_mask = (years >= test_start_year) & (years <= test_end_year)\n",
        "\n",
        "        if train_mask.sum() == 0 or test_mask.sum() == 0:\n",
        "            continue\n",
        "        splits.append((np.where(train_mask)[0], np.where(test_mask)[0]))\n",
        "    return splits\n",
        "\n",
        "\n",
        "def compute_metrics(y_true, y_pred, mape_threshold=100.0):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    # MAPE only on sufficiently large true values\n",
        "    mask = np.abs(y_true) >= mape_threshold\n",
        "    if mask.any():\n",
        "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) /\n",
        "                              np.clip(np.abs(y_true[mask]), 1e-6, None))) * 100.0\n",
        "    else:\n",
        "        mape = np.nan\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    medae = median_absolute_error(y_true, y_pred)\n",
        "    return mae, rmse, mape, r2, medae\n",
        "\n",
        "\n",
        "def evaluate_models_for_crop(sup, crop, yield_col, include_network_features=True, feature_set_name=\"with_network\"):\n",
        "    print(f\"\\n===== MODELING {crop} | Feature set: {feature_set_name} =====\")\n",
        "    sup = sup.copy()\n",
        "\n",
        "    # Define feature columns\n",
        "    exclude_cols = [\"TARGET_YIELD_NEXT\", yield_col, \"Dist Code\", \"State Name\", \"Dist Name\"]\n",
        "    feature_cols = [c for c in sup.columns if c not in exclude_cols]\n",
        "\n",
        "    # Drop non-numeric features\n",
        "    non_numeric = sup[feature_cols].select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "    feature_cols = [c for c in feature_cols if c not in non_numeric]\n",
        "\n",
        "    # Remove network-based features if doing ablation\n",
        "    if not include_network_features:\n",
        "        feature_cols = [c for c in feature_cols if not (c.startswith(\"NET_\") or c.startswith(\"CROP_\") or c.startswith(\"DIV_NET\"))]\n",
        "\n",
        "    if not feature_cols:\n",
        "        print(f\"No usable numeric features for {crop} with feature set {feature_set_name}.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    X = sup[feature_cols].values\n",
        "    years = sup[\"Year\"].values\n",
        "    y = sup[\"TARGET_YIELD_NEXT\"].values\n",
        "\n",
        "    try:\n",
        "        splits = time_series_cv_splits(pd.Series(years), n_splits=N_SPLITS,\n",
        "                                       min_train_years=MIN_TRAIN_YEARS,\n",
        "                                       test_window_years=TEST_WINDOW_YEARS)\n",
        "    except ValueError as e:\n",
        "        print(f\"Time-series CV error for {crop} ({feature_set_name}): {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    if not splits:\n",
        "        print(f\"Not enough temporal coverage for time-series CV for {crop}.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    models = {\n",
        "        \"Naive\": None,\n",
        "        \"RollingMean3\": None,\n",
        "        \"Ridge\": Pipeline([\n",
        "            (\"scaler\", RobustScaler()),\n",
        "            (\"model\", Ridge(alpha=5.0, random_state=RANDOM_STATE))\n",
        "        ]),\n",
        "        \"RandomForest\": Pipeline([\n",
        "            (\"scaler\", RobustScaler()),\n",
        "            (\"model\", RandomForestRegressor(\n",
        "                n_estimators=200,\n",
        "                max_depth=7,\n",
        "                random_state=RANDOM_STATE,\n",
        "                n_jobs=-1\n",
        "            ))\n",
        "        ]),\n",
        "        \"GradientBoosting\": Pipeline([\n",
        "            (\"scaler\", RobustScaler()),\n",
        "            (\"model\", GradientBoostingRegressor(\n",
        "                n_estimators=300,\n",
        "                learning_rate=0.05,\n",
        "                max_depth=3,\n",
        "                random_state=RANDOM_STATE\n",
        "            ))\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    records = []\n",
        "    for model_name, model in models.items():\n",
        "        fold_metrics = []\n",
        "        for fold_id, (train_idx, test_idx) in enumerate(splits, start=1):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "            sup_test = sup.iloc[test_idx]\n",
        "\n",
        "            if model_name == \"Naive\":\n",
        "                # Predict next-year yield as current-year yield\n",
        "                y_pred = sup_test[yield_col].values\n",
        "            elif model_name == \"RollingMean3\":\n",
        "                # Predict next-year as mean of last 3 years\n",
        "                y_t = sup_test[yield_col].values\n",
        "                y_lag1 = sup_test[f\"{crop}_Y_LAG1\"].values\n",
        "                y_lag2 = sup_test[f\"{crop}_Y_LAG2\"].values\n",
        "                stack = np.vstack([y_t, y_lag1, y_lag2])\n",
        "                y_pred = np.nanmean(stack, axis=0)\n",
        "            else:\n",
        "                model.fit(X_train, y_train)\n",
        "                y_pred = model.predict(X_test)\n",
        "\n",
        "            mae, rmse, mape, r2, medae = compute_metrics(y_test, y_pred)\n",
        "            fold_metrics.append((mae, rmse, mape, r2, medae))\n",
        "            print(f\"{crop} | {model_name} | {feature_set_name} | Fold {fold_id}: MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "\n",
        "        if not fold_metrics:\n",
        "            continue\n",
        "        maes, rmses, mapes, r2s, medaes = zip(*fold_metrics)\n",
        "        records.append({\n",
        "            \"Crop\": crop,\n",
        "            \"Model\": model_name,\n",
        "            \"FeatureSet\": feature_set_name,\n",
        "            \"MAE_mean\": float(np.mean(maes)),\n",
        "            \"MAE_std\": float(np.std(maes)),\n",
        "            \"RMSE_mean\": float(np.mean(rmses)),\n",
        "            \"RMSE_std\": float(np.std(rmses)),\n",
        "            \"MAPE_mean\": float(np.nanmean(mapes)),\n",
        "            \"MAPE_std\": float(np.nanstd(mapes)),\n",
        "            \"MedAE_mean\": float(np.mean(medaes)),\n",
        "            \"MedAE_std\": float(np.std(medaes)),\n",
        "            \"R2_mean\": float(np.mean(r2s)),\n",
        "            \"R2_std\": float(np.std(r2s)),\n",
        "        })\n",
        "\n",
        "    perf_df = pd.DataFrame(records)\n",
        "    if not perf_df.empty:\n",
        "        print(f\"\\nPerformance summary for {crop} ({feature_set_name}):\")\n",
        "        print(perf_df.sort_values(\"MAE_mean\").reset_index(drop=True))\n",
        "    return perf_df\n",
        "\n",
        "\n",
        "def plot_district_network(G):\n",
        "    if G is None or G.number_of_nodes() == 0:\n",
        "        return\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    pos = nx.spring_layout(G, seed=RANDOM_STATE, k=0.15)\n",
        "    degrees = dict(G.degree())\n",
        "    node_sizes = np.array(list(degrees.values()), dtype=float)\n",
        "    node_sizes = 100 + 300 * (node_sizes - node_sizes.min()) / (node_sizes.max() - node_sizes.min() + 1e-6)\n",
        "    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, alpha=0.7)\n",
        "    nx.draw_networkx_edges(G, pos, width=0.3, alpha=0.3)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"District Similarity Network (spring layout)\")\n",
        "    plt.tight_layout()\n",
        "    fname = os.path.join(OUTPUT_DIR, \"district_network_overview.pdf\")\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def diagnostic_plots_for_crop(sup, crop, yield_col, best_model_name, include_network_features=True):\n",
        "    print(f\"\\n===== DIAGNOSTIC PLOTS FOR {crop} ({best_model_name}, feature set={'with' if include_network_features else 'no'} network) =====\")\n",
        "    sup = sup.copy()\n",
        "\n",
        "    exclude_cols = [\"TARGET_YIELD_NEXT\", yield_col, \"Dist Code\", \"State Name\", \"Dist Name\"]\n",
        "    feature_cols = [c for c in sup.columns if c not in exclude_cols]\n",
        "    non_numeric = sup[feature_cols].select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "    feature_cols = [c for c in feature_cols if c not in non_numeric]\n",
        "    if not include_network_features:\n",
        "        feature_cols = [c for c in feature_cols if not (c.startswith(\"NET_\") or c.startswith(\"CROP_\") or c.startswith(\"DIV_NET\"))]\n",
        "    if not feature_cols:\n",
        "        print(\"No features available for diagnostics.\")\n",
        "        return\n",
        "\n",
        "    X = sup[feature_cols].values\n",
        "    years = sup[\"Year\"].values\n",
        "    y = sup[\"TARGET_YIELD_NEXT\"].values\n",
        "    try:\n",
        "        splits = time_series_cv_splits(pd.Series(years), n_splits=N_SPLITS,\n",
        "                                       min_train_years=MIN_TRAIN_YEARS,\n",
        "                                       test_window_years=TEST_WINDOW_YEARS)\n",
        "    except ValueError as e:\n",
        "        print(f\"Time-series CV error for diagnostics ({crop}): {e}\")\n",
        "        return\n",
        "\n",
        "    if not splits:\n",
        "        print(\"Not enough temporal coverage for diagnostics.\")\n",
        "        return\n",
        "\n",
        "    # Use last split as \"final validation\"\n",
        "    train_idx, test_idx = splits[-1]\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "    sup_test = sup.iloc[test_idx]\n",
        "\n",
        "    if best_model_name == \"Naive\":\n",
        "        y_pred = sup_test[yield_col].values\n",
        "    elif best_model_name == \"RollingMean3\":\n",
        "        y_t = sup_test[yield_col].values\n",
        "        y_lag1 = sup_test[f\"{crop}_Y_LAG1\"].values\n",
        "        y_lag2 = sup_test[f\"{crop}_Y_LAG2\"].values\n",
        "        stack = np.vstack([y_t, y_lag1, y_lag2])\n",
        "        y_pred = np.nanmean(stack, axis=0)\n",
        "    else:\n",
        "        if best_model_name == \"Ridge\":\n",
        "            model = Pipeline([\n",
        "                (\"scaler\", RobustScaler()),\n",
        "                (\"model\", Ridge(alpha=5.0, random_state=RANDOM_STATE))\n",
        "            ])\n",
        "        elif best_model_name == \"RandomForest\":\n",
        "            model = Pipeline([\n",
        "                (\"scaler\", RobustScaler()),\n",
        "                (\"model\", RandomForestRegressor(\n",
        "                    n_estimators=200,\n",
        "                    max_depth=7,\n",
        "                    random_state=RANDOM_STATE,\n",
        "                    n_jobs=-1\n",
        "                ))\n",
        "            ])\n",
        "        else:\n",
        "            model = Pipeline([\n",
        "                (\"scaler\", RobustScaler()),\n",
        "                (\"model\", GradientBoostingRegressor(\n",
        "                    n_estimators=300,\n",
        "                    learning_rate=0.05,\n",
        "                    max_depth=3,\n",
        "                    random_state=RANDOM_STATE\n",
        "                ))\n",
        "            ])\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    # Scatter true vs predicted\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.scatter(y_test, y_pred, alpha=0.4)\n",
        "    lims = [min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())]\n",
        "    plt.plot(lims, lims, \"r--\", linewidth=1)\n",
        "    plt.xlabel(\"True Yield\")\n",
        "    plt.ylabel(\"Predicted Yield\")\n",
        "    plt.title(f\"{crop}: True vs Predicted Yield ({best_model_name})\")\n",
        "    plt.tight_layout()\n",
        "    fname = os.path.join(OUTPUT_DIR, f\"{crop.lower()}_yield_true_vs_pred_{best_model_name}.pdf\")\n",
        "    plt.savefig(fname)\n",
        "    plt.close()\n",
        "\n",
        "    # Time-series for a few example districts\n",
        "    example_dists = sup_test[\"Dist Code\"].dropna().unique()[:3]\n",
        "    for dc in example_dists:\n",
        "        sub_idx = sup_test[\"Dist Code\"] == dc\n",
        "        sub_y_true = y_test[sub_idx]\n",
        "        sub_y_pred = y_pred[sub_idx]\n",
        "        sub_years = sup_test.loc[sub_idx, \"Year\"].values\n",
        "        order = np.argsort(sub_years)\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.plot(sub_years[order], sub_y_true[order], marker=\"o\", label=\"True\")\n",
        "        plt.plot(sub_years[order], sub_y_pred[order], marker=\"x\", label=\"Predicted\")\n",
        "        plt.title(f\"{crop} Yield over Time (Dist Code={dc})\")\n",
        "        plt.xlabel(\"Year\")\n",
        "        plt.ylabel(\"Yield\")\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        fname = os.path.join(OUTPUT_DIR, f\"{crop.lower()}_yield_timeseries_dist_{dc}_{best_model_name}.pdf\")\n",
        "        plt.savefig(fname)\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "def main():\n",
        "    ensure_output_dir(OUTPUT_DIR)\n",
        "\n",
        "    df, crops, area_cols, prod_cols, yield_cols = load_and_basic_eda(DATA_PATH)\n",
        "    df = clean_data(df, crops)\n",
        "    df, share_cols = compute_diversification(df, area_cols)\n",
        "    df, district_graph, net_start_year, net_end_year = build_district_network(df, share_cols, k=5)\n",
        "    crop_graph, crop_metrics = build_crop_network(df, area_cols, share_cols)\n",
        "    df = add_interaction_features(df)\n",
        "    plot_district_network(district_graph)\n",
        "\n",
        "    # Restrict modeling window to avoid temporal leakage from network features\n",
        "    model_min_year = net_start_year\n",
        "\n",
        "    # Major crops\n",
        "    target_crops = [\"RICE\", \"WHEAT\", \"MAIZE\", \"GROUNDNUT\", \"COTTON\", \"SUGARCANE\"]\n",
        "    all_perf = []\n",
        "    best_models_per_crop = {}\n",
        "    modeled_crops = []\n",
        "\n",
        "    # Save cleaned dataset with features\n",
        "    cleaned_path = os.path.join(OUTPUT_DIR, \"icrisat_cleaned_with_features.csv\")\n",
        "    df.to_csv(cleaned_path, index=False)\n",
        "    print(f\"\\nSaved cleaned dataset with features to: {cleaned_path}\")\n",
        "\n",
        "    for crop in target_crops:\n",
        "        if crop not in crops:\n",
        "            print(f\"Crop {crop} not found in dataset; skipping.\")\n",
        "            continue\n",
        "\n",
        "        sup, ycol = construct_supervised_dataset_for_crop(df, crop, crops[crop], model_min_year=model_min_year)\n",
        "        if sup.empty:\n",
        "            print(f\"No supervised data for {crop}; skipping modeling.\")\n",
        "            continue\n",
        "\n",
        "        modeled_crops.append(crop)\n",
        "\n",
        "        # Evaluate without network features (ablation)\n",
        "        perf_no_net = evaluate_models_for_crop(sup, crop, ycol,\n",
        "                                               include_network_features=False,\n",
        "                                               feature_set_name=\"no_network\")\n",
        "        # Evaluate with full feature set (including network)\n",
        "        perf_with_net = evaluate_models_for_crop(sup, crop, ycol,\n",
        "                                                 include_network_features=True,\n",
        "                                                 feature_set_name=\"with_network\")\n",
        "        perf_crop = pd.concat([perf_no_net, perf_with_net], ignore_index=True)\n",
        "        all_perf.append(perf_crop)\n",
        "\n",
        "        # Select best model based on MAE_mean (across all feature sets)\n",
        "        if not perf_crop.empty:\n",
        "            best_row = perf_crop.sort_values(\"MAE_mean\").iloc[0]\n",
        "            best_models_per_crop[crop] = (best_row[\"Model\"], best_row[\"FeatureSet\"])\n",
        "            print(f\"Best model for {crop}: {best_row['Model']} (FeatureSet={best_row['FeatureSet']}), MAE_mean={best_row['MAE_mean']:.2f}\")\n",
        "\n",
        "        # Diagnostics for the best configuration\n",
        "        if crop in best_models_per_crop:\n",
        "            best_model_name, best_feat_set = best_models_per_crop[crop]\n",
        "            include_net = (best_feat_set == \"with_network\")\n",
        "            diagnostic_plots_for_crop(sup, crop, ycol, best_model_name, include_network_features=include_net)\n",
        "\n",
        "    if all_perf:\n",
        "        perf_all = pd.concat(all_perf, ignore_index=True)\n",
        "        perf_path = os.path.join(OUTPUT_DIR, \"model_performance_summary.csv\")\n",
        "        perf_all.to_csv(perf_path, index=False)\n",
        "        print(f\"\\nSaved model performance summary to: {perf_path}\")\n",
        "    else:\n",
        "        perf_all = pd.DataFrame()\n",
        "        perf_path = \"\"\n",
        "\n",
        "    # Final summary\n",
        "    print(\"\\n===== FINAL SUMMARY =====\")\n",
        "    print(f\"Rows after cleaning: {len(df)}\")\n",
        "    print(f\"Years: {df['Year'].min()} - {df['Year'].max()}\")\n",
        "    if 'Dist Name' in df.columns:\n",
        "        print(f\"Number of districts: {df['Dist Name'].nunique()}\")\n",
        "    else:\n",
        "        print(f\"Number of districts: {df['Dist Code'].nunique()}\")\n",
        "    print(f\"Crops modeled: {modeled_crops}\")\n",
        "    if best_models_per_crop:\n",
        "        print(\"Best model per crop (by MAE_mean across feature sets):\")\n",
        "        for crop, (model_name, feat_set) in best_models_per_crop.items():\n",
        "            print(f\"  {crop}: {model_name} (FeatureSet={feat_set})\")\n",
        "    print(f\"Cleaned dataset with features: {cleaned_path}\")\n",
        "    if not perf_all.empty:\n",
        "        print(f\"Model performance summary: {perf_path}\")\n",
        "    print(f\"Supervised panel CSV prefix: {os.path.join(OUTPUT_DIR, 'supervised_panel_')}\")\n",
        "    print(\"Key PDF plots saved in OUTPUT_DIR (yield trends, distributions, network overview, diagnostics).\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwkBFHLyj4JP",
        "outputId": "0e2ec9ae-2e06-47ca-a560-b6ab0b9bac0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicate (Dist Code, Year) rows: 0\n",
            "Key (Dist Code, Year) is unique.\n",
            "\n",
            "===== BASIC EDA =====\n",
            "Rows: 16146, Columns: 80\n",
            "Time range: 1966 - 2017\n",
            "Unique States: 20\n",
            "Unique Districts: 311\n",
            "Detected crops (count=23): ['BARLEY', 'CASTOR', 'CHICKPEA', 'COTTON', 'FINGER MILLET', 'GROUNDNUT', 'KHARIF SORGHUM', 'LINSEED', 'MAIZE', 'MINOR PULSES', 'OILSEEDS', 'PEARL MILLET', 'PIGEONPEA', 'RABI SORGHUM', 'RAPESEED AND MUSTARD', 'RICE', 'SAFFLOWER', 'SESAMUM', 'SORGHUM', 'SOYABEAN']...\n",
            "\n",
            "Yield missingness (% of NaN):\n",
            "                               YieldColumn  MissingPct\n",
            "0                   RICE YIELD (Kg per ha)         0.0\n",
            "1                  WHEAT YIELD (Kg per ha)         0.0\n",
            "2         KHARIF SORGHUM YIELD (Kg per ha)         0.0\n",
            "3           RABI SORGHUM YIELD (Kg per ha)         0.0\n",
            "4                SORGHUM YIELD (Kg per ha)         0.0\n",
            "5           PEARL MILLET YIELD (Kg per ha)         0.0\n",
            "6                  MAIZE YIELD (Kg per ha)         0.0\n",
            "7          FINGER MILLET YIELD (Kg per ha)         0.0\n",
            "8                 BARLEY YIELD (Kg per ha)         0.0\n",
            "9               CHICKPEA YIELD (Kg per ha)         0.0\n",
            "10             PIGEONPEA YIELD (Kg per ha)         0.0\n",
            "11          MINOR PULSES YIELD (Kg per ha)         0.0\n",
            "12             GROUNDNUT YIELD (Kg per ha)         0.0\n",
            "13               SESAMUM YIELD (Kg per ha)         0.0\n",
            "14  RAPESEED AND MUSTARD YIELD (Kg per ha)         0.0\n",
            "15             SAFFLOWER YIELD (Kg per ha)         0.0\n",
            "16                CASTOR YIELD (Kg per ha)         0.0\n",
            "17               LINSEED YIELD (Kg per ha)         0.0\n",
            "18             SUNFLOWER YIELD (Kg per ha)         0.0\n",
            "19              SOYABEAN YIELD (Kg per ha)         0.0\n",
            "\n",
            "Summary for RICE yield:\n",
            "count    16146.000000\n",
            "mean      1486.924784\n",
            "std        956.185281\n",
            "min         -1.000000\n",
            "25%        800.000000\n",
            "50%       1333.210000\n",
            "75%       2113.517500\n",
            "max       5653.830000\n",
            "Name: RICE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for WHEAT yield:\n",
            "count    16146.000000\n",
            "mean      1492.419859\n",
            "std       1081.255367\n",
            "min         -1.000000\n",
            "25%        750.000000\n",
            "50%       1347.450000\n",
            "75%       2131.580000\n",
            "max       5541.520000\n",
            "Name: WHEAT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for MAIZE yield:\n",
            "count    16146.000000\n",
            "mean      1408.763218\n",
            "std       1191.694627\n",
            "min         -1.000000\n",
            "25%        696.890000\n",
            "50%       1159.065000\n",
            "75%       1863.640000\n",
            "max      21428.570000\n",
            "Name: MAIZE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for GROUNDNUT yield:\n",
            "count    16146.000000\n",
            "mean       765.947652\n",
            "std        627.713820\n",
            "min         -1.000000\n",
            "25%          0.000000\n",
            "50%        774.410000\n",
            "75%       1085.037500\n",
            "max       8500.000000\n",
            "Name: GROUNDNUT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for COTTON yield:\n",
            "count    16146.000000\n",
            "mean       124.644823\n",
            "std        207.681147\n",
            "min         -1.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%        202.270000\n",
            "max       5000.000000\n",
            "Name: COTTON YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for SUGARCANE yield:\n",
            "count    16146.00000\n",
            "mean      4500.15306\n",
            "std       3153.97042\n",
            "min         -1.00000\n",
            "25%       2000.00000\n",
            "50%       4502.21000\n",
            "75%       6704.60500\n",
            "max      22062.30000\n",
            "Name: SUGARCANE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "===== CLEANING DATA =====\n",
            "Clipped RICE yield: old max=5653.83, new max=4104.54\n",
            "Clipped WHEAT yield: old max=5541.52, new max=4484.85\n",
            "Clipped KHARIF SORGHUM yield: old max=6531.25, new max=2269.55\n",
            "Clipped RABI SORGHUM yield: old max=10000.00, new max=2333.33\n",
            "Clipped SORGHUM yield: old max=5742.59, new max=2226.14\n",
            "Clipped PEARL MILLET yield: old max=10000.00, new max=2321.72\n",
            "Clipped MAIZE yield: old max=21428.57, new max=5897.88\n",
            "Clipped FINGER MILLET yield: old max=9286.86, new max=2191.11\n",
            "Clipped BARLEY yield: old max=14441.86, new max=3493.78\n",
            "Clipped CHICKPEA yield: old max=58363.64, new max=1727.27\n",
            "Clipped PIGEONPEA yield: old max=12402.60, new max=2123.75\n",
            "Clipped MINOR PULSES yield: old max=18888.89, new max=1810.89\n",
            "Clipped GROUNDNUT yield: old max=8500.00, new max=2541.27\n",
            "Clipped SESAMUM yield: old max=6625.00, new max=1000.00\n",
            "Clipped RAPESEED AND MUSTARD yield: old max=10000.00, new max=1771.47\n",
            "Clipped SAFFLOWER yield: old max=4166.67, new max=1000.00\n",
            "Clipped CASTOR yield: old max=4600.00, new max=2000.00\n",
            "Clipped LINSEED yield: old max=7000.00, new max=1000.00\n",
            "Clipped SUNFLOWER yield: old max=4282.05, new max=2000.00\n",
            "Clipped SOYABEAN yield: old max=3884.06, new max=1826.50\n",
            "Clipped OILSEEDS yield: old max=25500.00, new max=1991.55\n",
            "Clipped SUGARCANE yield: old max=22062.30, new max=12000.00\n",
            "Clipped COTTON yield: old max=5000.00, new max=740.30\n",
            "\n",
            "===== COMPUTING DIVERSIFICATION =====\n",
            "\n",
            "===== BUILDING DISTRICT SIMILARITY NETWORK =====\n",
            "Network reference window: 2008-2017\n",
            "District network: 311 nodes, 1511 edges\n",
            "\n",
            "===== BUILDING CROP-COOCCURRENCE NETWORK =====\n",
            "Crop network: 23 nodes, 231 edges\n",
            "\n",
            "Saved cleaned dataset with features to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/icrisat_cleaned_with_features.csv\n",
            "\n",
            "Saved supervised panel for RICE to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/supervised_panel_rice.csv\n",
            "\n",
            "===== MODELING RICE =====\n",
            "RICE | Naive | no_network | Fold 1: MAE=252.27, RMSE=379.11, MAPE=84.44, MedAE=170.01, R2=0.803\n",
            "RICE | RollingMean3 | no_network | Fold 1: MAE=239.07, RMSE=348.30, MAPE=84.31, MedAE=168.44, R2=0.833\n",
            "RICE | Ridge | no_network | Fold 1: MAE=235.77, RMSE=339.82, MAPE=89.65, MedAE=159.27, R2=0.841\n",
            "RICE | RandomForest | no_network | Fold 1: MAE=236.68, RMSE=342.97, MAPE=56.09, MedAE=165.90, R2=0.838\n",
            "RICE | GradientBoosting | no_network | Fold 1: MAE=237.26, RMSE=339.69, MAPE=41.68, MedAE=166.46, R2=0.842\n",
            "RICE | Naive | no_network | Fold 2: MAE=278.92, RMSE=411.95, MAPE=23.52, MedAE=181.63, R2=0.819\n",
            "RICE | RollingMean3 | no_network | Fold 2: MAE=248.22, RMSE=360.24, MAPE=21.17, MedAE=166.67, R2=0.862\n",
            "RICE | Ridge | no_network | Fold 2: MAE=250.12, RMSE=357.12, MAPE=21.91, MedAE=167.09, R2=0.864\n",
            "RICE | RandomForest | no_network | Fold 2: MAE=244.13, RMSE=345.31, MAPE=23.01, MedAE=169.38, R2=0.873\n",
            "RICE | GradientBoosting | no_network | Fold 2: MAE=239.12, RMSE=337.93, MAPE=21.32, MedAE=166.00, R2=0.878\n",
            "RICE | Naive | no_network | Fold 3: MAE=286.32, RMSE=465.11, MAPE=19.79, MedAE=162.23, R2=0.817\n",
            "RICE | RollingMean3 | no_network | Fold 3: MAE=279.12, RMSE=422.71, MAPE=18.85, MedAE=182.78, R2=0.849\n",
            "RICE | Ridge | no_network | Fold 3: MAE=275.19, RMSE=413.00, MAPE=18.75, MedAE=176.54, R2=0.856\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "from itertools import combinations\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# CONFIG\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/Shiny/ICRISAT/ICRISAT-District Level Data.csv\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Shiny/ICRISAT/Results1\"\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "PLOT_DPI = 150\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# UTILS\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def compute_regression_metrics(y_true, y_pred):\n",
        "    \"\"\"Return MAE, RMSE, MAPE (%), median AE, R2.\"\"\"\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    # Safe MAPE (ignore zeros in denominator)\n",
        "    denom = np.where(y_true == 0, np.nan, np.abs(y_true))\n",
        "    mape = np.nanmean(np.abs(y_true - y_pred) / denom) * 100\n",
        "    medae = np.median(np.abs(y_true - y_pred))\n",
        "    try:\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "    except ValueError:\n",
        "        r2 = np.nan\n",
        "    return mae, rmse, mape, medae, r2\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# DATA LOADING & EDA\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def load_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "    if \"Year\" not in df.columns:\n",
        "        raise ValueError(\"Expected 'Year' column in data.\")\n",
        "    if \"Dist Code\" not in df.columns:\n",
        "        raise ValueError(\"Expected 'Dist Code' column in data.\")\n",
        "    df[\"Year\"] = df[\"Year\"].astype(int)\n",
        "    return df\n",
        "\n",
        "def get_yield_columns_and_crops(df):\n",
        "    \"\"\"Detect yield columns and infer crop names from them.\"\"\"\n",
        "    yield_cols = [c for c in df.columns if \"YIELD\" in c.upper()]\n",
        "    crop_to_yield = {}\n",
        "    for col in yield_cols:\n",
        "        # Example: \"RICE YIELD (Kg per ha)\" -> \"RICE\"\n",
        "        up = col.upper()\n",
        "        crop_part = up.split(\"YIELD\")[0]\n",
        "        crop_part = crop_part.replace(\"(KG PER HA)\", \"\")\n",
        "        crop_part = crop_part.strip()\n",
        "        crop_name = \" \".join(crop_part.split())\n",
        "        crop_to_yield[crop_name] = col\n",
        "    crops = sorted(crop_to_yield.keys())\n",
        "    return yield_cols, crops, crop_to_yield\n",
        "\n",
        "def infer_area_columns(df, crop_to_yield):\n",
        "    \"\"\"Map each crop to its likely AREA column.\"\"\"\n",
        "    crop_to_area = {}\n",
        "    for crop in crop_to_yield.keys():\n",
        "        up_crop = crop.upper()\n",
        "        candidates = [c for c in df.columns if up_crop in c.upper() and \"AREA\" in c.upper()]\n",
        "        if candidates:\n",
        "            # pick the first candidate\n",
        "            crop_to_area[crop] = candidates[0]\n",
        "    return crop_to_area\n",
        "\n",
        "def basic_eda(df):\n",
        "    print(\"Duplicate (Dist Code, Year) rows:\", df.duplicated(subset=[\"Dist Code\", \"Year\"]).sum())\n",
        "    if df.duplicated(subset=[\"Dist Code\", \"Year\"]).sum() == 0:\n",
        "        print(\"Key (Dist Code, Year) is unique.\\n\")\n",
        "\n",
        "    print(\"===== BASIC EDA =====\")\n",
        "    print(f\"Rows: {len(df):d}, Columns: {df.shape[1]:d}\")\n",
        "    print(f\"Time range: {df['Year'].min()} - {df['Year'].max()}\")\n",
        "    if \"State Name\" in df.columns:\n",
        "        print(f\"Unique States: {df['State Name'].nunique()}\")\n",
        "    if \"Dist Code\" in df.columns:\n",
        "        print(f\"Unique Districts: {df['Dist Code'].nunique()}\")\n",
        "\n",
        "    yield_cols, crops, crop_to_yield = get_yield_columns_and_crops(df)\n",
        "    print(f\"Detected crops (count={len(crops)}): {crops[:20]}...\")\n",
        "\n",
        "    # Yield missingness\n",
        "    miss = df[yield_cols].isna().mean().sort_values(ascending=False) * 100\n",
        "    miss_df = pd.DataFrame({\"YieldColumn\": miss.index, \"MissingPct\": miss.values})\n",
        "    print(\"\\nYield missingness (% of NaN):\")\n",
        "    print(miss_df.head(20))\n",
        "\n",
        "    # Summary for main crops if present\n",
        "    main_crops = [\"RICE\", \"WHEAT\", \"MAIZE\", \"GROUNDNUT\", \"COTTON\", \"SUGARCANE\"]\n",
        "    for mc in main_crops:\n",
        "        if mc in crop_to_yield:\n",
        "            col = crop_to_yield[mc]\n",
        "            print(f\"\\nSummary for {mc} yield:\")\n",
        "            print(df[col].describe())\n",
        "\n",
        "    return yield_cols, crops, crop_to_yield\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# CLEANING & DIVERSIFICATION\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def clip_yield_outliers(df, yield_cols, upper_q=0.99):\n",
        "    print(\"\\n===== CLEANING DATA =====\")\n",
        "    df = df.copy()\n",
        "    for col in yield_cols:\n",
        "        s = df[col]\n",
        "        if s.notna().sum() == 0:\n",
        "            continue\n",
        "        old_max = s.max()\n",
        "        q_high = s.quantile(upper_q)\n",
        "        df[col] = s.clip(upper=q_high)\n",
        "        new_max = df[col].max()\n",
        "        if new_max < old_max:\n",
        "            # Infer crop name for print\n",
        "            crop_name = col.upper().split(\"YIELD\")[0].strip()\n",
        "            crop_name = \" \".join(crop_name.split())\n",
        "            print(f\"Clipped {crop_name} yield: old max={old_max:.2f}, new max={new_max:.2f}\")\n",
        "    return df\n",
        "\n",
        "def compute_diversification(df, area_cols):\n",
        "    print(\"\\n===== COMPUTING DIVERSIFICATION =====\")\n",
        "    if not area_cols:\n",
        "        print(\"No crop-specific area columns found; skipping diversification.\")\n",
        "        return df\n",
        "\n",
        "    df = df.copy()\n",
        "    area = df[area_cols].clip(lower=0)\n",
        "    denom = area.sum(axis=1).replace(0, np.nan)\n",
        "    share_df = area.div(denom, axis=0)\n",
        "\n",
        "    herf = (share_df ** 2).sum(axis=1)\n",
        "    df[\"HERFINDAHL\"] = herf\n",
        "    df[\"DIVERSIFICATION_INDEX\"] = 1.0 - herf\n",
        "    return df\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# NETWORKS\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def build_district_similarity_network(df, area_cols, ref_start=2008, ref_end=2017, top_k=7):\n",
        "    print(\"\\n===== BUILDING DISTRICT SIMILARITY NETWORK =====\")\n",
        "    if not area_cols:\n",
        "        print(\"No area columns found; cannot build district similarity network.\")\n",
        "        G = nx.Graph()\n",
        "        return G, pd.DataFrame(columns=[\"Dist Code\", \"DIST_DEGREE\", \"DIST_STRENGTH\", \"DIST_BETWEENNESS\"])\n",
        "\n",
        "    sub = df[(df[\"Year\"] >= ref_start) & (df[\"Year\"] <= ref_end)].copy()\n",
        "    if sub.empty:\n",
        "        print(\"No rows in the reference window; cannot build district similarity network.\")\n",
        "        G = nx.Graph()\n",
        "        return G, pd.DataFrame(columns=[\"Dist Code\", \"DIST_DEGREE\", \"DIST_STRENGTH\", \"DIST_BETWEENNESS\"])\n",
        "\n",
        "    area = sub[area_cols].clip(lower=0)\n",
        "    denom = area.sum(axis=1).replace(0, np.nan)\n",
        "    share = area.div(denom, axis=0)\n",
        "    share[\"Dist Code\"] = sub[\"Dist Code\"].values\n",
        "\n",
        "    dist_profile = share.groupby(\"Dist Code\").mean().fillna(0.0)\n",
        "    if dist_profile.empty:\n",
        "        print(\"No district profiles; skipping district network.\")\n",
        "        G = nx.Graph()\n",
        "        return G, pd.DataFrame(columns=[\"Dist Code\", \"DIST_DEGREE\", \"DIST_STRENGTH\", \"DIST_BETWEENNESS\"])\n",
        "\n",
        "    from sklearn.metrics import pairwise_distances\n",
        "\n",
        "    # cosine similarity = 1 - cosine distance\n",
        "    cos_dist = pairwise_distances(dist_profile.values, metric=\"cosine\")\n",
        "    cos_sim = 1.0 - cos_dist\n",
        "\n",
        "    dist_codes = list(dist_profile.index)\n",
        "    G = nx.Graph()\n",
        "    for code in dist_codes:\n",
        "        G.add_node(code)\n",
        "\n",
        "    for i, u in enumerate(dist_codes):\n",
        "        sims_i = cos_sim[i]\n",
        "        # sort indices by similarity descending, skip self\n",
        "        idx_sorted = np.argsort(-sims_i)\n",
        "        neighbors = 0\n",
        "        for j in idx_sorted:\n",
        "            if j == i:\n",
        "                continue\n",
        "            v = dist_codes[j]\n",
        "            sim_val = sims_i[j]\n",
        "            if sim_val <= 0:\n",
        "                break\n",
        "            G.add_edge(u, v, weight=float(sim_val))\n",
        "            neighbors += 1\n",
        "            if neighbors >= top_k:\n",
        "                break\n",
        "\n",
        "    print(f\"Network reference window: {ref_start}-{ref_end}\")\n",
        "    print(f\"District network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "\n",
        "    degree = dict(G.degree())\n",
        "    strength = {\n",
        "        n: sum(data[\"weight\"] for _, _, data in G.edges(n, data=True))\n",
        "        for n in G.nodes()\n",
        "    }\n",
        "    betw = nx.betweenness_centrality(G, weight=\"weight\", normalized=True)\n",
        "\n",
        "    dist_net_feat = pd.DataFrame({\n",
        "        \"Dist Code\": list(G.nodes()),\n",
        "        \"DIST_DEGREE\": [degree[d] for d in G.nodes()],\n",
        "        \"DIST_STRENGTH\": [strength[d] for d in G.nodes()],\n",
        "        \"DIST_BETWEENNESS\": [betw[d] for d in G.nodes()],\n",
        "    })\n",
        "    return G, dist_net_feat\n",
        "\n",
        "def build_crop_cooccurrence_network(df, crop_to_area):\n",
        "    print(\"\\n===== BUILDING CROP-COOCCURRENCE NETWORK =====\")\n",
        "    if not crop_to_area:\n",
        "        print(\"No crop-area mapping; skipping crop network.\")\n",
        "        return nx.Graph()\n",
        "\n",
        "    col_to_crop = {area_col: crop for crop, area_col in crop_to_area.items()}\n",
        "    area_cols = list(col_to_crop.keys())\n",
        "    area_df = df[area_cols].fillna(0)\n",
        "\n",
        "    G = nx.Graph()\n",
        "    for crop in crop_to_area.keys():\n",
        "        G.add_node(crop)\n",
        "\n",
        "    for _, row in area_df.iterrows():\n",
        "        present_cols = [c for c in area_cols if row[c] > 0]\n",
        "        if len(present_cols) < 2:\n",
        "            continue\n",
        "        crops_present = [col_to_crop[c] for c in present_cols]\n",
        "        for c1, c2 in combinations(sorted(set(crops_present)), 2):\n",
        "            if G.has_edge(c1, c2):\n",
        "                G[c1][c2][\"weight\"] += 1\n",
        "            else:\n",
        "                G.add_edge(c1, c2, weight=1)\n",
        "\n",
        "    print(f\"Crop network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "    return G\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# SUPERVISED PANEL PER CROP\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def build_supervised_panel_for_crop(df, crop, yield_col, area_col=None, min_year=1970):\n",
        "    cols = [\"Dist Code\", \"Year\", yield_col, \"DIVERSIFICATION_INDEX\", \"HERFINDAHL\",\n",
        "            \"DIST_DEGREE\", \"DIST_STRENGTH\", \"DIST_BETWEENNESS\"]\n",
        "    if \"State Name\" in df.columns:\n",
        "        cols.append(\"State Name\")\n",
        "    if \"District Name\" in df.columns:\n",
        "        cols.append(\"District Name\")\n",
        "    if area_col is not None and area_col in df.columns:\n",
        "        cols.append(area_col)\n",
        "\n",
        "    cols = [c for c in cols if c in df.columns]\n",
        "    sub = df[cols].copy()\n",
        "    sub = sub[sub[\"Year\"] >= min_year].sort_values([\"Dist Code\", \"Year\"])\n",
        "\n",
        "    def _process_group(g):\n",
        "        g = g.sort_values(\"Year\").copy()\n",
        "        y = g[yield_col]\n",
        "        g[\"Y_LAG1\"] = y.shift(1)\n",
        "        g[\"Y_LAG2\"] = y.shift(2)\n",
        "        g[\"Y_LAG3\"] = y.shift(3)\n",
        "        g[\"Y_ROLL_MEAN3\"] = y.rolling(window=3, min_periods=3).mean().shift(1)\n",
        "        return g\n",
        "\n",
        "    # Will trigger a deprecation warning in future pandas, but safe now\n",
        "    sub = sub.groupby(\"Dist Code\", group_keys=False).apply(_process_group)\n",
        "    sub = sub.rename(columns={yield_col: \"TARGET_YIELD\"})\n",
        "\n",
        "    # Require at least lag1 and rolling mean to be available => drop early years\n",
        "    sub = sub.dropna(subset=[\"TARGET_YIELD\", \"Y_LAG1\", \"Y_ROLL_MEAN3\"])\n",
        "    return sub\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# MODELING\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def evaluate_models_for_crop(sup, crop, feature_sets=(\"no_network\", \"with_network\"), area_col_name=None,\n",
        "                             random_state=RANDOM_STATE):\n",
        "    print(f\"\\n===== MODELING {crop} =====\")\n",
        "    if sup.empty:\n",
        "        print(f\"No data for {crop}; skipping.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    data = sup.copy().sort_values(\"Year\").reset_index(drop=True)\n",
        "\n",
        "    base_features = [\"Year\", \"DIVERSIFICATION_INDEX\", \"HERFINDAHL\",\n",
        "                     \"Y_LAG1\", \"Y_LAG2\", \"Y_LAG3\", \"Y_ROLL_MEAN3\"]\n",
        "    if area_col_name is not None and area_col_name in data.columns:\n",
        "        base_features.append(area_col_name)\n",
        "\n",
        "    network_features = [\"DIST_DEGREE\", \"DIST_STRENGTH\", \"DIST_BETWEENNESS\"]\n",
        "\n",
        "    y_full = data[\"TARGET_YIELD\"].values\n",
        "\n",
        "    fold_rows = []\n",
        "\n",
        "    for feature_set in feature_sets:\n",
        "        if feature_set == \"no_network\":\n",
        "            feature_cols = [c for c in base_features if c in data.columns]\n",
        "        else:\n",
        "            feature_cols = [c for c in base_features + network_features if c in data.columns]\n",
        "\n",
        "        if len(feature_cols) == 0:\n",
        "            print(f\"{crop} | {feature_set}: no usable features, skipping.\")\n",
        "            continue\n",
        "\n",
        "        X_all = data[feature_cols].values\n",
        "        tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "        try:\n",
        "            splits = list(tscv.split(X_all))\n",
        "        except ValueError as e:\n",
        "            print(f\"Time-series CV error for {crop} ({feature_set}): {e}\")\n",
        "            continue\n",
        "\n",
        "        for fold_idx, (train_idx, test_idx) in enumerate(splits, start=1):\n",
        "            X_train, X_test = X_all[train_idx], X_all[test_idx]\n",
        "            y_train, y_test = y_full[train_idx], y_full[test_idx]\n",
        "\n",
        "            # 1) Naive baseline: use lag-1 yield\n",
        "            y_pred_naive = data.loc[test_idx, \"Y_LAG1\"].values\n",
        "            mae, rmse, mape, medae, r2 = compute_regression_metrics(y_test, y_pred_naive)\n",
        "            print(f\"{crop} | Naive | {feature_set} | Fold {fold_idx}: \"\n",
        "                  f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "            fold_rows.append(dict(Crop=crop, Model=\"Naive\", FeatureSet=feature_set,\n",
        "                                  Fold=fold_idx, MAE=mae, RMSE=rmse, MAPE=mape,\n",
        "                                  MedAE=medae, R2=r2))\n",
        "\n",
        "            # 2) RollingMean3 baseline\n",
        "            y_pred_rm3 = data.loc[test_idx, \"Y_ROLL_MEAN3\"].values\n",
        "            mae, rmse, mape, medae, r2 = compute_regression_metrics(y_test, y_pred_rm3)\n",
        "            print(f\"{crop} | RollingMean3 | {feature_set} | Fold {fold_idx}: \"\n",
        "                  f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "            fold_rows.append(dict(Crop=crop, Model=\"RollingMean3\", FeatureSet=feature_set,\n",
        "                                  Fold=fold_idx, MAE=mae, RMSE=rmse, MAPE=mape,\n",
        "                                  MedAE=medae, R2=r2))\n",
        "\n",
        "            # 3) Ridge regression\n",
        "            ridge = Ridge(alpha=1.0)\n",
        "            ridge.fit(X_train, y_train)\n",
        "            y_pred = ridge.predict(X_test)\n",
        "            mae, rmse, mape, medae, r2 = compute_regression_metrics(y_test, y_pred)\n",
        "            print(f\"{crop} | Ridge | {feature_set} | Fold {fold_idx}: \"\n",
        "                  f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "            fold_rows.append(dict(Crop=crop, Model=\"Ridge\", FeatureSet=feature_set,\n",
        "                                  Fold=fold_idx, MAE=mae, RMSE=rmse, MAPE=mape,\n",
        "                                  MedAE=medae, R2=r2))\n",
        "\n",
        "            # 4) RandomForest\n",
        "            rf = RandomForestRegressor(\n",
        "                n_estimators=300,\n",
        "                max_depth=None,\n",
        "                min_samples_leaf=5,\n",
        "                n_jobs=-1,\n",
        "                random_state=random_state,\n",
        "            )\n",
        "            rf.fit(X_train, y_train)\n",
        "            y_pred = rf.predict(X_test)\n",
        "            mae, rmse, mape, medae, r2 = compute_regression_metrics(y_test, y_pred)\n",
        "            print(f\"{crop} | RandomForest | {feature_set} | Fold {fold_idx}: \"\n",
        "                  f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "            fold_rows.append(dict(Crop=crop, Model=\"RandomForest\", FeatureSet=feature_set,\n",
        "                                  Fold=fold_idx, MAE=mae, RMSE=rmse, MAPE=mape,\n",
        "                                  MedAE=medae, R2=r2))\n",
        "\n",
        "            # 5) GradientBoosting\n",
        "            gb = GradientBoostingRegressor(\n",
        "                n_estimators=300,\n",
        "                learning_rate=0.05,\n",
        "                max_depth=3,\n",
        "                random_state=random_state,\n",
        "            )\n",
        "            gb.fit(X_train, y_train)\n",
        "            y_pred = gb.predict(X_test)\n",
        "            mae, rmse, mape, medae, r2 = compute_regression_metrics(y_test, y_pred)\n",
        "            print(f\"{crop} | GradientBoosting | {feature_set} | Fold {fold_idx}: \"\n",
        "                  f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "            fold_rows.append(dict(Crop=crop, Model=\"GradientBoosting\", FeatureSet=feature_set,\n",
        "                                  Fold=fold_idx, MAE=mae, RMSE=rmse, MAPE=mape,\n",
        "                                  MedAE=medae, R2=r2))\n",
        "\n",
        "    if not fold_rows:\n",
        "        print(f\"No fold-level metrics for {crop}; skipping performance summary.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    fold_df = pd.DataFrame(fold_rows)\n",
        "    summary = (\n",
        "        fold_df.groupby([\"Crop\", \"Model\", \"FeatureSet\"], as_index=False)\n",
        "        .agg(\n",
        "            MAE_mean=(\"MAE\", \"mean\"),\n",
        "            MAE_std=(\"MAE\", \"std\"),\n",
        "            RMSE_mean=(\"RMSE\", \"mean\"),\n",
        "            RMSE_std=(\"RMSE\", \"std\"),\n",
        "            MAPE_mean=(\"MAPE\", \"mean\"),\n",
        "            MAPE_std=(\"MAPE\", \"std\"),\n",
        "            MedAE_mean=(\"MedAE\", \"mean\"),\n",
        "            MedAE_std=(\"MedAE\", \"std\"),\n",
        "            R2_mean=(\"R2\", \"mean\"),\n",
        "            R2_std=(\"R2\", \"std\"),\n",
        "        )\n",
        "    )\n",
        "\n",
        "    for fs in summary[\"FeatureSet\"].unique():\n",
        "        sub = summary[summary[\"FeatureSet\"] == fs].copy().sort_values(\"MAE_mean\")\n",
        "        print(f\"\\nPerformance summary for {crop} ({fs}):\")\n",
        "        print(sub)\n",
        "\n",
        "    return summary\n",
        "\n",
        "def select_best_model(summary_df, crop, mae_tol_frac=0.01):\n",
        "    \"\"\"Select best model per crop:\n",
        "       - start from min MAE_mean\n",
        "       - allow mae_tol_frac tolerance\n",
        "       - prefer positive R2_mean when available\n",
        "       - then prefer FeatureSet='with_network'\n",
        "       - then lowest MAE_mean, highest R2_mean\n",
        "    \"\"\"\n",
        "    if summary_df.empty:\n",
        "        return None\n",
        "    dfc = summary_df[summary_df[\"Crop\"] == crop].copy()\n",
        "    if dfc.empty:\n",
        "        return None\n",
        "    best_mae = dfc[\"MAE_mean\"].min()\n",
        "    candidates = dfc[dfc[\"MAE_mean\"] <= best_mae * (1.0 + mae_tol_frac)]\n",
        "\n",
        "    # Prefer positive R2 where available\n",
        "    pos = candidates[candidates[\"R2_mean\"] > 0]\n",
        "    if not pos.empty:\n",
        "        candidates = pos\n",
        "\n",
        "    # Prefer with_network when available\n",
        "    with_net = candidates[candidates[\"FeatureSet\"] == \"with_network\"]\n",
        "    if not with_net.empty:\n",
        "        candidates = with_net\n",
        "\n",
        "    # Final tie-break: lowest MAE, then highest R2\n",
        "    candidates = candidates.sort_values([\"MAE_mean\", \"R2_mean\"], ascending=[True, False])\n",
        "    best = candidates.iloc[0]\n",
        "    print(f\"\\nBest model for {crop}: {best['Model']} (FeatureSet={best['FeatureSet']}), \"\n",
        "          f\"MAE_mean={best['MAE_mean']:.2f}\")\n",
        "    return best\n",
        "\n",
        "def fit_and_plot_best_model(sup, crop, best_row, area_col_name=None):\n",
        "    \"\"\"Fit best model on full data (for ML models) or use baselines and\n",
        "    save simple diagnostic plots: observed vs predicted and residuals histogram.\n",
        "    \"\"\"\n",
        "    if best_row is None or sup.empty:\n",
        "        return\n",
        "\n",
        "    model_name = best_row[\"Model\"]\n",
        "    feature_set = best_row[\"FeatureSet\"]\n",
        "\n",
        "    data = sup.copy().sort_values(\"Year\").reset_index(drop=True)\n",
        "    base_features = [\"Year\", \"DIVERSIFICATION_INDEX\", \"HERFINDAHL\",\n",
        "                     \"Y_LAG1\", \"Y_LAG2\", \"Y_LAG3\", \"Y_ROLL_MEAN3\"]\n",
        "    if area_col_name is not None and area_col_name in data.columns:\n",
        "        base_features.append(area_col_name)\n",
        "    network_features = [\"DIST_DEGREE\", \"DIST_STRENGTH\", \"DIST_BETWEENNESS\"]\n",
        "\n",
        "    if feature_set == \"no_network\":\n",
        "        feature_cols = [c for c in base_features if c in data.columns]\n",
        "    else:\n",
        "        feature_cols = [c for c in base_features + network_features if c in data.columns]\n",
        "\n",
        "    y = data[\"TARGET_YIELD\"].values\n",
        "\n",
        "    if model_name == \"Naive\":\n",
        "        y_pred = data[\"Y_LAG1\"].values\n",
        "    elif model_name == \"RollingMean3\":\n",
        "        y_pred = data[\"Y_ROLL_MEAN3\"].values\n",
        "    else:\n",
        "        X = data[feature_cols].values\n",
        "        if model_name == \"Ridge\":\n",
        "            model = Ridge(alpha=1.0)\n",
        "        elif model_name == \"RandomForest\":\n",
        "            model = RandomForestRegressor(\n",
        "                n_estimators=300,\n",
        "                max_depth=None,\n",
        "                min_samples_leaf=5,\n",
        "                n_jobs=-1,\n",
        "                random_state=RANDOM_STATE,\n",
        "            )\n",
        "        elif model_name == \"GradientBoosting\":\n",
        "            model = GradientBoostingRegressor(\n",
        "                n_estimators=300,\n",
        "                learning_rate=0.05,\n",
        "                max_depth=3,\n",
        "                random_state=RANDOM_STATE,\n",
        "            )\n",
        "        else:\n",
        "            return\n",
        "        model.fit(X, y)\n",
        "        y_pred = model.predict(X)\n",
        "\n",
        "    # Drop NaNs\n",
        "    mask = (~np.isnan(y)) & (~np.isnan(y_pred))\n",
        "    y = y[mask]\n",
        "    y_pred = y_pred[mask]\n",
        "    if len(y) == 0:\n",
        "        return\n",
        "\n",
        "    # Scatter: observed vs predicted\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.scatter(y, y_pred, s=10, alpha=0.6)\n",
        "    plt.xlabel(\"Observed yield (kg/ha)\")\n",
        "    plt.ylabel(\"Predicted yield (kg/ha)\")\n",
        "    plt.title(f\"{crop} | {model_name} ({feature_set})\")\n",
        "    lim_min = min(y.min(), y_pred.min())\n",
        "    lim_max = max(y.max(), y_pred.max())\n",
        "    plt.plot([lim_min, lim_max], [lim_min, lim_max], linestyle=\"--\")\n",
        "    plt.tight_layout()\n",
        "    out_scatter = os.path.join(\n",
        "        OUTPUT_DIR,\n",
        "        f\"{crop.lower()}_{model_name.lower()}_{feature_set}_diag_scatter.pdf\",\n",
        "    )\n",
        "    plt.savefig(out_scatter, dpi=PLOT_DPI)\n",
        "    plt.close()\n",
        "\n",
        "    # Residuals histogram\n",
        "    residuals = y - y_pred\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.hist(residuals, bins=30)\n",
        "    plt.xlabel(\"Residual (observed - predicted)\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(f\"{crop} | {model_name} ({feature_set}) residuals\")\n",
        "    plt.tight_layout()\n",
        "    out_resid = os.path.join(\n",
        "        OUTPUT_DIR,\n",
        "        f\"{crop.lower()}_{model_name.lower()}_{feature_set}_residuals_hist.pdf\",\n",
        "    )\n",
        "    plt.savefig(out_resid, dpi=PLOT_DPI)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Saved diagnostic plots for {crop} ({model_name}, feature set={feature_set}) to OUTPUT_DIR.\")\n",
        "\n",
        "# ----------------------------------------------------------------------\n",
        "# MAIN PIPELINE\n",
        "# ----------------------------------------------------------------------\n",
        "\n",
        "def main():\n",
        "    df = load_data(DATA_PATH)\n",
        "    yield_cols, crops, crop_to_yield = basic_eda(df)\n",
        "\n",
        "    # Clip yield outliers\n",
        "    df = clip_yield_outliers(df, yield_cols, upper_q=0.99)\n",
        "\n",
        "    # Area mapping & diversification\n",
        "    crop_to_area = infer_area_columns(df, crop_to_yield)\n",
        "    area_cols = list(crop_to_area.values())\n",
        "    df = compute_diversification(df, area_cols)\n",
        "\n",
        "    # Networks\n",
        "    G_dist, dist_net_feat = build_district_similarity_network(\n",
        "        df, area_cols, ref_start=2008, ref_end=2017, top_k=7\n",
        "    )\n",
        "    if not dist_net_feat.empty:\n",
        "        df = df.merge(dist_net_feat, on=\"Dist Code\", how=\"left\")\n",
        "    else:\n",
        "        # If network features missing, fill with zeros\n",
        "        df[\"DIST_DEGREE\"] = 0.0\n",
        "        df[\"DIST_STRENGTH\"] = 0.0\n",
        "        df[\"DIST_BETWEENNESS\"] = 0.0\n",
        "\n",
        "    G_crop = build_crop_cooccurrence_network(df, crop_to_area)\n",
        "\n",
        "    cleaned_path = os.path.join(OUTPUT_DIR, \"icrisat_cleaned_with_features.csv\")\n",
        "    df.to_csv(cleaned_path, index=False)\n",
        "    print(f\"\\nSaved cleaned dataset with features to: {cleaned_path}\")\n",
        "\n",
        "    crops_to_model = [\"RICE\", \"WHEAT\", \"MAIZE\", \"GROUNDNUT\", \"COTTON\", \"SUGARCANE\"]\n",
        "\n",
        "    all_summaries = []\n",
        "    best_models_info = []\n",
        "\n",
        "    for crop in crops_to_model:\n",
        "        if crop not in crop_to_yield:\n",
        "            print(f\"\\nCrop {crop} not found in yield columns; skipping modeling.\")\n",
        "            continue\n",
        "        yield_col = crop_to_yield[crop]\n",
        "        area_col = crop_to_area.get(crop, None)\n",
        "\n",
        "        sup = build_supervised_panel_for_crop(df, crop, yield_col, area_col, min_year=1970)\n",
        "        if sup.empty:\n",
        "            print(f\"\\nSupervised panel for {crop} is empty; skipping.\")\n",
        "            continue\n",
        "\n",
        "        panel_path = os.path.join(OUTPUT_DIR, f\"supervised_panel_{crop.lower()}.csv\")\n",
        "        sup.to_csv(panel_path, index=False)\n",
        "        print(f\"\\nSaved supervised panel for {crop} to: {panel_path}\")\n",
        "\n",
        "        summary = evaluate_models_for_crop(\n",
        "            sup,\n",
        "            crop,\n",
        "            feature_sets=(\"no_network\", \"with_network\"),\n",
        "            area_col_name=area_col,\n",
        "            random_state=RANDOM_STATE,\n",
        "        )\n",
        "        if summary.empty:\n",
        "            continue\n",
        "\n",
        "        all_summaries.append(summary)\n",
        "        best = select_best_model(summary, crop)\n",
        "        if best is not None:\n",
        "            best_models_info.append(best)\n",
        "            fit_and_plot_best_model(sup, crop, best, area_col_name=area_col)\n",
        "\n",
        "    perf_path = None\n",
        "    if all_summaries:\n",
        "        perf_summary = pd.concat(all_summaries, ignore_index=True)\n",
        "        perf_path = os.path.join(OUTPUT_DIR, \"model_performance_summary.csv\")\n",
        "        perf_summary.to_csv(perf_path, index=False)\n",
        "        print(f\"\\nSaved model performance summary to: {perf_path}\")\n",
        "\n",
        "    print(\"\\n===== FINAL SUMMARY =====\")\n",
        "    print(f\"Rows after cleaning: {len(df)}\")\n",
        "    print(f\"Years: {df['Year'].min()} - {df['Year'].max()}\")\n",
        "    if \"Dist Code\" in df.columns:\n",
        "        print(f\"Number of districts: {df['Dist Code'].nunique()}\")\n",
        "\n",
        "    modeled_crops = [b[\"Crop\"] for b in best_models_info] if best_models_info else []\n",
        "    print(f\"Crops modeled: {modeled_crops}\")\n",
        "    if best_models_info:\n",
        "        print(\"Best model per crop (MAE-based with MAE-tolerance + R2/with-network preference):\")\n",
        "        for b in best_models_info:\n",
        "            print(f\"  {b['Crop']}: {b['Model']} (FeatureSet={b['FeatureSet']}), \"\n",
        "                  f\"MAE_mean={b['MAE_mean']:.2f}\")\n",
        "\n",
        "    print(f\"Cleaned dataset with features: {cleaned_path}\")\n",
        "    if perf_path is not None:\n",
        "        print(f\"Model performance summary: {perf_path}\")\n",
        "    print(f\"Supervised panel CSV prefix: {os.path.join(OUTPUT_DIR, 'supervised_panel_')}\")\n",
        "    print(\"Key PDF plots saved in OUTPUT_DIR (diagnostic scatter + residuals for best models).\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrSOuAnep-m6",
        "outputId": "cfb43aef-df6d-4c36-c50a-d985fc254c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAW_CSV_PATH not found.\n",
            "Falling back to existing CLEANED dataset: /content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\n",
            "\n",
            "Data source type: cleaned\n",
            "===== BASIC EDA =====\n",
            "Duplicate (Dist Code, Year) rows: 0\n",
            "Key (Dist Code, Year) is unique.\n",
            "\n",
            "Rows: 16146, Columns: 85\n",
            "Time range: 1966 - 2017\n",
            "Unique States: 20\n",
            "Detected crops (count=23): ['BARLEY', 'CASTOR', 'CHICKPEA', 'COTTON', 'FINGER MILLET', 'GROUNDNUT', 'KHARIF SORGHUM', 'LINSEED', 'MAIZE', 'MINOR PULSES', 'OILSEEDS', 'PEARL MILLET', 'PIGEONPEA', 'RABI SORGHUM', 'RAPESEED AND MUSTARD', 'RICE', 'SAFFLOWER', 'SESAMUM', 'SORGHUM', 'SOYABEAN']...\n",
            "\n",
            "Yield missingness (% of NaN):\n",
            "                           YieldColumn  MissingPct\n",
            "                RICE YIELD (Kg per ha)         0.0\n",
            "               WHEAT YIELD (Kg per ha)         0.0\n",
            "      KHARIF SORGHUM YIELD (Kg per ha)         0.0\n",
            "        RABI SORGHUM YIELD (Kg per ha)         0.0\n",
            "             SORGHUM YIELD (Kg per ha)         0.0\n",
            "        PEARL MILLET YIELD (Kg per ha)         0.0\n",
            "               MAIZE YIELD (Kg per ha)         0.0\n",
            "       FINGER MILLET YIELD (Kg per ha)         0.0\n",
            "              BARLEY YIELD (Kg per ha)         0.0\n",
            "            CHICKPEA YIELD (Kg per ha)         0.0\n",
            "           PIGEONPEA YIELD (Kg per ha)         0.0\n",
            "        MINOR PULSES YIELD (Kg per ha)         0.0\n",
            "           GROUNDNUT YIELD (Kg per ha)         0.0\n",
            "             SESAMUM YIELD (Kg per ha)         0.0\n",
            "RAPESEED AND MUSTARD YIELD (Kg per ha)         0.0\n",
            "           SAFFLOWER YIELD (Kg per ha)         0.0\n",
            "              CASTOR YIELD (Kg per ha)         0.0\n",
            "             LINSEED YIELD (Kg per ha)         0.0\n",
            "           SUNFLOWER YIELD (Kg per ha)         0.0\n",
            "            SOYABEAN YIELD (Kg per ha)         0.0\n",
            "            OILSEEDS YIELD (Kg per ha)         0.0\n",
            "           SUGARCANE YIELD (Kg per ha)         0.0\n",
            "              COTTON YIELD (Kg per ha)         0.0\n",
            "\n",
            "Summary for RICE yield:\n",
            "count    16146.000000\n",
            "mean      1483.293905\n",
            "std        945.019454\n",
            "min          0.000000\n",
            "25%        800.000000\n",
            "50%       1333.210000\n",
            "75%       2113.517500\n",
            "max       4104.539500\n",
            "Name: RICE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for WHEAT yield:\n",
            "count    16146.000000\n",
            "mean      1489.259768\n",
            "std       1071.708135\n",
            "min          0.000000\n",
            "25%        750.000000\n",
            "50%       1347.450000\n",
            "75%       2131.580000\n",
            "max       4484.845500\n",
            "Name: WHEAT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for MAIZE yield:\n",
            "count    16146.000000\n",
            "mean      1394.225152\n",
            "std       1115.346031\n",
            "min          0.000000\n",
            "25%        696.890000\n",
            "50%       1159.065000\n",
            "75%       1863.640000\n",
            "max       5897.884500\n",
            "Name: MAIZE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for GROUNDNUT yield:\n",
            "count    16146.000000\n",
            "mean       759.274661\n",
            "std        598.974987\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%        774.410000\n",
            "75%       1085.037500\n",
            "max       2541.269500\n",
            "Name: GROUNDNUT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for COTTON yield:\n",
            "count    16146.00000\n",
            "mean       119.82308\n",
            "std        167.34296\n",
            "min          0.00000\n",
            "25%          0.00000\n",
            "50%          0.00000\n",
            "75%        202.27000\n",
            "max        740.29700\n",
            "Name: COTTON YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for SUGARCANE yield:\n",
            "count    16146.000000\n",
            "mean      4484.083204\n",
            "std       3105.530811\n",
            "min          0.000000\n",
            "25%       2000.000000\n",
            "50%       4502.210000\n",
            "75%       6704.605000\n",
            "max      12000.000000\n",
            "Name: SUGARCANE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "===== CLEANING DATA =====\n",
            "Clipped RICE yield: old max=4104.54, new max=4104.22\n",
            "Clipped WHEAT yield: old max=4484.85, new max=4484.00\n",
            "Clipped KHARIF SORGHUM yield: old max=2269.55, new max=2269.43\n",
            "Clipped RABI SORGHUM yield: old max=2333.33, new max=2333.33\n",
            "Clipped SORGHUM yield: old max=2226.14, new max=2225.52\n",
            "Clipped PEARL MILLET yield: old max=2321.72, new max=2321.59\n",
            "Clipped MAIZE yield: old max=5897.88, new max=5897.19\n",
            "Clipped FINGER MILLET yield: old max=2191.11, new max=2189.49\n",
            "Clipped BARLEY yield: old max=3493.78, new max=3493.62\n",
            "Clipped CHICKPEA yield: old max=1727.27, new max=1727.27\n",
            "Clipped PIGEONPEA yield: old max=2123.75, new max=2123.06\n",
            "Clipped MINOR PULSES yield: old max=1810.89, new max=1810.86\n",
            "Clipped GROUNDNUT yield: old max=2541.27, new max=2541.00\n",
            "Clipped SESAMUM yield: old max=1000.00, new max=1000.00\n",
            "Clipped RAPESEED AND MUSTARD yield: old max=1771.47, new max=1771.47\n",
            "Clipped SAFFLOWER yield: old max=1000.00, new max=1000.00\n",
            "Clipped CASTOR yield: old max=2000.00, new max=2000.00\n",
            "Clipped LINSEED yield: old max=1000.00, new max=1000.00\n",
            "Clipped SUNFLOWER yield: old max=2000.00, new max=2000.00\n",
            "Clipped SOYABEAN yield: old max=1826.50, new max=1824.93\n",
            "Clipped OILSEEDS yield: old max=1991.55, new max=1990.66\n",
            "Clipped SUGARCANE yield: old max=12000.00, new max=12000.00\n",
            "Clipped COTTON yield: old max=740.30, new max=740.16\n",
            "\n",
            "===== COMPUTING DIVERSIFICATION =====\n",
            "\n",
            "===== BUILDING DISTRICT SIMILARITY NETWORK =====\n",
            "Network reference window: 2008-2017\n",
            "District network: 311 nodes, 7874 edges\n",
            "\n",
            "===== BUILDING CROP-COOCCURRENCE NETWORK =====\n",
            "Crop network: 29 nodes, 406 edges\n",
            "\n",
            "Saved cleaned dataset with features to: /content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\n",
            "\n",
            "Saved supervised panel for RICE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_rice.csv\n",
            "\n",
            "Saved supervised panel for WHEAT to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_wheat.csv\n",
            "\n",
            "Saved supervised panel for MAIZE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_maize.csv\n",
            "\n",
            "Saved supervised panel for GROUNDNUT to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_groundnut.csv\n",
            "\n",
            "Saved supervised panel for COTTON to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_cotton.csv\n",
            "\n",
            "Saved supervised panel for SUGARCANE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_sugarcane.csv\n",
            "\n",
            "===== MODELING RICE =====\n",
            "RICE | Naive | no_network | Fold 1: MAE=256.67, RMSE=386.28, MAPE=23.76, MedAE=171.89, R2=0.798\n",
            "RICE | RollingMean3 | no_network | Fold 1: MAE=240.53, RMSE=350.47, MAPE=21.84, MedAE=171.06, R2=0.834\n",
            "RICE | Ridge | no_network | Fold 1: MAE=238.47, RMSE=343.66, MAPE=22.48, MedAE=160.42, R2=0.840\n",
            "RICE | RandomForest | no_network | Fold 1: MAE=253.91, RMSE=365.35, MAPE=24.29, MedAE=180.76, R2=0.820\n",
            "RICE | GradientBoosting | no_network | Fold 1: MAE=249.78, RMSE=359.91, MAPE=23.79, MedAE=171.77, R2=0.825\n",
            "RICE | Naive | no_network | Fold 2: MAE=277.47, RMSE=410.14, MAPE=23.06, MedAE=179.67, R2=0.821\n",
            "RICE | RollingMean3 | no_network | Fold 2: MAE=248.73, RMSE=360.88, MAPE=20.89, MedAE=166.67, R2=0.862\n",
            "RICE | Ridge | no_network | Fold 2: MAE=249.13, RMSE=356.05, MAPE=21.18, MedAE=165.43, R2=0.865\n",
            "RICE | RandomForest | no_network | Fold 2: MAE=263.67, RMSE=374.36, MAPE=22.45, MedAE=182.97, R2=0.851\n",
            "RICE | GradientBoosting | no_network | Fold 2: MAE=254.92, RMSE=366.31, MAPE=21.69, MedAE=168.57, R2=0.857\n",
            "RICE | Naive | no_network | Fold 3: MAE=287.57, RMSE=467.14, MAPE=19.92, MedAE=163.14, R2=0.817\n",
            "RICE | RollingMean3 | no_network | Fold 3: MAE=280.60, RMSE=424.96, MAPE=19.02, MedAE=183.97, R2=0.849\n",
            "RICE | Ridge | no_network | Fold 3: MAE=276.87, RMSE=414.51, MAPE=18.98, MedAE=173.27, R2=0.856\n",
            "RICE | RandomForest | no_network | Fold 3: MAE=292.25, RMSE=438.40, MAPE=20.06, MedAE=192.23, R2=0.839\n",
            "RICE | GradientBoosting | no_network | Fold 3: MAE=283.25, RMSE=422.77, MAPE=19.62, MedAE=177.53, R2=0.850\n",
            "RICE | Naive | with_network | Fold 1: MAE=256.67, RMSE=386.28, MAPE=23.76, MedAE=171.89, R2=0.798\n",
            "RICE | RollingMean3 | with_network | Fold 1: MAE=240.53, RMSE=350.47, MAPE=21.84, MedAE=171.06, R2=0.834\n",
            "RICE | Ridge | with_network | Fold 1: MAE=237.73, RMSE=343.20, MAPE=22.42, MedAE=161.50, R2=0.841\n",
            "RICE | RandomForest | with_network | Fold 1: MAE=249.99, RMSE=357.73, MAPE=23.51, MedAE=179.97, R2=0.827\n",
            "RICE | GradientBoosting | with_network | Fold 1: MAE=255.26, RMSE=371.91, MAPE=23.42, MedAE=170.74, R2=0.813\n",
            "RICE | Naive | with_network | Fold 2: MAE=277.47, RMSE=410.14, MAPE=23.06, MedAE=179.67, R2=0.821\n",
            "RICE | RollingMean3 | with_network | Fold 2: MAE=248.73, RMSE=360.88, MAPE=20.89, MedAE=166.67, R2=0.862\n",
            "RICE | Ridge | with_network | Fold 2: MAE=248.68, RMSE=356.19, MAPE=21.11, MedAE=165.89, R2=0.865\n",
            "RICE | RandomForest | with_network | Fold 2: MAE=262.30, RMSE=372.62, MAPE=21.91, MedAE=179.58, R2=0.853\n",
            "RICE | GradientBoosting | with_network | Fold 2: MAE=255.23, RMSE=364.47, MAPE=21.30, MedAE=173.58, R2=0.859\n",
            "RICE | Naive | with_network | Fold 3: MAE=287.57, RMSE=467.14, MAPE=19.92, MedAE=163.14, R2=0.817\n",
            "RICE | RollingMean3 | with_network | Fold 3: MAE=280.60, RMSE=424.96, MAPE=19.02, MedAE=183.97, R2=0.849\n",
            "RICE | Ridge | with_network | Fold 3: MAE=275.82, RMSE=413.97, MAPE=18.92, MedAE=174.80, R2=0.857\n",
            "RICE | RandomForest | with_network | Fold 3: MAE=295.13, RMSE=438.98, MAPE=20.15, MedAE=192.70, R2=0.839\n",
            "RICE | GradientBoosting | with_network | Fold 3: MAE=286.91, RMSE=426.91, MAPE=19.59, MedAE=182.73, R2=0.847\n",
            "\n",
            "===== MODELING WHEAT =====\n",
            "WHEAT | Naive | no_network | Fold 1: MAE=227.93, RMSE=359.53, MAPE=17.97, MedAE=145.52, R2=0.861\n",
            "WHEAT | RollingMean3 | no_network | Fold 1: MAE=215.00, RMSE=318.21, MAPE=16.75, MedAE=151.92, R2=0.891\n",
            "WHEAT | Ridge | no_network | Fold 1: MAE=214.15, RMSE=311.97, MAPE=16.52, MedAE=140.97, R2=0.895\n",
            "WHEAT | RandomForest | no_network | Fold 1: MAE=252.42, RMSE=374.66, MAPE=18.26, MedAE=170.00, R2=0.849\n",
            "WHEAT | GradientBoosting | no_network | Fold 1: MAE=292.16, RMSE=560.34, MAPE=19.36, MedAE=157.42, R2=0.661\n",
            "WHEAT | Naive | no_network | Fold 2: MAE=241.55, RMSE=373.60, MAPE=18.05, MedAE=159.87, R2=0.891\n",
            "WHEAT | RollingMean3 | no_network | Fold 2: MAE=216.56, RMSE=329.53, MAPE=16.16, MedAE=142.62, R2=0.915\n",
            "WHEAT | Ridge | no_network | Fold 2: MAE=223.72, RMSE=329.78, MAPE=16.47, MedAE=147.41, R2=0.915\n",
            "WHEAT | RandomForest | no_network | Fold 2: MAE=235.94, RMSE=348.12, MAPE=17.48, MedAE=163.48, R2=0.906\n",
            "WHEAT | GradientBoosting | no_network | Fold 2: MAE=228.46, RMSE=339.77, MAPE=16.80, MedAE=151.03, R2=0.910\n",
            "WHEAT | Naive | no_network | Fold 3: MAE=313.43, RMSE=500.13, MAPE=19.12, MedAE=183.58, R2=0.851\n",
            "WHEAT | RollingMean3 | no_network | Fold 3: MAE=306.18, RMSE=466.94, MAPE=17.87, MedAE=193.80, R2=0.870\n",
            "WHEAT | Ridge | no_network | Fold 3: MAE=297.42, RMSE=452.12, MAPE=17.37, MedAE=180.54, R2=0.878\n",
            "WHEAT | RandomForest | no_network | Fold 3: MAE=316.75, RMSE=481.24, MAPE=18.59, MedAE=200.73, R2=0.862\n",
            "WHEAT | GradientBoosting | no_network | Fold 3: MAE=313.50, RMSE=478.63, MAPE=18.06, MedAE=188.38, R2=0.863\n",
            "WHEAT | Naive | with_network | Fold 1: MAE=227.93, RMSE=359.53, MAPE=17.97, MedAE=145.52, R2=0.861\n",
            "WHEAT | RollingMean3 | with_network | Fold 1: MAE=215.00, RMSE=318.21, MAPE=16.75, MedAE=151.92, R2=0.891\n",
            "WHEAT | Ridge | with_network | Fold 1: MAE=214.51, RMSE=312.09, MAPE=16.50, MedAE=141.27, R2=0.895\n",
            "WHEAT | RandomForest | with_network | Fold 1: MAE=247.97, RMSE=362.72, MAPE=17.96, MedAE=168.55, R2=0.858\n",
            "WHEAT | GradientBoosting | with_network | Fold 1: MAE=281.39, RMSE=502.33, MAPE=18.76, MedAE=157.71, R2=0.728\n",
            "WHEAT | Naive | with_network | Fold 2: MAE=241.55, RMSE=373.60, MAPE=18.05, MedAE=159.87, R2=0.891\n",
            "WHEAT | RollingMean3 | with_network | Fold 2: MAE=216.56, RMSE=329.53, MAPE=16.16, MedAE=142.62, R2=0.915\n",
            "WHEAT | Ridge | with_network | Fold 2: MAE=223.85, RMSE=329.80, MAPE=16.47, MedAE=146.92, R2=0.915\n",
            "WHEAT | RandomForest | with_network | Fold 2: MAE=236.49, RMSE=347.11, MAPE=17.35, MedAE=162.73, R2=0.906\n",
            "WHEAT | GradientBoosting | with_network | Fold 2: MAE=228.24, RMSE=337.12, MAPE=16.66, MedAE=152.36, R2=0.911\n",
            "WHEAT | Naive | with_network | Fold 3: MAE=313.43, RMSE=500.13, MAPE=19.12, MedAE=183.58, R2=0.851\n",
            "WHEAT | RollingMean3 | with_network | Fold 3: MAE=306.18, RMSE=466.94, MAPE=17.87, MedAE=193.80, R2=0.870\n",
            "WHEAT | Ridge | with_network | Fold 3: MAE=297.53, RMSE=452.24, MAPE=17.38, MedAE=181.11, R2=0.878\n",
            "WHEAT | RandomForest | with_network | Fold 3: MAE=316.82, RMSE=480.41, MAPE=18.45, MedAE=197.20, R2=0.862\n",
            "WHEAT | GradientBoosting | with_network | Fold 3: MAE=316.83, RMSE=480.21, MAPE=18.19, MedAE=195.66, R2=0.862\n",
            "\n",
            "===== MODELING MAIZE =====\n",
            "MAIZE | Naive | no_network | Fold 1: MAE=364.21, RMSE=584.91, MAPE=37.86, MedAE=233.32, R2=0.480\n",
            "MAIZE | RollingMean3 | no_network | Fold 1: MAE=343.68, RMSE=528.18, MAPE=36.29, MedAE=231.84, R2=0.576\n",
            "MAIZE | Ridge | no_network | Fold 1: MAE=344.18, RMSE=510.86, MAPE=36.19, MedAE=221.06, R2=0.603\n",
            "MAIZE | RandomForest | no_network | Fold 1: MAE=363.70, RMSE=550.75, MAPE=39.39, MedAE=245.32, R2=0.539\n",
            "MAIZE | GradientBoosting | no_network | Fold 1: MAE=355.52, RMSE=538.24, MAPE=38.23, MedAE=231.28, R2=0.560\n",
            "MAIZE | Naive | no_network | Fold 2: MAE=403.64, RMSE=651.31, MAPE=30.25, MedAE=250.00, R2=0.614\n",
            "MAIZE | RollingMean3 | no_network | Fold 2: MAE=385.14, RMSE=611.27, MAPE=27.52, MedAE=252.09, R2=0.660\n",
            "MAIZE | Ridge | no_network | Fold 2: MAE=395.18, RMSE=599.38, MAPE=27.39, MedAE=246.41, R2=0.673\n",
            "MAIZE | RandomForest | no_network | Fold 2: MAE=415.27, RMSE=646.42, MAPE=28.73, MedAE=270.32, R2=0.620\n",
            "MAIZE | GradientBoosting | no_network | Fold 2: MAE=407.00, RMSE=644.44, MAPE=28.09, MedAE=248.61, R2=0.622\n",
            "MAIZE | Naive | no_network | Fold 3: MAE=503.39, RMSE=833.61, MAPE=28.55, MedAE=268.72, R2=0.677\n",
            "MAIZE | RollingMean3 | no_network | Fold 3: MAE=479.53, RMSE=764.46, MAPE=26.26, MedAE=281.83, R2=0.728\n",
            "MAIZE | Ridge | no_network | Fold 3: MAE=493.05, RMSE=754.90, MAPE=26.09, MedAE=298.20, R2=0.735\n",
            "MAIZE | RandomForest | no_network | Fold 3: MAE=508.93, RMSE=783.75, MAPE=27.20, MedAE=311.58, R2=0.714\n",
            "MAIZE | GradientBoosting | no_network | Fold 3: MAE=508.23, RMSE=803.08, MAPE=26.94, MedAE=298.00, R2=0.700\n",
            "MAIZE | Naive | with_network | Fold 1: MAE=364.21, RMSE=584.91, MAPE=37.86, MedAE=233.32, R2=0.480\n",
            "MAIZE | RollingMean3 | with_network | Fold 1: MAE=343.68, RMSE=528.18, MAPE=36.29, MedAE=231.84, R2=0.576\n",
            "MAIZE | Ridge | with_network | Fold 1: MAE=344.06, RMSE=510.85, MAPE=36.19, MedAE=222.32, R2=0.603\n",
            "MAIZE | RandomForest | with_network | Fold 1: MAE=359.78, RMSE=546.69, MAPE=39.25, MedAE=241.11, R2=0.546\n",
            "MAIZE | GradientBoosting | with_network | Fold 1: MAE=354.20, RMSE=537.32, MAPE=38.22, MedAE=231.63, R2=0.561\n",
            "MAIZE | Naive | with_network | Fold 2: MAE=403.64, RMSE=651.31, MAPE=30.25, MedAE=250.00, R2=0.614\n",
            "MAIZE | RollingMean3 | with_network | Fold 2: MAE=385.14, RMSE=611.27, MAPE=27.52, MedAE=252.09, R2=0.660\n",
            "MAIZE | Ridge | with_network | Fold 2: MAE=394.55, RMSE=598.94, MAPE=27.39, MedAE=244.23, R2=0.674\n",
            "MAIZE | RandomForest | with_network | Fold 2: MAE=412.32, RMSE=641.53, MAPE=28.07, MedAE=269.29, R2=0.626\n",
            "MAIZE | GradientBoosting | with_network | Fold 2: MAE=405.96, RMSE=644.37, MAPE=27.69, MedAE=250.61, R2=0.622\n",
            "MAIZE | Naive | with_network | Fold 3: MAE=503.39, RMSE=833.61, MAPE=28.55, MedAE=268.72, R2=0.677\n",
            "MAIZE | RollingMean3 | with_network | Fold 3: MAE=479.53, RMSE=764.46, MAPE=26.26, MedAE=281.83, R2=0.728\n",
            "MAIZE | Ridge | with_network | Fold 3: MAE=491.73, RMSE=754.67, MAPE=26.07, MedAE=296.05, R2=0.735\n",
            "MAIZE | RandomForest | with_network | Fold 3: MAE=512.68, RMSE=778.52, MAPE=27.04, MedAE=319.63, R2=0.718\n",
            "MAIZE | GradientBoosting | with_network | Fold 3: MAE=524.65, RMSE=814.39, MAPE=26.98, MedAE=315.19, R2=0.691\n",
            "\n",
            "===== MODELING GROUNDNUT =====\n",
            "GROUNDNUT | Naive | no_network | Fold 1: MAE=240.08, RMSE=398.12, MAPE=47.51, MedAE=128.19, R2=0.443\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 1: MAE=229.13, RMSE=354.88, MAPE=44.03, MedAE=152.70, R2=0.557\n",
            "GROUNDNUT | Ridge | no_network | Fold 1: MAE=241.83, RMSE=347.25, MAPE=43.58, MedAE=149.53, R2=0.576\n",
            "GROUNDNUT | RandomForest | no_network | Fold 1: MAE=251.36, RMSE=374.37, MAPE=51.83, MedAE=170.08, R2=0.507\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 1: MAE=247.82, RMSE=367.15, MAPE=50.69, MedAE=164.01, R2=0.526\n",
            "GROUNDNUT | Naive | no_network | Fold 2: MAE=230.08, RMSE=379.35, MAPE=36.16, MedAE=122.25, R2=0.584\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 2: MAE=215.27, RMSE=329.75, MAPE=33.00, MedAE=144.89, R2=0.685\n",
            "GROUNDNUT | Ridge | no_network | Fold 2: MAE=231.93, RMSE=325.52, MAPE=32.14, MedAE=140.03, R2=0.693\n",
            "GROUNDNUT | RandomForest | no_network | Fold 2: MAE=234.15, RMSE=345.76, MAPE=34.98, MedAE=155.35, R2=0.654\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 2: MAE=234.96, RMSE=349.78, MAPE=34.47, MedAE=145.54, R2=0.646\n",
            "GROUNDNUT | Naive | no_network | Fold 3: MAE=246.87, RMSE=422.61, MAPE=28.58, MedAE=118.80, R2=0.688\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 3: MAE=235.66, RMSE=375.77, MAPE=25.67, MedAE=145.00, R2=0.754\n",
            "GROUNDNUT | Ridge | no_network | Fold 3: MAE=258.84, RMSE=378.67, MAPE=25.97, MedAE=162.06, R2=0.750\n",
            "GROUNDNUT | RandomForest | no_network | Fold 3: MAE=265.62, RMSE=395.37, MAPE=28.26, MedAE=177.25, R2=0.727\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 3: MAE=274.13, RMSE=417.24, MAPE=28.27, MedAE=164.95, R2=0.696\n",
            "GROUNDNUT | Naive | with_network | Fold 1: MAE=240.08, RMSE=398.12, MAPE=47.51, MedAE=128.19, R2=0.443\n",
            "GROUNDNUT | RollingMean3 | with_network | Fold 1: MAE=229.13, RMSE=354.88, MAPE=44.03, MedAE=152.70, R2=0.557\n",
            "GROUNDNUT | Ridge | with_network | Fold 1: MAE=241.90, RMSE=347.27, MAPE=43.92, MedAE=150.79, R2=0.576\n",
            "GROUNDNUT | RandomForest | with_network | Fold 1: MAE=245.57, RMSE=366.56, MAPE=50.62, MedAE=161.25, R2=0.528\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 1: MAE=248.71, RMSE=367.35, MAPE=51.07, MedAE=160.58, R2=0.526\n",
            "GROUNDNUT | Naive | with_network | Fold 2: MAE=230.08, RMSE=379.35, MAPE=36.16, MedAE=122.25, R2=0.584\n",
            "GROUNDNUT | RollingMean3 | with_network | Fold 2: MAE=215.27, RMSE=329.75, MAPE=33.00, MedAE=144.89, R2=0.685\n",
            "GROUNDNUT | Ridge | with_network | Fold 2: MAE=231.73, RMSE=325.48, MAPE=32.20, MedAE=139.65, R2=0.693\n",
            "GROUNDNUT | RandomForest | with_network | Fold 2: MAE=232.53, RMSE=339.88, MAPE=33.82, MedAE=151.52, R2=0.666\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 2: MAE=237.45, RMSE=349.90, MAPE=34.08, MedAE=146.98, R2=0.646\n",
            "GROUNDNUT | Naive | with_network | Fold 3: MAE=246.87, RMSE=422.61, MAPE=28.58, MedAE=118.80, R2=0.688\n",
            "GROUNDNUT | RollingMean3 | with_network | Fold 3: MAE=235.66, RMSE=375.77, MAPE=25.67, MedAE=145.00, R2=0.754\n",
            "GROUNDNUT | Ridge | with_network | Fold 3: MAE=258.89, RMSE=378.62, MAPE=26.01, MedAE=161.45, R2=0.750\n",
            "GROUNDNUT | RandomForest | with_network | Fold 3: MAE=266.44, RMSE=392.07, MAPE=28.04, MedAE=178.75, R2=0.732\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 3: MAE=274.84, RMSE=409.01, MAPE=28.10, MedAE=169.81, R2=0.708\n",
            "\n",
            "===== MODELING COTTON =====\n",
            "COTTON | Naive | no_network | Fold 1: MAE=49.99, RMSE=111.82, MAPE=41.48, MedAE=0.00, R2=0.458\n",
            "COTTON | RollingMean3 | no_network | Fold 1: MAE=47.88, RMSE=98.99, MAPE=38.41, MedAE=5.40, R2=0.575\n",
            "COTTON | Ridge | no_network | Fold 1: MAE=50.72, RMSE=96.31, MAPE=37.06, MedAE=12.74, R2=0.598\n",
            "COTTON | RandomForest | no_network | Fold 1: MAE=49.18, RMSE=99.73, MAPE=39.44, MedAE=11.44, R2=0.569\n",
            "COTTON | GradientBoosting | no_network | Fold 1: MAE=50.27, RMSE=101.54, MAPE=39.64, MedAE=9.75, R2=0.553\n",
            "COTTON | Naive | no_network | Fold 2: MAE=41.06, RMSE=91.00, MAPE=34.05, MedAE=0.00, R2=0.693\n",
            "COTTON | RollingMean3 | no_network | Fold 2: MAE=44.49, RMSE=91.18, MAPE=35.00, MedAE=2.21, R2=0.692\n",
            "COTTON | Ridge | no_network | Fold 2: MAE=49.40, RMSE=88.27, MAPE=32.68, MedAE=16.19, R2=0.712\n",
            "COTTON | RandomForest | no_network | Fold 2: MAE=47.78, RMSE=94.05, MAPE=34.58, MedAE=11.61, R2=0.673\n",
            "COTTON | GradientBoosting | no_network | Fold 2: MAE=47.09, RMSE=92.87, MAPE=33.94, MedAE=7.94, R2=0.681\n",
            "COTTON | Naive | no_network | Fold 3: MAE=68.28, RMSE=144.04, MAPE=373.54, MedAE=0.00, R2=0.593\n",
            "COTTON | RollingMean3 | no_network | Fold 3: MAE=67.61, RMSE=128.40, MAPE=600.58, MedAE=4.86, R2=0.677\n",
            "COTTON | Ridge | no_network | Fold 3: MAE=71.85, RMSE=126.08, MAPE=498.40, MedAE=15.31, R2=0.689\n",
            "COTTON | RandomForest | no_network | Fold 3: MAE=72.44, RMSE=131.69, MAPE=481.47, MedAE=16.59, R2=0.660\n",
            "COTTON | GradientBoosting | no_network | Fold 3: MAE=72.89, RMSE=132.12, MAPE=461.30, MedAE=7.68, R2=0.658\n",
            "COTTON | Naive | with_network | Fold 1: MAE=49.99, RMSE=111.82, MAPE=41.48, MedAE=0.00, R2=0.458\n",
            "COTTON | RollingMean3 | with_network | Fold 1: MAE=47.88, RMSE=98.99, MAPE=38.41, MedAE=5.40, R2=0.575\n",
            "COTTON | Ridge | with_network | Fold 1: MAE=50.37, RMSE=96.18, MAPE=37.17, MedAE=14.36, R2=0.599\n",
            "COTTON | RandomForest | with_network | Fold 1: MAE=49.55, RMSE=98.50, MAPE=38.76, MedAE=14.30, R2=0.579\n",
            "COTTON | GradientBoosting | with_network | Fold 1: MAE=50.19, RMSE=102.03, MAPE=39.10, MedAE=9.44, R2=0.549\n",
            "COTTON | Naive | with_network | Fold 2: MAE=41.06, RMSE=91.00, MAPE=34.05, MedAE=0.00, R2=0.693\n",
            "COTTON | RollingMean3 | with_network | Fold 2: MAE=44.49, RMSE=91.18, MAPE=35.00, MedAE=2.21, R2=0.692\n",
            "COTTON | Ridge | with_network | Fold 2: MAE=48.85, RMSE=88.19, MAPE=32.86, MedAE=19.52, R2=0.712\n",
            "COTTON | RandomForest | with_network | Fold 2: MAE=48.10, RMSE=93.52, MAPE=33.91, MedAE=14.40, R2=0.676\n",
            "COTTON | GradientBoosting | with_network | Fold 2: MAE=47.26, RMSE=94.01, MAPE=33.86, MedAE=10.29, R2=0.673\n",
            "COTTON | Naive | with_network | Fold 3: MAE=68.28, RMSE=144.04, MAPE=373.54, MedAE=0.00, R2=0.593\n",
            "COTTON | RollingMean3 | with_network | Fold 3: MAE=67.61, RMSE=128.40, MAPE=600.58, MedAE=4.86, R2=0.677\n",
            "COTTON | Ridge | with_network | Fold 3: MAE=71.67, RMSE=126.04, MAPE=496.49, MedAE=18.85, R2=0.689\n",
            "COTTON | RandomForest | with_network | Fold 3: MAE=74.29, RMSE=131.66, MAPE=487.35, MedAE=20.36, R2=0.660\n",
            "COTTON | GradientBoosting | with_network | Fold 3: MAE=73.76, RMSE=133.02, MAPE=502.50, MedAE=11.92, R2=0.653\n",
            "\n",
            "===== MODELING SUGARCANE =====\n",
            "SUGARCANE | Naive | no_network | Fold 1: MAE=848.16, RMSE=1574.76, MAPE=20.36, MedAE=427.70, R2=0.740\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 1: MAE=853.25, RMSE=1484.17, MAPE=21.11, MedAE=459.92, R2=0.769\n",
            "SUGARCANE | Ridge | no_network | Fold 1: MAE=845.71, RMSE=1429.19, MAPE=21.91, MedAE=425.75, R2=0.786\n",
            "SUGARCANE | RandomForest | no_network | Fold 1: MAE=890.23, RMSE=1494.05, MAPE=23.04, MedAE=501.58, R2=0.766\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 1: MAE=879.28, RMSE=1494.54, MAPE=21.12, MedAE=484.66, R2=0.766\n",
            "SUGARCANE | Naive | no_network | Fold 2: MAE=921.11, RMSE=1722.73, MAPE=24.36, MedAE=411.06, R2=0.708\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 2: MAE=930.12, RMSE=1585.51, MAPE=25.36, MedAE=477.78, R2=0.753\n",
            "SUGARCANE | Ridge | no_network | Fold 2: MAE=936.09, RMSE=1541.29, MAPE=27.52, MedAE=481.24, R2=0.766\n",
            "SUGARCANE | RandomForest | no_network | Fold 2: MAE=985.46, RMSE=1631.83, MAPE=29.29, MedAE=553.77, R2=0.738\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 2: MAE=957.85, RMSE=1589.13, MAPE=26.12, MedAE=516.26, R2=0.752\n",
            "SUGARCANE | Naive | no_network | Fold 3: MAE=1207.34, RMSE=2255.80, MAPE=26.08, MedAE=462.09, R2=0.547\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 3: MAE=1214.23, RMSE=2020.01, MAPE=27.20, MedAE=583.33, R2=0.637\n",
            "SUGARCANE | Ridge | no_network | Fold 3: MAE=1209.93, RMSE=1987.66, MAPE=27.74, MedAE=558.83, R2=0.649\n",
            "SUGARCANE | RandomForest | no_network | Fold 3: MAE=1249.70, RMSE=2099.99, MAPE=28.50, MedAE=607.68, R2=0.608\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 3: MAE=1228.11, RMSE=2069.58, MAPE=26.46, MedAE=555.76, R2=0.619\n",
            "SUGARCANE | Naive | with_network | Fold 1: MAE=848.16, RMSE=1574.76, MAPE=20.36, MedAE=427.70, R2=0.740\n",
            "SUGARCANE | RollingMean3 | with_network | Fold 1: MAE=853.25, RMSE=1484.17, MAPE=21.11, MedAE=459.92, R2=0.769\n",
            "SUGARCANE | Ridge | with_network | Fold 1: MAE=848.10, RMSE=1430.06, MAPE=21.91, MedAE=430.75, R2=0.786\n",
            "SUGARCANE | RandomForest | with_network | Fold 1: MAE=885.67, RMSE=1484.38, MAPE=22.92, MedAE=501.98, R2=0.769\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 1: MAE=876.61, RMSE=1490.79, MAPE=21.04, MedAE=478.51, R2=0.767\n",
            "SUGARCANE | Naive | with_network | Fold 2: MAE=921.11, RMSE=1722.73, MAPE=24.36, MedAE=411.06, R2=0.708\n",
            "SUGARCANE | RollingMean3 | with_network | Fold 2: MAE=930.12, RMSE=1585.51, MAPE=25.36, MedAE=477.78, R2=0.753\n",
            "SUGARCANE | Ridge | with_network | Fold 2: MAE=934.68, RMSE=1540.74, MAPE=27.43, MedAE=479.82, R2=0.766\n",
            "SUGARCANE | RandomForest | with_network | Fold 2: MAE=1003.64, RMSE=1625.63, MAPE=29.20, MedAE=564.18, R2=0.740\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 2: MAE=967.64, RMSE=1600.71, MAPE=26.23, MedAE=521.34, R2=0.748\n",
            "SUGARCANE | Naive | with_network | Fold 3: MAE=1207.34, RMSE=2255.80, MAPE=26.08, MedAE=462.09, R2=0.547\n",
            "SUGARCANE | RollingMean3 | with_network | Fold 3: MAE=1214.23, RMSE=2020.01, MAPE=27.20, MedAE=583.33, R2=0.637\n",
            "SUGARCANE | Ridge | with_network | Fold 3: MAE=1208.18, RMSE=1988.20, MAPE=27.84, MedAE=551.11, R2=0.648\n",
            "SUGARCANE | RandomForest | with_network | Fold 3: MAE=1244.45, RMSE=2081.44, MAPE=28.77, MedAE=592.19, R2=0.615\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 3: MAE=1230.47, RMSE=2066.49, MAPE=26.79, MedAE=565.55, R2=0.620\n",
            "\n",
            "Performance summary for COTTON (no_network):\n",
            "  Crop            Model FeatureSet  MAE_mean   MAE_std  RMSE_mean  RMSE_std  MAPE_mean   MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "COTTON GradientBoosting no_network 56.750866 14.069392 108.843492 20.615898 178.296097 245.109207    8.456924   1.129174 0.630598 0.068017\n",
            "COTTON            Naive no_network 53.108523 13.872640 115.621328 26.720687 149.691277 193.898543    0.000000   0.000000 0.581646 0.118101\n",
            "COTTON     RandomForest no_network 56.469262 13.851599 108.490460 20.293864 185.161217 256.619869   13.216022   2.922958 0.633881 0.056582\n",
            "COTTON            Ridge no_network 57.321898 12.597933 103.551154 19.917927 189.381690 267.630411   14.747723   1.791373 0.666032 0.060025\n",
            "COTTON     RollingMean3 no_network 53.328040 12.485999 106.189259 19.623983 224.664992 325.558916    4.158889   1.706134 0.648159 0.063543\n",
            "\n",
            "Performance summary for COTTON (with_network):\n",
            "  Crop            Model   FeatureSet  MAE_mean   MAE_std  RMSE_mean  RMSE_std  MAPE_mean   MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "COTTON GradientBoosting with_network 57.071600 14.527851 109.684541 20.602284 191.818750 269.068471   10.547865   1.259456 0.624988 0.066656\n",
            "COTTON            Naive with_network 53.108523 13.872640 115.621328 26.720687 149.691277 193.898543    0.000000   0.000000 0.581646 0.118101\n",
            "COTTON     RandomForest with_network 57.309745 14.719780 107.893154 20.731659 186.674902 260.407548   16.353258   3.472115 0.638682 0.051876\n",
            "COTTON            Ridge with_network 56.963526 12.754979 103.471293 19.948850 188.841025 266.439625   17.575154   2.807824 0.666608 0.059664\n",
            "COTTON     RollingMean3 with_network 53.328040 12.485999 106.189259 19.623983 224.664992 325.558916    4.158889   1.706134 0.648159 0.063543\n",
            "\n",
            "Performance summary for GROUNDNUT (no_network):\n",
            "     Crop            Model FeatureSet   MAE_mean   MAE_std  RMSE_mean  RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "GROUNDNUT GradientBoosting no_network 252.302285 19.967084 378.056230 35.027534  37.811331 11.576749  158.167640  10.943938 0.622863 0.087359\n",
            "GROUNDNUT            Naive no_network 239.009815  8.448145 400.024337 21.693489  37.417441  9.523584  123.080000   4.749705 0.571686 0.123182\n",
            "GROUNDNUT     RandomForest no_network 250.376515 15.759898 371.834706 24.902103  38.358237 12.139124  167.560272  11.167113 0.629620 0.111957\n",
            "GROUNDNUT            Ridge no_network 244.201963 13.613109 350.476605 26.721716  33.897764  8.937333  150.540593  11.052257 0.673173 0.088577\n",
            "GROUNDNUT     RollingMean3 no_network 226.686450 10.413719 353.465909 23.042697  34.234681  9.242275  147.527778   4.476748 0.665492 0.099648\n",
            "\n",
            "Performance summary for GROUNDNUT (with_network):\n",
            "     Crop            Model   FeatureSet   MAE_mean   MAE_std  RMSE_mean  RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "GROUNDNUT GradientBoosting with_network 253.666136 19.184231 375.419967 30.371178  37.749185 11.920704  159.119674  11.483774 0.626564 0.092717\n",
            "GROUNDNUT            Naive with_network 239.009815  8.448145 400.024337 21.693489  37.417441  9.523584  123.080000   4.749705 0.571686 0.123182\n",
            "GROUNDNUT     RandomForest with_network 248.177658 17.104124 366.169260 26.094922  37.491593 11.730678  163.840520  13.794700 0.641800 0.104125\n",
            "GROUNDNUT            Ridge with_network 244.177002 13.721452 350.459655 26.713326  34.042773  9.094179  150.631683  10.904518 0.673192 0.088646\n",
            "GROUNDNUT     RollingMean3 with_network 226.686450 10.413719 353.465909 23.042697  34.234681  9.242275  147.527778   4.476748 0.665492 0.099648\n",
            "\n",
            "Performance summary for MAIZE (no_network):\n",
            " Crop            Model FeatureSet   MAE_mean   MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "MAIZE GradientBoosting no_network 423.583845 77.689232 661.923670 133.281011  31.086303  6.214960  259.295810  34.616787 0.627227 0.070335\n",
            "MAIZE            Naive no_network 423.743168 71.735525 689.944745 128.776115  32.222673  4.956916  250.680000  17.709794 0.590222 0.100541\n",
            "MAIZE     RandomForest no_network 429.297851 73.622344 660.306878 117.120905  31.771972  6.637432  275.740538  33.461428 0.624310 0.087766\n",
            "MAIZE            Ridge no_network 410.801899 75.651667 621.712432 123.543123  29.889858  5.491483  255.223682  39.315941 0.670427 0.065861\n",
            "MAIZE     RollingMean3 no_network 402.780461 69.621445 634.636856 119.856666  30.020771  5.466128  255.255556  25.144892 0.654687 0.076263\n",
            "\n",
            "Performance summary for MAIZE (with_network):\n",
            " Crop            Model   FeatureSet   MAE_mean   MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "MAIZE GradientBoosting with_network 428.269018 87.384258 665.360496 139.720460  30.965542  6.295781  265.810374  43.800476 0.624923 0.065229\n",
            "MAIZE            Naive with_network 423.743168 71.735525 689.944745 128.776115  32.222673  4.956916  250.680000  17.709794 0.590222 0.100541\n",
            "MAIZE     RandomForest with_network 428.256318 77.686624 655.579346 116.552632  31.451546  6.772509  276.674986  39.777781 0.629746 0.086272\n",
            "MAIZE            Ridge with_network 410.112173 75.051956 621.488035 123.460234  29.881004  5.502053  254.200882  37.861025 0.670642 0.065946\n",
            "MAIZE     RollingMean3 with_network 402.780461 69.621445 634.636856 119.856666  30.020771  5.466128  255.255556  25.144892 0.654687 0.076263\n",
            "\n",
            "Performance summary for RICE (no_network):\n",
            "Crop            Model FeatureSet   MAE_mean   MAE_std  RMSE_mean  RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "RICE GradientBoosting no_network 262.650491 18.026411 382.997477 34.595104  21.702241  2.085943  172.622372   4.538550 0.844287 0.017059\n",
            "RICE            Naive no_network 273.904740 15.753798 421.185895 41.548700  22.249600  2.044237  171.566667   8.269742 0.812360 0.012222\n",
            "RICE     RandomForest no_network 269.946681 19.926112 392.704125 39.829418  22.267585  2.120288  185.319034   6.084669 0.836642 0.015870\n",
            "RICE            Ridge no_network 254.824569 19.822356 371.408388 37.840812  20.878594  1.771927  166.372185   6.476838 0.853988 0.012582\n",
            "RICE     RollingMean3 no_network 256.619943 21.170554 378.770377 40.335867  20.583837  1.431600  173.898889   8.991003 0.848186 0.013808\n",
            "\n",
            "Performance summary for RICE (with_network):\n",
            "Crop            Model   FeatureSet   MAE_mean   MAE_std  RMSE_mean  RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "RICE GradientBoosting with_network 265.795376 18.281757 387.763123 34.106877  21.437446  1.918738  175.682079   6.264034 0.839827 0.023805\n",
            "RICE            Naive with_network 273.904740 15.753798 421.185895 41.548700  22.249600  2.044237  171.566667   8.269742 0.812360 0.012222\n",
            "RICE     RandomForest with_network 269.140393 23.332733 389.774352 43.254342  21.855556  1.678983  184.082564   7.463704 0.839444 0.012717\n",
            "RICE            Ridge with_network 254.073108 19.610411 371.121213 37.674171  20.814957  1.769131  167.394183   6.778732 0.854220 0.012342\n",
            "RICE     RollingMean3 with_network 256.619943 21.170554 378.770377 40.335867  20.583837  1.431600  173.898889   8.991003 0.848186 0.013808\n",
            "\n",
            "Performance summary for SUGARCANE (no_network):\n",
            "     Crop            Model FeatureSet    MAE_mean    MAE_std   RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "SUGARCANE GradientBoosting no_network 1021.747833 182.980762 1717.752672 308.341948  24.566322  2.993744  518.891582  35.623277 0.712234 0.081052\n",
            "SUGARCANE            Naive no_network  992.200001 189.850369 1851.094594 358.207997  23.602330  2.936956  433.616667  26.024420 0.665251 0.103352\n",
            "SUGARCANE     RandomForest no_network 1041.794663 186.240350 1741.954022 317.626034  26.944453  3.405556  554.343244  53.050923 0.704017 0.084563\n",
            "SUGARCANE            Ridge no_network  997.241505 189.654673 1652.711527 295.439483  25.722581  3.301921  488.605628  66.846573 0.733670 0.074350\n",
            "SUGARCANE     RollingMean3 no_network  999.199373 190.144866 1696.564838 284.659978  24.554944  3.125227  507.011111  66.697051 0.719700 0.072058\n",
            "\n",
            "Performance summary for SUGARCANE (with_network):\n",
            "     Crop            Model   FeatureSet    MAE_mean    MAE_std   RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "SUGARCANE GradientBoosting with_network 1024.907381 183.747600 1719.329070 305.633178  24.684788  3.172056  521.800581  43.520979 0.711794 0.079947\n",
            "SUGARCANE            Naive with_network  992.200001 189.850369 1851.094594 358.207997  23.602330  2.936956  433.616667  26.024420 0.665251 0.103352\n",
            "SUGARCANE     RandomForest with_network 1044.584553 182.861369 1730.480908 312.032823  26.967548  3.507865  552.784696  46.171064 0.707984 0.082150\n",
            "SUGARCANE            Ridge with_network  996.984767 187.950318 1653.001146 295.519832  25.725268  3.313246  487.225391  60.524847 0.733574 0.074403\n",
            "SUGARCANE     RollingMean3 with_network  999.199373 190.144866 1696.564838 284.659978  24.554944  3.125227  507.011111  66.697051 0.719700 0.072058\n",
            "\n",
            "Performance summary for WHEAT (no_network):\n",
            " Crop            Model FeatureSet   MAE_mean   MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "WHEAT GradientBoosting no_network 278.039886 44.247222 459.580146 111.510779  18.074461  1.279491  165.611782  19.977310 0.811591 0.132236\n",
            "WHEAT            Naive no_network 260.971058 45.937542 411.087148  77.431708  18.381683  0.638980  162.990000  19.220866 0.867564 0.021132\n",
            "WHEAT     RandomForest no_network 268.370069 42.703076 401.340941  70.459199  18.107675  0.570460  178.071549  19.891881 0.872028 0.029849\n",
            "WHEAT            Ridge no_network 245.097102 45.568315 364.624431  76.290851  16.788752  0.506005  156.304501  21.229968 0.896136 0.018634\n",
            "WHEAT     RollingMean3 no_network 245.912575 52.201683 371.559825  82.795212  16.923115  0.868304  162.781111  27.259788 0.892058 0.022765\n",
            "\n",
            "Performance summary for WHEAT (with_network):\n",
            " Crop            Model   FeatureSet   MAE_mean   MAE_std  RMSE_mean  RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "WHEAT GradientBoosting with_network 275.484234 44.590366 439.888373 89.682624  17.868608  1.087017  168.576367  23.609312 0.833921 0.095121\n",
            "WHEAT            Naive with_network 260.971058 45.937542 411.087148 77.431708  18.381683  0.638980  162.990000  19.220866 0.867564 0.021132\n",
            "WHEAT     RandomForest with_network 267.096648 43.446527 396.746786 72.872590  17.919331  0.551634  176.163141  18.450468 0.875535 0.026623\n",
            "WHEAT            Ridge with_network 245.300335 45.476302 364.709339 76.316051  16.783924  0.513273  156.432705  21.554388 0.896085 0.018665\n",
            "WHEAT     RollingMean3 with_network 245.912575 52.201683 371.559825 82.795212  16.923115  0.868304  162.781111  27.259788 0.892058 0.022765\n",
            "\n",
            "Saved model performance summary to: /content/drive/MyDrive/Shiny/ICRISAT/Results/model_performance_summary.csv\n",
            "\n",
            "===== FINAL SUMMARY =====\n",
            "  COTTON: RollingMean3 (FeatureSet=with_network), MAE_mean=53.33, R2_mean=0.648\n",
            "  GROUNDNUT: RollingMean3 (FeatureSet=with_network), MAE_mean=226.69, R2_mean=0.665\n",
            "  MAIZE: RollingMean3 (FeatureSet=with_network), MAE_mean=402.78, R2_mean=0.655\n",
            "  RICE: Ridge (FeatureSet=with_network), MAE_mean=254.07, R2_mean=0.854\n",
            "  SUGARCANE: Ridge (FeatureSet=with_network), MAE_mean=996.98, R2_mean=0.734\n",
            "  WHEAT: Ridge (FeatureSet=with_network), MAE_mean=245.30, R2_mean=0.896\n",
            "Saved diagnostic plots for COTTON (RollingMean3, feature set=with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved diagnostic plots for GROUNDNUT (RollingMean3, feature set=with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved diagnostic plots for MAIZE (RollingMean3, feature set=with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved diagnostic plots for RICE (Ridge, feature set=with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved diagnostic plots for SUGARCANE (Ridge, feature set=with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved diagnostic plots for WHEAT (Ridge, feature set=with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "\n",
            "===== PIPELINE COMPLETE =====\n",
            "Rows after cleaning: 16146\n",
            "Years: 1966 - 2017\n",
            "Number of districts (by Dist Code): 311\n",
            "Crops modeled: ['RICE', 'WHEAT', 'MAIZE', 'GROUNDNUT', 'COTTON', 'SUGARCANE']\n",
            "Cleaned dataset with features: /content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\n",
            "Model performance summary: /content/drive/MyDrive/Shiny/ICRISAT/Results/model_performance_summary.csv\n",
            "Supervised panel CSV prefix: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_\n",
            "Key PDF plots saved in OUTPUT_DIR (diagnostic scatter + residuals for best models).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        "    median_absolute_error,\n",
        ")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# CONFIG\n",
        "# -----------------------------------------------------------------------------\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# IMPORTANT: set this to your actual raw ICRISAT CSV if you want to start from raw.\n",
        "# Example:\n",
        "# RAW_CSV_PATH = \"/content/drive/MyDrive/Shiny/ICRISAT/ICRISAT_district_panel_1966_2017.csv\"\n",
        "RAW_CSV_PATH = \"/content/drive/MyDrive/Shiny/ICRISAT/icrisat_raw.csv\"\n",
        "\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Shiny/ICRISAT/Results\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "CLEANED_CSV_PATH = os.path.join(OUTPUT_DIR, \"icrisat_cleaned_with_features.csv\")\n",
        "MODEL_PERF_PATH = os.path.join(OUTPUT_DIR, \"model_performance_summary.csv\")\n",
        "SUPERVISED_PANEL_PREFIX = os.path.join(OUTPUT_DIR, \"supervised_panel_\")\n",
        "\n",
        "# Six main crops to model\n",
        "CROP_YIELD_COLS = {\n",
        "    \"RICE\": \"RICE YIELD (Kg per ha)\",\n",
        "    \"WHEAT\": \"WHEAT YIELD (Kg per ha)\",\n",
        "    \"MAIZE\": \"MAIZE YIELD (Kg per ha)\",\n",
        "    \"GROUNDNUT\": \"GROUNDNUT YIELD (Kg per ha)\",\n",
        "    \"COTTON\": \"COTTON YIELD (Kg per ha)\",\n",
        "    \"SUGARCANE\": \"SUGARCANE YIELD (Kg per ha)\",\n",
        "}\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# DATA LOADER\n",
        "# -----------------------------------------------------------------------------\n",
        "def load_icrisat_dataframe():\n",
        "    \"\"\"\n",
        "    Robust loader:\n",
        "    1) Try RAW_CSV_PATH (for starting from raw data).\n",
        "    2) If not found, try CLEANED_CSV_PATH as fallback (for re-running modeling).\n",
        "    \"\"\"\n",
        "    if os.path.exists(RAW_CSV_PATH):\n",
        "        print(f\"Loading RAW dataset from: {RAW_CSV_PATH}\")\n",
        "        df = pd.read_csv(RAW_CSV_PATH)\n",
        "        return df, \"raw\"\n",
        "    elif os.path.exists(CLEANED_CSV_PATH):\n",
        "        print(\n",
        "            f\"RAW_CSV_PATH not found.\\n\"\n",
        "            f\"Falling back to existing CLEANED dataset: {CLEANED_CSV_PATH}\"\n",
        "        )\n",
        "        df = pd.read_csv(CLEANED_CSV_PATH)\n",
        "        return df, \"cleaned\"\n",
        "    else:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Neither RAW_CSV_PATH nor CLEANED_CSV_PATH exists.\\n\"\n",
        "            f\"RAW_CSV_PATH = {RAW_CSV_PATH}\\n\"\n",
        "            f\"CLEANED_CSV_PATH = {CLEANED_CSV_PATH}\\n\"\n",
        "            f\"Please update RAW_CSV_PATH to the correct CSV file.\"\n",
        "        )\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# UTILITIES\n",
        "# -----------------------------------------------------------------------------\n",
        "def safe_mape(y_true, y_pred):\n",
        "    \"\"\"MAPE computed only on strictly positive targets (in %).\"\"\"\n",
        "    y_true = np.asarray(y_true, dtype=float)\n",
        "    y_pred = np.asarray(y_pred, dtype=float)\n",
        "    mask = np.abs(y_true) > 1e-6\n",
        "    if not np.any(mask):\n",
        "        return np.nan\n",
        "    return np.mean(np.abs(y_true[mask] - y_pred[mask]) / np.abs(y_true[mask])) * 100.0\n",
        "\n",
        "\n",
        "def compute_metrics(y_true, y_pred):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    # sklearn version may not support squared=False, so compute RMSE manually\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    medae = median_absolute_error(y_true, y_pred)\n",
        "    mape = safe_mape(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    return mae, rmse, mape, medae, r2\n",
        "\n",
        "\n",
        "def make_time_series_folds(df, time_col=\"Year\", n_splits=3):\n",
        "    \"\"\"\n",
        "    Expanding-window time-series CV on the *year* dimension.\n",
        "    Years are split into (n_splits + 1) contiguous blocks.\n",
        "    For fold k, train on blocks [0..k-1], test on block k.\n",
        "    \"\"\"\n",
        "    years = np.sort(df[time_col].unique())\n",
        "    blocks = np.array_split(years, n_splits + 1)  # e.g. 4 blocks for 3 folds\n",
        "    folds = []\n",
        "    for k in range(1, len(blocks)):\n",
        "        train_years = np.concatenate(blocks[:k])\n",
        "        test_years = blocks[k]\n",
        "        folds.append((set(train_years), set(test_years)))\n",
        "    return folds\n",
        "\n",
        "\n",
        "def make_model(model_name):\n",
        "    \"\"\"Instantiate a fresh sklearn model object for the given name.\"\"\"\n",
        "    if model_name == \"Ridge\":\n",
        "        model = Pipeline(\n",
        "            [\n",
        "                (\"scaler\", StandardScaler()),\n",
        "                (\"ridge\", Ridge(alpha=1.0)),\n",
        "            ]\n",
        "        )\n",
        "    elif model_name == \"RandomForest\":\n",
        "        model = RandomForestRegressor(\n",
        "            n_estimators=400,\n",
        "            max_depth=None,\n",
        "            min_samples_leaf=2,\n",
        "            random_state=RANDOM_STATE,\n",
        "            n_jobs=-1,\n",
        "        )\n",
        "    elif model_name == \"GradientBoosting\":\n",
        "        model = GradientBoostingRegressor(\n",
        "            n_estimators=500,\n",
        "            learning_rate=0.05,\n",
        "            max_depth=3,\n",
        "            random_state=RANDOM_STATE,\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
        "    return model\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# BASIC EDA + CLEANING\n",
        "# -----------------------------------------------------------------------------\n",
        "def basic_eda(df):\n",
        "    print(\"===== BASIC EDA =====\")\n",
        "    # key uniqueness\n",
        "    dup_count = (\n",
        "        df.groupby([\"Dist Code\", \"Year\"])\n",
        "        .size()\n",
        "        .reset_index(name=\"n\")\n",
        "        .query(\"n > 1\")\n",
        "        .shape[0]\n",
        "    )\n",
        "    print(f\"Duplicate (Dist Code, Year) rows: {dup_count}\")\n",
        "    if dup_count == 0:\n",
        "        print(\"Key (Dist Code, Year) is unique.\\n\")\n",
        "\n",
        "    print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
        "    if \"Year\" in df.columns:\n",
        "        print(f\"Time range: {df['Year'].min()} - {df['Year'].max()}\")\n",
        "    if \"State Name\" in df.columns:\n",
        "        print(f\"Unique States: {df['State Name'].nunique()}\")\n",
        "    if \"District Name\" in df.columns:\n",
        "        print(f\"Unique Districts: {df['District Name'].nunique()}\")\n",
        "\n",
        "    # Yield columns\n",
        "    yield_cols = [c for c in df.columns if \"YIELD\" in c]\n",
        "    crops = [c.replace(\" YIELD (Kg per ha)\", \"\").strip() for c in yield_cols]\n",
        "    print(f\"Detected crops (count={len(crops)}): {sorted(set(crops))[:20]}...\")\n",
        "\n",
        "    # Missingness\n",
        "    miss = df[yield_cols].isna().mean().sort_values() * 100\n",
        "    miss_df = (\n",
        "        miss.reset_index()\n",
        "        .rename(columns={\"index\": \"YieldColumn\", 0: \"MissingPct\"})\n",
        "    )\n",
        "    print(\"\\nYield missingness (% of NaN):\")\n",
        "    print(miss_df.to_string(index=False))\n",
        "\n",
        "    # Descriptive stats for main crops (if present)\n",
        "    for crop, ycol in CROP_YIELD_COLS.items():\n",
        "        if ycol in df.columns:\n",
        "            print(f\"\\nSummary for {crop} yield:\")\n",
        "            print(df[ycol].describe())\n",
        "\n",
        "\n",
        "def clip_yield_outliers(df, upper_quantile=0.99):\n",
        "    \"\"\"Clip yield columns at [0, q] to remove extreme outliers.\"\"\"\n",
        "    print(\"\\n===== CLEANING DATA =====\")\n",
        "    yield_cols = [c for c in df.columns if \"YIELD\" in c]\n",
        "    for col in yield_cols:\n",
        "        old_max = df[col].max()\n",
        "        q = df[col].quantile(upper_quantile)\n",
        "        df[col] = df[col].clip(lower=0, upper=q)\n",
        "        new_max = df[col].max()\n",
        "        crop_name = col.replace(\" YIELD (Kg per ha)\", \"\").strip()\n",
        "        print(\n",
        "            f\"Clipped {crop_name} yield: old max={old_max:.2f}, new max={new_max:.2f}\"\n",
        "        )\n",
        "    return df\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# DIVERSIFICATION + NETWORKS\n",
        "# -----------------------------------------------------------------------------\n",
        "def compute_diversification(df):\n",
        "    \"\"\"Compute Herfindahl and diversification index using area columns.\"\"\"\n",
        "    print(\"\\n===== COMPUTING DIVERSIFICATION =====\")\n",
        "    area_cols = [\n",
        "        c\n",
        "        for c in df.columns\n",
        "        if \"AREA\" in c.upper() and \"YIELD\" not in c.upper()\n",
        "    ]\n",
        "    if not area_cols:\n",
        "        print(\"No AREA columns found  diversification indices will be NaN.\")\n",
        "        df[\"HERFINDAHL\"] = np.nan\n",
        "        df[\"DIVERSIFICATION_INDEX\"] = np.nan\n",
        "        return df, area_cols\n",
        "\n",
        "    area_df = df[[\"Dist Code\", \"Year\"] + area_cols].copy()\n",
        "    area_df[area_cols] = area_df[area_cols].clip(lower=0).fillna(0)\n",
        "\n",
        "    total_area = area_df[area_cols].sum(axis=1)\n",
        "    shares = area_df[area_cols].div(\n",
        "        total_area.replace({0: np.nan}), axis=0\n",
        "    )\n",
        "    hhi = (shares ** 2).sum(axis=1)\n",
        "\n",
        "    df[\"HERFINDAHL\"] = hhi.values\n",
        "    df[\"DIVERSIFICATION_INDEX\"] = 1.0 - hhi.values\n",
        "\n",
        "    return df, area_cols\n",
        "\n",
        "\n",
        "def build_district_similarity_network(df, area_cols,\n",
        "                                      start_year=2008, end_year=2017,\n",
        "                                      corr_threshold=0.7):\n",
        "    print(\"\\n===== BUILDING DISTRICT SIMILARITY NETWORK =====\")\n",
        "    print(f\"Network reference window: {start_year}-{end_year}\")\n",
        "\n",
        "    window = df[(df[\"Year\"] >= start_year) & (df[\"Year\"] <= end_year)].copy()\n",
        "    if window.empty:\n",
        "        raise ValueError(\"No data in the specified reference window.\")\n",
        "\n",
        "    valid_area_cols = [c for c in area_cols if c in window.columns]\n",
        "    if not valid_area_cols:\n",
        "        raise ValueError(\"No valid area columns found for network building.\")\n",
        "\n",
        "    window[valid_area_cols] = window[valid_area_cols].clip(lower=0).fillna(0)\n",
        "\n",
        "    # Aggregate to district-level crop area shares over the window\n",
        "    grouped = window.groupby(\"Dist Code\")[valid_area_cols].sum()\n",
        "    total = grouped.sum(axis=1)\n",
        "    shares = grouped.div(total.replace({0: np.nan}), axis=0).fillna(0)\n",
        "\n",
        "    corr = shares.T.corr()\n",
        "\n",
        "    G = nx.Graph()\n",
        "    for dist in shares.index:\n",
        "        G.add_node(dist)\n",
        "\n",
        "    dists = list(shares.index)\n",
        "    for i in range(len(dists)):\n",
        "        for j in range(i + 1, len(dists)):\n",
        "            d1, d2 = dists[i], dists[j]\n",
        "            w = corr.loc[d1, d2]\n",
        "            if np.isfinite(w) and w >= corr_threshold:\n",
        "                G.add_edge(d1, d2, weight=float(w))\n",
        "\n",
        "    print(f\"District network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "    return G\n",
        "\n",
        "\n",
        "def build_crop_cooccurrence_network(df, area_cols, min_area=1e-6):\n",
        "    print(\"\\n===== BUILDING CROP-COOCCURRENCE NETWORK =====\")\n",
        "    valid_area_cols = [c for c in area_cols if c in df.columns]\n",
        "    if not valid_area_cols:\n",
        "        raise ValueError(\"No valid area columns for crop network.\")\n",
        "\n",
        "    crop_names = [\n",
        "        c.replace(\"AREA\", \"\")\n",
        "        .replace(\"(000 ha)\", \"\")\n",
        "        .replace(\"(\", \"\")\n",
        "        .replace(\")\", \"\")\n",
        "        .replace(\"  \", \" \")\n",
        "        .replace(\"  \", \" \")\n",
        "        .strip()\n",
        "        for c in valid_area_cols\n",
        "    ]\n",
        "\n",
        "    G = nx.Graph()\n",
        "    for crop in crop_names:\n",
        "        G.add_node(crop)\n",
        "\n",
        "    arr = df[valid_area_cols].fillna(0).values\n",
        "    for row in arr:\n",
        "        active = [\n",
        "            crop\n",
        "            for crop, val in zip(crop_names, row)\n",
        "            if val > min_area\n",
        "        ]\n",
        "        for i in range(len(active)):\n",
        "            for j in range(i + 1, len(active)):\n",
        "                c1, c2 = active[i], active[j]\n",
        "                if G.has_edge(c1, c2):\n",
        "                    G[c1][c2][\"weight\"] += 1\n",
        "                else:\n",
        "                    G.add_edge(c1, c2, weight=1)\n",
        "\n",
        "    print(f\"Crop network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "    return G\n",
        "\n",
        "\n",
        "def add_district_network_features(df, G):\n",
        "    \"\"\"Map district-level network metrics back to the full panel.\"\"\"\n",
        "    degree_dict = dict(G.degree(weight=None))\n",
        "    strength_dict = dict(G.degree(weight=\"weight\"))\n",
        "    betw_dict = nx.betweenness_centrality(G, weight=\"weight\", normalized=True)\n",
        "\n",
        "    df[\"DIST_DEGREE\"] = df[\"Dist Code\"].map(degree_dict).fillna(0).astype(float)\n",
        "    df[\"DIST_STRENGTH\"] = df[\"Dist Code\"].map(strength_dict).fillna(0).astype(float)\n",
        "    df[\"DIST_BETWEENNESS\"] = df[\"Dist Code\"].map(betw_dict).fillna(0.0).astype(float)\n",
        "    return df\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# SUPERVISED PANEL CONSTRUCTION\n",
        "# -----------------------------------------------------------------------------\n",
        "def build_supervised_panel_for_crop(df, crop_name, yield_col,\n",
        "                                    min_year=1970,\n",
        "                                    save_prefix=SUPERVISED_PANEL_PREFIX):\n",
        "    \"\"\"\n",
        "    Build a panel with:\n",
        "      - TARGET_YIELD\n",
        "      - lags: Y_LAG1, Y_LAG2, Y_LAG3\n",
        "      - lagged rolling mean: Y_ROLL_MEAN3\n",
        "      - diversification + network features (if present)\n",
        "    \"\"\"\n",
        "    cols = [\"Dist Code\", \"Year\", yield_col]\n",
        "\n",
        "    for extra_col in [\n",
        "        \"State Name\",\n",
        "        \"District Name\",\n",
        "        \"DIVERSIFICATION_INDEX\",\n",
        "        \"HERFINDAHL\",\n",
        "        \"DIST_DEGREE\",\n",
        "        \"DIST_STRENGTH\",\n",
        "        \"DIST_BETWEENNESS\",\n",
        "    ]:\n",
        "        if extra_col in df.columns:\n",
        "            cols.append(extra_col)\n",
        "\n",
        "    cols = list(dict.fromkeys(cols))  # remove duplicates\n",
        "    sub = df[cols].copy()\n",
        "    sub = sub[sub[\"Year\"] >= min_year]\n",
        "    sub = sub.sort_values([\"Dist Code\", \"Year\"]).reset_index(drop=True)\n",
        "\n",
        "    # Lags\n",
        "    sub[\"Y_LAG1\"] = sub.groupby(\"Dist Code\")[yield_col].shift(1)\n",
        "    sub[\"Y_LAG2\"] = sub.groupby(\"Dist Code\")[yield_col].shift(2)\n",
        "    sub[\"Y_LAG3\"] = sub.groupby(\"Dist Code\")[yield_col].shift(3)\n",
        "\n",
        "    # Rolling mean of the last 3 years, lagged by 1 year\n",
        "    roll = (\n",
        "        sub.groupby(\"Dist Code\")[yield_col]\n",
        "        .rolling(window=3, min_periods=3)\n",
        "        .mean()\n",
        "        .shift(1)\n",
        "        .reset_index(level=0, drop=True)\n",
        "    )\n",
        "    sub[\"Y_ROLL_MEAN3\"] = roll\n",
        "\n",
        "    sub = sub.rename(columns={yield_col: \"TARGET_YIELD\"})\n",
        "\n",
        "    # Require target + at least lag1 and rolling mean to exist\n",
        "    sub = sub.dropna(\n",
        "        subset=[\"TARGET_YIELD\", \"Y_LAG1\", \"Y_ROLL_MEAN3\"]\n",
        "    ).reset_index(drop=True)\n",
        "\n",
        "    # Save to CSV\n",
        "    out_path = f\"{save_prefix}{crop_name.lower()}.csv\"\n",
        "    sub.to_csv(out_path, index=False)\n",
        "    print(f\"\\nSaved supervised panel for {crop_name} to: {out_path}\")\n",
        "\n",
        "    return sub\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# MODELING + EVALUATION\n",
        "# -----------------------------------------------------------------------------\n",
        "def evaluate_models_for_crop(crop_name, panel_df, records):\n",
        "    print(f\"\\n===== MODELING {crop_name} =====\")\n",
        "    folds = make_time_series_folds(panel_df, time_col=\"Year\", n_splits=3)\n",
        "\n",
        "    base_features = [\n",
        "        \"Y_LAG1\",\n",
        "        \"Y_LAG2\",\n",
        "        \"Y_LAG3\",\n",
        "        \"Y_ROLL_MEAN3\",\n",
        "        \"DIVERSIFICATION_INDEX\",\n",
        "        \"HERFINDAHL\",\n",
        "    ]\n",
        "    base_features = [f for f in base_features if f in panel_df.columns]\n",
        "\n",
        "    network_features = [\n",
        "        \"DIST_DEGREE\",\n",
        "        \"DIST_STRENGTH\",\n",
        "        \"DIST_BETWEENNESS\",\n",
        "    ]\n",
        "    network_features = [f for f in network_features if f in panel_df.columns]\n",
        "\n",
        "    models_to_run = [\"Naive\", \"RollingMean3\", \"Ridge\", \"RandomForest\", \"GradientBoosting\"]\n",
        "\n",
        "    for feature_set in [\"no_network\", \"with_network\"]:\n",
        "        if feature_set == \"no_network\":\n",
        "            feature_cols = base_features\n",
        "        else:\n",
        "            feature_cols = base_features + network_features\n",
        "\n",
        "        feature_cols = [c for c in feature_cols if c in panel_df.columns]\n",
        "        if not feature_cols and feature_set == \"with_network\":\n",
        "            # If network features missing, skip with_network\n",
        "            continue\n",
        "\n",
        "        for fold_idx, (train_years, test_years) in enumerate(folds, start=1):\n",
        "            train_mask = panel_df[\"Year\"].isin(train_years)\n",
        "            test_mask = panel_df[\"Year\"].isin(test_years)\n",
        "\n",
        "            X_train = panel_df.loc[train_mask, feature_cols]\n",
        "            X_test = panel_df.loc[test_mask, feature_cols]\n",
        "            y_train = panel_df.loc[train_mask, \"TARGET_YIELD\"].values\n",
        "            y_test = panel_df.loc[test_mask, \"TARGET_YIELD\"].values\n",
        "\n",
        "            for model_name in models_to_run:\n",
        "                if model_name == \"Naive\":\n",
        "                    y_pred = panel_df.loc[test_mask, \"Y_LAG1\"].values\n",
        "                elif model_name == \"RollingMean3\":\n",
        "                    y_pred = panel_df.loc[test_mask, \"Y_ROLL_MEAN3\"].values\n",
        "                else:\n",
        "                    model = make_model(model_name)\n",
        "                    model.fit(X_train, y_train)\n",
        "                    y_pred = model.predict(X_test)\n",
        "\n",
        "                mae, rmse, mape, medae, r2 = compute_metrics(y_test, y_pred)\n",
        "                print(\n",
        "                    f\"{crop_name} | {model_name} | {feature_set} | Fold {fold_idx}: \"\n",
        "                    f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.2f}, \"\n",
        "                    f\"MedAE={medae:.2f}, R2={r2:.3f}\"\n",
        "                )\n",
        "\n",
        "                records.append(\n",
        "                    {\n",
        "                        \"Crop\": crop_name,\n",
        "                        \"Model\": model_name,\n",
        "                        \"FeatureSet\": feature_set,\n",
        "                        \"Fold\": fold_idx,\n",
        "                        \"MAE\": mae,\n",
        "                        \"RMSE\": rmse,\n",
        "                        \"MAPE\": mape,\n",
        "                        \"MedAE\": medae,\n",
        "                        \"R2\": r2,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "\n",
        "def summarise_performance(records_df):\n",
        "    summary = (\n",
        "        records_df.groupby([\"Crop\", \"Model\", \"FeatureSet\"])\n",
        "        .agg(\n",
        "            MAE_mean=(\"MAE\", \"mean\"),\n",
        "            MAE_std=(\"MAE\", \"std\"),\n",
        "            RMSE_mean=(\"RMSE\", \"mean\"),\n",
        "            RMSE_std=(\"RMSE\", \"std\"),\n",
        "            MAPE_mean=(\"MAPE\", \"mean\"),\n",
        "            MAPE_std=(\"MAPE\", \"std\"),\n",
        "            MedAE_mean=(\"MedAE\", \"mean\"),\n",
        "            MedAE_std=(\"MedAE\", \"std\"),\n",
        "            R2_mean=(\"R2\", \"mean\"),\n",
        "            R2_std=(\"R2\", \"std\"),\n",
        "        )\n",
        "        .reset_index()\n",
        "    )\n",
        "\n",
        "    for crop in summary[\"Crop\"].unique():\n",
        "        for feat_set in [\"no_network\", \"with_network\"]:\n",
        "            sub = summary[(summary[\"Crop\"] == crop) &\n",
        "                          (summary[\"FeatureSet\"] == feat_set)]\n",
        "            if not sub.empty:\n",
        "                print(f\"\\nPerformance summary for {crop} ({feat_set}):\")\n",
        "                print(sub.to_string(index=False))\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "def select_best_models(summary_df, mae_tol_frac=0.01):\n",
        "    \"\"\"\n",
        "    For each crop, pick the best model as:\n",
        "      - lowest MAE_mean\n",
        "      - within 1% tolerance, prefer 'with_network'\n",
        "      - within that, highest R2_mean\n",
        "    \"\"\"\n",
        "    best_rows = []\n",
        "    print(\"\\n===== FINAL SUMMARY =====\")\n",
        "    crops = summary_df[\"Crop\"].unique()\n",
        "    for crop in crops:\n",
        "        sub = summary_df[summary_df[\"Crop\"] == crop].copy()\n",
        "        best_mae = sub[\"MAE_mean\"].min()\n",
        "        tol = mae_tol_frac * best_mae\n",
        "        candidates = sub[sub[\"MAE_mean\"] <= best_mae + tol]\n",
        "\n",
        "        # Prefer with_network if at least one candidate has it\n",
        "        if (candidates[\"FeatureSet\"] == \"with_network\").any():\n",
        "            candidates = candidates[candidates[\"FeatureSet\"] == \"with_network\"]\n",
        "\n",
        "        # Among remaining, pick highest R2_mean\n",
        "        idx = candidates[\"R2_mean\"].idxmax()\n",
        "        row = candidates.loc[idx]\n",
        "        best_rows.append(row)\n",
        "\n",
        "        print(\n",
        "            f\"  {crop}: {row['Model']} (FeatureSet={row['FeatureSet']}), \"\n",
        "            f\"MAE_mean={row['MAE_mean']:.2f}, R2_mean={row['R2_mean']:.3f}\"\n",
        "        )\n",
        "\n",
        "    best_df = pd.DataFrame(best_rows).reset_index(drop=True)\n",
        "    return best_df\n",
        "\n",
        "\n",
        "def get_oof_predictions_for_best(panel_df, crop_name, best_row):\n",
        "    \"\"\"Collect out-of-fold predictions for the best model for diagnostic plots.\"\"\"\n",
        "    model_name = best_row[\"Model\"]\n",
        "    feature_set = best_row[\"FeatureSet\"]\n",
        "\n",
        "    base_features = [\n",
        "        \"Y_LAG1\",\n",
        "        \"Y_LAG2\",\n",
        "        \"Y_LAG3\",\n",
        "        \"Y_ROLL_MEAN3\",\n",
        "        \"DIVERSIFICATION_INDEX\",\n",
        "        \"HERFINDAHL\",\n",
        "    ]\n",
        "    base_features = [f for f in base_features if f in panel_df.columns]\n",
        "\n",
        "    network_features = [\n",
        "        \"DIST_DEGREE\",\n",
        "        \"DIST_STRENGTH\",\n",
        "        \"DIST_BETWEENNESS\",\n",
        "    ]\n",
        "    network_features = [f for f in network_features if f in panel_df.columns]\n",
        "\n",
        "    if feature_set == \"no_network\":\n",
        "        feature_cols = base_features\n",
        "    else:\n",
        "        feature_cols = base_features + network_features\n",
        "\n",
        "    feature_cols = [c for c in feature_cols if c in panel_df.columns]\n",
        "    folds = make_time_series_folds(panel_df, time_col=\"Year\", n_splits=3)\n",
        "\n",
        "    all_y_true = []\n",
        "    all_y_pred = []\n",
        "\n",
        "    for train_years, test_years in folds:\n",
        "        train_mask = panel_df[\"Year\"].isin(train_years)\n",
        "        test_mask = panel_df[\"Year\"].isin(test_years)\n",
        "\n",
        "        X_train = panel_df.loc[train_mask, feature_cols]\n",
        "        X_test = panel_df.loc[test_mask, feature_cols]\n",
        "        y_train = panel_df.loc[train_mask, \"TARGET_YIELD\"].values\n",
        "        y_test = panel_df.loc[test_mask, \"TARGET_YIELD\"].values\n",
        "\n",
        "        if model_name == \"Naive\":\n",
        "            y_pred = panel_df.loc[test_mask, \"Y_LAG1\"].values\n",
        "        elif model_name == \"RollingMean3\":\n",
        "            y_pred = panel_df.loc[test_mask, \"Y_ROLL_MEAN3\"].values\n",
        "        else:\n",
        "            model = make_model(model_name)\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "        all_y_true.append(y_test)\n",
        "        all_y_pred.append(y_pred)\n",
        "\n",
        "    all_y_true = np.concatenate(all_y_true)\n",
        "    all_y_pred = np.concatenate(all_y_pred)\n",
        "    return all_y_true, all_y_pred\n",
        "\n",
        "\n",
        "def plot_diagnostics(y_true, y_pred, crop_name, model_name, feature_set):\n",
        "    \"\"\"Two-panel diagnostic: predicted vs observed and residuals vs predicted.\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # Scatter: observed vs predicted\n",
        "    ax = axes[0]\n",
        "    ax.scatter(y_true, y_pred, alpha=0.4, edgecolor=\"none\")\n",
        "    mn = min(np.min(y_true), np.min(y_pred))\n",
        "    mx = max(np.max(y_true), np.max(y_pred))\n",
        "    ax.plot([mn, mx], [mn, mx], \"k--\", linewidth=1)\n",
        "    ax.set_xlabel(\"Observed yield (kg/ha)\")\n",
        "    ax.set_ylabel(\"Predicted yield (kg/ha)\")\n",
        "    ax.set_title(f\"{crop_name} | {model_name} | {feature_set}\")\n",
        "\n",
        "    # Residuals vs predicted\n",
        "    resid = y_true - y_pred\n",
        "    ax = axes[1]\n",
        "    ax.scatter(y_pred, resid, alpha=0.4, edgecolor=\"none\")\n",
        "    ax.axhline(0.0, color=\"k\", linestyle=\"--\", linewidth=1)\n",
        "    ax.set_xlabel(\"Predicted yield (kg/ha)\")\n",
        "    ax.set_ylabel(\"Residual (kg/ha)\")\n",
        "    ax.set_title(\"Residuals vs predicted\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    fname = os.path.join(\n",
        "        OUTPUT_DIR,\n",
        "        f\"{crop_name.lower()}_{model_name.lower()}_{feature_set}_diagnostics.pdf\",\n",
        "    )\n",
        "    fig.savefig(fname, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    print(\n",
        "        f\"Saved diagnostic plots for {crop_name} ({model_name}, \"\n",
        "        f\"feature set={feature_set}) to {OUTPUT_DIR}.\"\n",
        "    )\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# MAIN\n",
        "# -----------------------------------------------------------------------------\n",
        "def main():\n",
        "    # 1. Load data (raw or cleaned fallback)\n",
        "    df, source_type = load_icrisat_dataframe()\n",
        "    print(f\"\\nData source type: {source_type}\")\n",
        "    basic_eda(df)\n",
        "\n",
        "    # 2. Clip yields / clean (idempotent if already clipped)\n",
        "    df = clip_yield_outliers(df, upper_quantile=0.99)\n",
        "\n",
        "    # 3. Diversification indices\n",
        "    df, area_cols = compute_diversification(df)\n",
        "\n",
        "    # 4. Build networks (district similarity + crop co-occurrence)\n",
        "    dist_network = build_district_similarity_network(\n",
        "        df, area_cols, start_year=2008, end_year=2017, corr_threshold=0.7\n",
        "    )\n",
        "    crop_network = build_crop_cooccurrence_network(df, area_cols)\n",
        "\n",
        "    # 5. Add district-level network features\n",
        "    df = add_district_network_features(df, dist_network)\n",
        "\n",
        "    # 6. Save cleaned dataset with features\n",
        "    df.to_csv(CLEANED_CSV_PATH, index=False)\n",
        "    print(\n",
        "        f\"\\nSaved cleaned dataset with features to: {CLEANED_CSV_PATH}\"\n",
        "    )\n",
        "\n",
        "    # 7. Build supervised panels for each crop\n",
        "    panels = {}\n",
        "    for crop, ycol in CROP_YIELD_COLS.items():\n",
        "        if ycol not in df.columns:\n",
        "            print(f\"\\nWARNING: Yield column {ycol} not found, skipping {crop}.\")\n",
        "            continue\n",
        "        panel = build_supervised_panel_for_crop(\n",
        "            df, crop_name=crop, yield_col=ycol, min_year=1970\n",
        "        )\n",
        "        panels[crop] = panel\n",
        "\n",
        "    # 8. Model evaluation\n",
        "    records = []\n",
        "    for crop, panel in panels.items():\n",
        "        evaluate_models_for_crop(crop, panel, records)\n",
        "\n",
        "    records_df = pd.DataFrame(records)\n",
        "    records_df.to_csv(\n",
        "        os.path.join(OUTPUT_DIR, \"model_per_fold_raw.csv\"), index=False\n",
        "    )\n",
        "\n",
        "    # 9. Summarise performance\n",
        "    summary_df = summarise_performance(records_df)\n",
        "    summary_df.to_csv(MODEL_PERF_PATH, index=False)\n",
        "    print(f\"\\nSaved model performance summary to: {MODEL_PERF_PATH}\")\n",
        "\n",
        "    # 10. Select best model per crop\n",
        "    best_df = select_best_models(summary_df)\n",
        "\n",
        "    # 11. Diagnostics for best models\n",
        "    for _, row in best_df.iterrows():\n",
        "        crop = row[\"Crop\"]\n",
        "        model_name = row[\"Model\"]\n",
        "        feature_set = row[\"FeatureSet\"]\n",
        "        panel = panels[crop]\n",
        "        y_true, y_pred = get_oof_predictions_for_best(panel, crop, row)\n",
        "        plot_diagnostics(y_true, y_pred, crop, model_name, feature_set)\n",
        "\n",
        "    print(\"\\n===== PIPELINE COMPLETE =====\")\n",
        "    print(f\"Rows after cleaning: {df.shape[0]}\")\n",
        "    if \"Year\" in df.columns:\n",
        "        print(f\"Years: {df['Year'].min()} - {df['Year'].max()}\")\n",
        "    if \"District Name\" in df.columns:\n",
        "        print(f\"Number of districts: {df['District Name'].nunique()}\")\n",
        "    elif \"Dist Code\" in df.columns:\n",
        "        print(f\"Number of districts (by Dist Code): {df['Dist Code'].nunique()}\")\n",
        "    print(f\"Crops modeled: {list(panels.keys())}\")\n",
        "    print(f\"Cleaned dataset with features: {CLEANED_CSV_PATH}\")\n",
        "    print(f\"Model performance summary: {MODEL_PERF_PATH}\")\n",
        "    print(f\"Supervised panel CSV prefix: {SUPERVISED_PANEL_PREFIX}\")\n",
        "    print(\"Key PDF plots saved in OUTPUT_DIR (diagnostic scatter + residuals for best models).\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPyAl_Xl4c8e",
        "outputId": "685914bb-81a0-4995-cbe0-8cecafcbd02a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAW_CSV_PATH not found.\n",
            "Falling back to existing CLEANED dataset: /content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\n",
            "\n",
            "Data source type: cleaned\n",
            "===== BASIC EDA =====\n",
            "Duplicate (Dist Code, Year) rows: 0\n",
            "Key (Dist Code, Year) is unique.\n",
            "\n",
            "Rows: 16146, Columns: 91\n",
            "Time range: 1966 - 2017\n",
            "Unique States: 20\n",
            "Detected crops (count=23): ['BARLEY', 'CASTOR', 'CHICKPEA', 'COTTON', 'FINGER MILLET', 'GROUNDNUT', 'KHARIF SORGHUM', 'LINSEED', 'MAIZE', 'MINOR PULSES', 'OILSEEDS', 'PEARL MILLET', 'PIGEONPEA', 'RABI SORGHUM', 'RAPESEED AND MUSTARD', 'RICE', 'SAFFLOWER', 'SESAMUM', 'SORGHUM', 'SOYABEAN', 'SUGARCANE', 'SUNFLOWER', 'WHEAT']...\n",
            "\n",
            "Yield missingness (% of NaN):\n",
            "                           YieldColumn  MissingPct\n",
            "                RICE YIELD (Kg per ha)         0.0\n",
            "               WHEAT YIELD (Kg per ha)         0.0\n",
            "      KHARIF SORGHUM YIELD (Kg per ha)         0.0\n",
            "        RABI SORGHUM YIELD (Kg per ha)         0.0\n",
            "             SORGHUM YIELD (Kg per ha)         0.0\n",
            "        PEARL MILLET YIELD (Kg per ha)         0.0\n",
            "               MAIZE YIELD (Kg per ha)         0.0\n",
            "       FINGER MILLET YIELD (Kg per ha)         0.0\n",
            "              BARLEY YIELD (Kg per ha)         0.0\n",
            "            CHICKPEA YIELD (Kg per ha)         0.0\n",
            "           PIGEONPEA YIELD (Kg per ha)         0.0\n",
            "        MINOR PULSES YIELD (Kg per ha)         0.0\n",
            "           GROUNDNUT YIELD (Kg per ha)         0.0\n",
            "             SESAMUM YIELD (Kg per ha)         0.0\n",
            "RAPESEED AND MUSTARD YIELD (Kg per ha)         0.0\n",
            "           SAFFLOWER YIELD (Kg per ha)         0.0\n",
            "              CASTOR YIELD (Kg per ha)         0.0\n",
            "             LINSEED YIELD (Kg per ha)         0.0\n",
            "           SUNFLOWER YIELD (Kg per ha)         0.0\n",
            "            SOYABEAN YIELD (Kg per ha)         0.0\n",
            "            OILSEEDS YIELD (Kg per ha)         0.0\n",
            "           SUGARCANE YIELD (Kg per ha)         0.0\n",
            "              COTTON YIELD (Kg per ha)         0.0\n",
            "\n",
            "Summary for RICE yield:\n",
            "count    16146.000000\n",
            "mean      1483.290702\n",
            "std        945.010569\n",
            "min          0.000000\n",
            "25%        800.000000\n",
            "50%       1333.210000\n",
            "75%       2113.517500\n",
            "max       4104.220225\n",
            "Name: RICE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for WHEAT yield:\n",
            "count    16146.000000\n",
            "mean      1489.251300\n",
            "std       1071.684468\n",
            "min          0.000000\n",
            "25%        750.000000\n",
            "50%       1347.450000\n",
            "75%       2131.580000\n",
            "max       4484.001525\n",
            "Name: WHEAT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for MAIZE yield:\n",
            "count    16146.000000\n",
            "mean      1394.218224\n",
            "std       1115.318055\n",
            "min          0.000000\n",
            "25%        696.890000\n",
            "50%       1159.065000\n",
            "75%       1863.640000\n",
            "max       5897.193975\n",
            "Name: MAIZE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for GROUNDNUT yield:\n",
            "count    16146.000000\n",
            "mean       759.271954\n",
            "std        598.966934\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%        774.410000\n",
            "75%       1085.037500\n",
            "max       2540.999725\n",
            "Name: GROUNDNUT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for COTTON yield:\n",
            "count    16146.000000\n",
            "mean       119.821739\n",
            "std        167.337989\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%        202.270000\n",
            "max        740.163350\n",
            "Name: COTTON YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for SUGARCANE yield:\n",
            "count    16146.000000\n",
            "mean      4484.083204\n",
            "std       3105.530811\n",
            "min          0.000000\n",
            "25%       2000.000000\n",
            "50%       4502.210000\n",
            "75%       6704.605000\n",
            "max      12000.000000\n",
            "Name: SUGARCANE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "===== CLEANING DATA =====\n",
            "\n",
            "===== COMPUTING DIVERSIFICATION =====\n",
            "===== BUILDING DISTRICT SIMILARITY NETWORK =====\n",
            "Network reference window: 2008-2017\n",
            "District network: 311 nodes, 37917 edges\n",
            "\n",
            "===== BUILDING CROP-COOCCURRENCE NETWORK =====\n",
            "Crop network: 23 nodes, 253 edges\n",
            "\n",
            "Saved cleaned dataset with features to: /content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\n",
            "\n",
            "Saved supervised panel for RICE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_rice.csv\n",
            "\n",
            "RICE | Naive | no_network | Fold 1: MAE=283.12, RMSE=388.58, MAPE=40.29, MedAE=206.41, R2=0.741\n",
            "RICE | RollingMean3 | no_network | Fold 1: MAE=261.17, RMSE=354.54, MAPE=37.42, MedAE=200.58, R2=0.785\n",
            "RICE | Ridge | no_network | Fold 1: MAE=285.29, RMSE=413.02, MAPE=40.23, MedAE=196.99, R2=0.708\n",
            "RICE | RandomForest | no_network | Fold 1: MAE=248.51, RMSE=344.56, MAPE=34.19, MedAE=176.35, R2=0.797\n",
            "RICE | GradientBoosting | no_network | Fold 1: MAE=220.33, RMSE=311.63, MAPE=25.20, MedAE=155.35, R2=0.834\n",
            "RICE | Ridge | with_network | Fold 1: MAE=279.85, RMSE=403.40, MAPE=39.56, MedAE=196.07, R2=0.721\n",
            "RICE | RandomForest | with_network | Fold 1: MAE=248.08, RMSE=343.85, MAPE=34.26, MedAE=180.30, R2=0.797\n",
            "RICE | GradientBoosting | with_network | Fold 1: MAE=220.84, RMSE=313.14, MAPE=25.36, MedAE=154.34, R2=0.832\n",
            "RICE | Naive | no_network | Fold 2: MAE=281.83, RMSE=403.88, MAPE=23.17, MedAE=194.60, R2=0.779\n",
            "RICE | RollingMean3 | no_network | Fold 2: MAE=243.52, RMSE=345.71, MAPE=20.55, MedAE=170.77, R2=0.838\n",
            "RICE | Ridge | no_network | Fold 2: MAE=252.38, RMSE=350.15, MAPE=20.94, MedAE=182.18, R2=0.834\n",
            "RICE | RandomForest | no_network | Fold 2: MAE=231.74, RMSE=327.33, MAPE=19.61, MedAE=165.23, R2=0.855\n",
            "RICE | GradientBoosting | no_network | Fold 2: MAE=212.21, RMSE=297.29, MAPE=17.02, MedAE=152.76, R2=0.880\n",
            "RICE | Ridge | with_network | Fold 2: MAE=251.97, RMSE=350.29, MAPE=20.83, MedAE=183.30, R2=0.834\n",
            "RICE | RandomForest | with_network | Fold 2: MAE=231.06, RMSE=326.63, MAPE=19.48, MedAE=163.32, R2=0.856\n",
            "RICE | GradientBoosting | with_network | Fold 2: MAE=213.63, RMSE=300.05, MAPE=17.07, MedAE=153.89, R2=0.878\n",
            "RICE | Naive | no_network | Fold 3: MAE=296.28, RMSE=459.69, MAPE=19.26, MedAE=178.54, R2=0.759\n",
            "RICE | RollingMean3 | no_network | Fold 3: MAE=286.20, RMSE=419.19, MAPE=18.36, MedAE=191.22, R2=0.800\n",
            "RICE | Ridge | no_network | Fold 3: MAE=284.16, RMSE=389.01, MAPE=18.86, MedAE=210.71, R2=0.827\n",
            "RICE | RandomForest | no_network | Fold 3: MAE=277.54, RMSE=390.65, MAPE=18.63, MedAE=195.77, R2=0.826\n",
            "RICE | GradientBoosting | no_network | Fold 3: MAE=241.07, RMSE=342.11, MAPE=16.15, MedAE=170.74, R2=0.867\n",
            "RICE | Ridge | with_network | Fold 3: MAE=284.12, RMSE=388.18, MAPE=18.90, MedAE=209.85, R2=0.828\n",
            "RICE | RandomForest | with_network | Fold 3: MAE=278.17, RMSE=391.37, MAPE=18.65, MedAE=194.45, R2=0.825\n",
            "RICE | GradientBoosting | with_network | Fold 3: MAE=239.30, RMSE=339.30, MAPE=16.18, MedAE=168.55, R2=0.869\n",
            "Saved supervised panel for WHEAT to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_wheat.csv\n",
            "\n",
            "WHEAT | Naive | no_network | Fold 1: MAE=256.38, RMSE=366.30, MAPE=20.32, MedAE=179.57, R2=0.752\n",
            "WHEAT | RollingMean3 | no_network | Fold 1: MAE=243.36, RMSE=335.36, MAPE=19.13, MedAE=179.21, R2=0.792\n",
            "WHEAT | Ridge | no_network | Fold 1: MAE=473.20, RMSE=1257.45, MAPE=47.96, MedAE=203.16, R2=-1.918\n",
            "WHEAT | RandomForest | no_network | Fold 1: MAE=244.93, RMSE=343.43, MAPE=18.90, MedAE=174.79, R2=0.782\n",
            "WHEAT | GradientBoosting | no_network | Fold 1: MAE=211.10, RMSE=298.85, MAPE=15.93, MedAE=145.80, R2=0.835\n",
            "WHEAT | Ridge | with_network | Fold 1: MAE=472.34, RMSE=1241.08, MAPE=46.95, MedAE=204.39, R2=-1.842\n",
            "WHEAT | RandomForest | with_network | Fold 1: MAE=244.72, RMSE=343.01, MAPE=18.88, MedAE=172.71, R2=0.783\n",
            "WHEAT | GradientBoosting | with_network | Fold 1: MAE=209.74, RMSE=298.42, MAPE=15.69, MedAE=144.45, R2=0.836\n",
            "WHEAT | Naive | no_network | Fold 2: MAE=266.28, RMSE=380.48, MAPE=17.55, MedAE=192.28, R2=0.825\n",
            "WHEAT | RollingMean3 | no_network | Fold 2: MAE=239.63, RMSE=333.89, MAPE=15.99, MedAE=173.52, R2=0.865\n",
            "WHEAT | Ridge | no_network | Fold 2: MAE=246.66, RMSE=342.53, MAPE=16.32, MedAE=186.46, R2=0.858\n",
            "WHEAT | RandomForest | no_network | Fold 2: MAE=220.16, RMSE=304.11, MAPE=15.20, MedAE=164.34, R2=0.888\n",
            "WHEAT | GradientBoosting | no_network | Fold 2: MAE=199.30, RMSE=268.72, MAPE=13.26, MedAE=151.80, R2=0.912\n",
            "WHEAT | Ridge | with_network | Fold 2: MAE=247.06, RMSE=342.85, MAPE=16.38, MedAE=185.39, R2=0.858\n",
            "WHEAT | RandomForest | with_network | Fold 2: MAE=220.07, RMSE=304.33, MAPE=15.17, MedAE=166.23, R2=0.888\n",
            "WHEAT | GradientBoosting | with_network | Fold 2: MAE=200.77, RMSE=270.62, MAPE=13.45, MedAE=153.52, R2=0.911\n",
            "WHEAT | Naive | no_network | Fold 3: MAE=338.37, RMSE=497.47, MAPE=18.76, MedAE=222.74, R2=0.776\n",
            "WHEAT | RollingMean3 | no_network | Fold 3: MAE=324.36, RMSE=463.30, MAPE=17.35, MedAE=222.22, R2=0.805\n",
            "WHEAT | Ridge | no_network | Fold 3: MAE=290.10, RMSE=401.58, MAPE=16.23, MedAE=212.67, R2=0.854\n",
            "WHEAT | RandomForest | no_network | Fold 3: MAE=295.23, RMSE=417.01, MAPE=15.73, MedAE=203.19, R2=0.842\n",
            "WHEAT | GradientBoosting | no_network | Fold 3: MAE=262.13, RMSE=374.93, MAPE=13.93, MedAE=182.27, R2=0.873\n",
            "WHEAT | Ridge | with_network | Fold 3: MAE=290.67, RMSE=402.55, MAPE=16.24, MedAE=213.33, R2=0.853\n",
            "WHEAT | RandomForest | with_network | Fold 3: MAE=296.11, RMSE=418.11, MAPE=15.79, MedAE=206.27, R2=0.842\n",
            "WHEAT | GradientBoosting | with_network | Fold 3: MAE=258.87, RMSE=370.75, MAPE=13.70, MedAE=180.27, R2=0.875\n",
            "Saved supervised panel for MAIZE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_maize.csv\n",
            "\n",
            "MAIZE | Naive | no_network | Fold 1: MAE=399.22, RMSE=623.06, MAPE=40.81, MedAE=259.91, R2=0.312\n",
            "MAIZE | RollingMean3 | no_network | Fold 1: MAE=379.21, RMSE=571.01, MAPE=39.55, MedAE=260.04, R2=0.422\n",
            "MAIZE | Ridge | no_network | Fold 1: MAE=593.04, RMSE=1361.61, MAPE=52.17, MedAE=275.15, R2=-2.286\n",
            "MAIZE | RandomForest | no_network | Fold 1: MAE=310.57, RMSE=488.47, MAPE=32.11, MedAE=200.93, R2=0.577\n",
            "MAIZE | GradientBoosting | no_network | Fold 1: MAE=255.30, RMSE=413.57, MAPE=25.23, MedAE=162.15, R2=0.697\n",
            "MAIZE | Ridge | with_network | Fold 1: MAE=539.86, RMSE=1144.22, MAPE=48.74, MedAE=268.81, R2=-1.320\n",
            "MAIZE | RandomForest | with_network | Fold 1: MAE=311.45, RMSE=490.49, MAPE=32.13, MedAE=200.04, R2=0.574\n",
            "MAIZE | GradientBoosting | with_network | Fold 1: MAE=257.70, RMSE=411.95, MAPE=25.21, MedAE=165.13, R2=0.699\n",
            "MAIZE | Naive | no_network | Fold 2: MAE=410.81, RMSE=613.36, MAPE=29.27, MedAE=281.45, R2=0.477\n",
            "MAIZE | RollingMean3 | no_network | Fold 2: MAE=366.05, RMSE=544.43, MAPE=25.57, MedAE=251.96, R2=0.588\n",
            "MAIZE | Ridge | no_network | Fold 2: MAE=372.51, RMSE=553.19, MAPE=23.86, MedAE=255.76, R2=0.575\n",
            "MAIZE | RandomForest | no_network | Fold 2: MAE=343.51, RMSE=524.93, MAPE=22.01, MedAE=222.69, R2=0.617\n",
            "MAIZE | GradientBoosting | no_network | Fold 2: MAE=273.87, RMSE=412.36, MAPE=17.34, MedAE=181.30, R2=0.764\n",
            "MAIZE | Ridge | with_network | Fold 2: MAE=371.93, RMSE=552.32, MAPE=23.83, MedAE=256.52, R2=0.576\n",
            "MAIZE | RandomForest | with_network | Fold 2: MAE=344.75, RMSE=526.80, MAPE=22.09, MedAE=221.76, R2=0.614\n",
            "MAIZE | GradientBoosting | with_network | Fold 2: MAE=275.91, RMSE=414.65, MAPE=17.49, MedAE=184.92, R2=0.761\n",
            "MAIZE | Naive | no_network | Fold 3: MAE=513.72, RMSE=817.16, MAPE=29.04, MedAE=300.00, R2=0.634\n",
            "MAIZE | RollingMean3 | no_network | Fold 3: MAE=488.77, RMSE=759.50, MAPE=27.08, MedAE=304.04, R2=0.684\n",
            "MAIZE | Ridge | no_network | Fold 3: MAE=514.46, RMSE=794.57, MAPE=26.53, MedAE=320.46, R2=0.654\n",
            "MAIZE | RandomForest | no_network | Fold 3: MAE=476.32, RMSE=709.89, MAPE=24.67, MedAE=296.70, R2=0.724\n",
            "MAIZE | GradientBoosting | no_network | Fold 3: MAE=412.42, RMSE=622.32, MAPE=20.70, MedAE=252.05, R2=0.788\n",
            "MAIZE | Ridge | with_network | Fold 3: MAE=512.22, RMSE=790.61, MAPE=26.41, MedAE=322.29, R2=0.657\n",
            "MAIZE | RandomForest | with_network | Fold 3: MAE=476.41, RMSE=710.93, MAPE=24.66, MedAE=296.71, R2=0.723\n",
            "MAIZE | GradientBoosting | with_network | Fold 3: MAE=412.27, RMSE=622.43, MAPE=20.69, MedAE=252.05, R2=0.787\n",
            "Saved supervised panel for GROUNDNUT to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_groundnut.csv\n",
            "\n",
            "GROUNDNUT | Naive | no_network | Fold 1: MAE=271.23, RMSE=391.11, MAPE=44.14, MedAE=193.55, R2=-0.154\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 1: MAE=263.89, RMSE=363.36, MAPE=44.27, MedAE=193.34, R2=0.004\n",
            "GROUNDNUT | Ridge | no_network | Fold 1: MAE=4418.62, RMSE=14940.03, MAPE=618.15, MedAE=287.97, R2=-1683.136\n",
            "GROUNDNUT | RandomForest | no_network | Fold 1: MAE=203.22, RMSE=281.71, MAPE=36.65, MedAE=150.69, R2=0.401\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 1: MAE=184.19, RMSE=251.18, MAPE=28.11, MedAE=141.66, R2=0.524\n",
            "GROUNDNUT | Ridge | with_network | Fold 1: MAE=4391.90, RMSE=14864.65, MAPE=614.72, MedAE=287.73, R2=-1666.183\n",
            "GROUNDNUT | RandomForest | with_network | Fold 1: MAE=203.84, RMSE=282.36, MAPE=36.81, MedAE=152.04, R2=0.398\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 1: MAE=183.51, RMSE=250.82, MAPE=27.31, MedAE=141.79, R2=0.525\n",
            "GROUNDNUT | Naive | no_network | Fold 2: MAE=284.88, RMSE=412.05, MAPE=39.25, MedAE=193.95, R2=-0.049\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 2: MAE=253.01, RMSE=352.31, MAPE=33.37, MedAE=186.02, R2=0.233\n",
            "GROUNDNUT | Ridge | no_network | Fold 2: MAE=219.55, RMSE=290.03, MAPE=28.41, MedAE=171.64, R2=0.481\n",
            "GROUNDNUT | RandomForest | no_network | Fold 2: MAE=205.08, RMSE=279.47, MAPE=27.09, MedAE=154.54, R2=0.518\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 2: MAE=170.99, RMSE=232.14, MAPE=20.98, MedAE=129.15, R2=0.667\n",
            "GROUNDNUT | Ridge | with_network | Fold 2: MAE=220.50, RMSE=291.48, MAPE=28.40, MedAE=173.21, R2=0.475\n",
            "GROUNDNUT | RandomForest | with_network | Fold 2: MAE=205.72, RMSE=280.11, MAPE=27.06, MedAE=155.90, R2=0.515\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 2: MAE=174.24, RMSE=234.22, MAPE=21.25, MedAE=134.23, R2=0.661\n",
            "GROUNDNUT | Naive | no_network | Fold 3: MAE=279.97, RMSE=428.14, MAPE=28.08, MedAE=175.49, R2=0.407\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 3: MAE=257.37, RMSE=368.97, MAPE=25.59, MedAE=183.24, R2=0.560\n",
            "GROUNDNUT | Ridge | no_network | Fold 3: MAE=292.06, RMSE=389.90, MAPE=26.90, MedAE=227.55, R2=0.508\n",
            "GROUNDNUT | RandomForest | no_network | Fold 3: MAE=240.13, RMSE=327.24, MAPE=21.49, MedAE=178.07, R2=0.654\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 3: MAE=213.46, RMSE=296.68, MAPE=19.07, MedAE=151.31, R2=0.715\n",
            "GROUNDNUT | Ridge | with_network | Fold 3: MAE=292.21, RMSE=390.51, MAPE=26.86, MedAE=228.41, R2=0.507\n",
            "GROUNDNUT | RandomForest | with_network | Fold 3: MAE=240.41, RMSE=326.95, MAPE=21.52, MedAE=178.55, R2=0.654\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 3: MAE=216.08, RMSE=299.92, MAPE=19.40, MedAE=154.07, R2=0.709\n",
            "Saved supervised panel for COTTON to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_cotton.csv\n",
            "\n",
            "COTTON | Naive | no_network | Fold 1: MAE=71.09, RMSE=121.11, MAPE=36.91, MedAE=38.65, R2=0.199\n",
            "COTTON | RollingMean3 | no_network | Fold 1: MAE=68.11, RMSE=112.32, MAPE=34.69, MedAE=36.19, R2=0.311\n",
            "COTTON | Ridge | no_network | Fold 1: MAE=307.25, RMSE=954.34, MAPE=271.25, MedAE=84.50, R2=-48.766\n",
            "COTTON | RandomForest | no_network | Fold 1: MAE=57.58, RMSE=87.78, MAPE=33.28, MedAE=35.52, R2=0.579\n",
            "COTTON | GradientBoosting | no_network | Fold 1: MAE=48.97, RMSE=72.70, MAPE=29.09, MedAE=32.08, R2=0.711\n",
            "COTTON | Ridge | with_network | Fold 1: MAE=322.54, RMSE=1034.39, MAPE=283.61, MedAE=85.60, R2=-57.465\n",
            "COTTON | RandomForest | with_network | Fold 1: MAE=57.55, RMSE=87.70, MAPE=33.20, MedAE=35.39, R2=0.580\n",
            "COTTON | GradientBoosting | with_network | Fold 1: MAE=48.55, RMSE=73.16, MAPE=27.83, MedAE=31.15, R2=0.708\n",
            "COTTON | Naive | no_network | Fold 2: MAE=79.60, RMSE=122.92, MAPE=36.16, MedAE=50.47, R2=0.064\n",
            "COTTON | RollingMean3 | no_network | Fold 2: MAE=76.83, RMSE=115.91, MAPE=35.03, MedAE=49.19, R2=0.168\n",
            "COTTON | Ridge | no_network | Fold 2: MAE=71.77, RMSE=100.17, MAPE=36.51, MedAE=53.75, R2=0.379\n",
            "COTTON | RandomForest | no_network | Fold 2: MAE=66.93, RMSE=93.05, MAPE=35.09, MedAE=49.50, R2=0.464\n",
            "COTTON | GradientBoosting | no_network | Fold 2: MAE=51.77, RMSE=71.97, MAPE=26.68, MedAE=37.93, R2=0.679\n",
            "COTTON | Ridge | with_network | Fold 2: MAE=71.82, RMSE=99.91, MAPE=36.59, MedAE=53.21, R2=0.382\n",
            "COTTON | RandomForest | with_network | Fold 2: MAE=67.13, RMSE=93.23, MAPE=35.07, MedAE=48.89, R2=0.462\n",
            "COTTON | GradientBoosting | with_network | Fold 2: MAE=54.03, RMSE=76.00, MAPE=27.96, MedAE=39.45, R2=0.642\n",
            "COTTON | Naive | no_network | Fold 3: MAE=120.20, RMSE=181.89, MAPE=319.25, MedAE=72.80, R2=0.094\n",
            "COTTON | RollingMean3 | no_network | Fold 3: MAE=116.18, RMSE=165.17, MAPE=511.15, MedAE=77.97, R2=0.253\n",
            "COTTON | Ridge | no_network | Fold 3: MAE=110.32, RMSE=149.64, MAPE=528.10, MedAE=80.73, R2=0.387\n",
            "COTTON | RandomForest | no_network | Fold 3: MAE=111.21, RMSE=145.73, MAPE=407.66, MedAE=82.39, R2=0.418\n",
            "COTTON | GradientBoosting | no_network | Fold 3: MAE=81.99, RMSE=110.87, MAPE=149.29, MedAE=59.53, R2=0.663\n",
            "COTTON | Ridge | with_network | Fold 3: MAE=110.08, RMSE=148.69, MAPE=519.61, MedAE=81.13, R2=0.395\n",
            "COTTON | RandomForest | with_network | Fold 3: MAE=111.39, RMSE=145.91, MAPE=397.94, MedAE=83.66, R2=0.417\n",
            "COTTON | GradientBoosting | with_network | Fold 3: MAE=81.54, RMSE=109.98, MAPE=136.00, MedAE=60.64, R2=0.669\n",
            "Saved supervised panel for SUGARCANE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_sugarcane.csv\n",
            "\n",
            "SUGARCANE | Naive | no_network | Fold 1: MAE=879.27, RMSE=1412.06, MAPE=20.49, MedAE=541.67, R2=0.713\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 1: MAE=862.56, RMSE=1329.42, MAPE=19.93, MedAE=558.70, R2=0.746\n",
            "SUGARCANE | Ridge | no_network | Fold 1: MAE=2347.17, RMSE=6961.41, MAPE=74.90, MedAE=809.78, R2=-5.966\n",
            "SUGARCANE | RandomForest | no_network | Fold 1: MAE=784.29, RMSE=1130.87, MAPE=18.99, MedAE=565.66, R2=0.816\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 1: MAE=689.84, RMSE=1008.73, MAPE=17.20, MedAE=475.49, R2=0.854\n",
            "SUGARCANE | Ridge | with_network | Fold 1: MAE=2121.30, RMSE=6065.04, MAPE=66.10, MedAE=776.66, R2=-4.288\n",
            "SUGARCANE | RandomForest | with_network | Fold 1: MAE=788.69, RMSE=1134.73, MAPE=19.25, MedAE=574.42, R2=0.815\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 1: MAE=681.81, RMSE=1003.85, MAPE=16.53, MedAE=454.74, R2=0.855\n",
            "SUGARCANE | Naive | no_network | Fold 2: MAE=909.99, RMSE=1545.62, MAPE=22.56, MedAE=500.57, R2=0.635\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 2: MAE=879.00, RMSE=1396.06, MAPE=24.75, MedAE=520.06, R2=0.702\n",
            "SUGARCANE | Ridge | no_network | Fold 2: MAE=982.87, RMSE=1382.11, MAPE=40.86, MedAE=699.65, R2=0.708\n",
            "SUGARCANE | RandomForest | no_network | Fold 2: MAE=838.17, RMSE=1196.00, MAPE=36.11, MedAE=591.76, R2=0.781\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 2: MAE=723.60, RMSE=1024.01, MAPE=28.33, MedAE=509.90, R2=0.840\n",
            "SUGARCANE | Ridge | with_network | Fold 2: MAE=952.24, RMSE=1351.66, MAPE=38.53, MedAE=671.92, R2=0.721\n",
            "SUGARCANE | RandomForest | with_network | Fold 2: MAE=830.99, RMSE=1189.15, MAPE=35.32, MedAE=581.27, R2=0.784\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 2: MAE=716.05, RMSE=1017.59, MAPE=27.96, MedAE=495.49, R2=0.842\n",
            "SUGARCANE | Naive | no_network | Fold 3: MAE=1165.32, RMSE=2012.30, MAPE=25.93, MedAE=559.26, R2=0.423\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 3: MAE=1159.33, RMSE=1824.22, MAPE=26.92, MedAE=661.36, R2=0.526\n",
            "SUGARCANE | Ridge | no_network | Fold 3: MAE=1156.61, RMSE=1651.48, MAPE=50.64, MedAE=806.81, R2=0.612\n",
            "SUGARCANE | RandomForest | no_network | Fold 3: MAE=997.85, RMSE=1474.89, MAPE=31.63, MedAE=650.64, R2=0.690\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 3: MAE=868.19, RMSE=1275.55, MAPE=31.73, MedAE=578.97, R2=0.768\n",
            "SUGARCANE | Ridge | with_network | Fold 3: MAE=1145.08, RMSE=1624.54, MAPE=47.38, MedAE=810.35, R2=0.624\n",
            "SUGARCANE | RandomForest | with_network | Fold 3: MAE=1001.76, RMSE=1471.01, MAPE=31.85, MedAE=652.92, R2=0.692\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 3: MAE=863.47, RMSE=1268.91, MAPE=31.34, MedAE=570.94, R2=0.771\n",
            "\n",
            "Saved per-fold model results to: /content/drive/MyDrive/Shiny/ICRISAT/Results/model_per_fold_raw.csv\n",
            "Saved model performance summary to: /content/drive/MyDrive/Shiny/ICRISAT/Results/model_performance_summary.csv\n",
            "\n",
            "Performance summary for RICE (no_network):\n",
            "Crop            Model FeatureSet   MAE_mean   MAE_std  RMSE_mean  RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "RICE GradientBoosting no_network 224.535153 14.883864 317.012425 22.889574  19.459545  4.993854  159.617387   9.722498 0.860175 0.024067\n",
            "RICE     RandomForest no_network 252.598503 23.170571 354.179524 32.740285  24.142879  8.714898  179.117533  15.459430 0.825852 0.029258\n",
            "RICE     RollingMean3 no_network 263.631121 21.442914 373.147503 40.120840  25.443765 10.430766  187.521111  15.245244 0.807500 0.027730\n",
            "RICE            Ridge no_network 273.941357 18.683638 384.061342 31.725662  26.678699 11.783659  196.623796  14.269672 0.789739 0.071153\n",
            "RICE            Naive no_network 287.078892  7.994603 417.382161 37.426210  27.572644 11.186783  193.183333  13.988904 0.759858 0.019067\n",
            "\n",
            "Performance summary for RICE (with_network):\n",
            "Crop            Model   FeatureSet   MAE_mean   MAE_std  RMSE_mean  RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "RICE GradientBoosting with_network 224.592117 13.239636 317.496330 19.983597  19.534621  5.061072  158.925474   8.340155 0.859624 0.024420\n",
            "RICE     RandomForest with_network 252.437390 23.853785 353.950152 33.533869  24.131372  8.783922  179.354372  15.589020 0.826123 0.029156\n",
            "RICE            Ridge with_network 271.978808 17.460084 380.621057 27.348262  26.430567 11.413468  196.409632  13.278179 0.794430 0.063545\n",
            "\n",
            "Performance summary for WHEAT (no_network):\n",
            " Crop            Model FeatureSet   MAE_mean    MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "WHEAT GradientBoosting no_network 224.176446  33.390295 314.165024  54.737716  14.375983  1.387697  159.958344  19.554805  0.873426 0.038648\n",
            "WHEAT     RandomForest no_network 253.442063  38.253691 354.845792  57.310720  16.611651  1.999851  180.775467  20.105324  0.837558 0.052943\n",
            "WHEAT     RollingMean3 no_network 269.115101  47.879433 377.518940  74.293889  17.490894  1.576526  191.650000  26.629871  0.820936 0.038598\n",
            "WHEAT            Naive no_network 287.008345  44.754485 414.750688  71.985446  18.873923  1.388593  198.195000  22.185514  0.784219 0.036802\n",
            "WHEAT            Ridge no_network 336.652488 120.235758 667.187838 512.037237  26.836153 18.292651  200.759890  13.268972 -0.068771 1.601447\n",
            "\n",
            "Performance summary for WHEAT (with_network):\n",
            " Crop            Model   FeatureSet   MAE_mean    MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "WHEAT GradientBoosting with_network 223.125750  31.275835 313.263912  51.687504  14.278072  1.227851  159.413511  18.621630  0.874108 0.037806\n",
            "WHEAT     RandomForest with_network 253.634411  38.798212 355.149524  57.850022  16.614609  1.987274  181.736650  21.488003  0.837400 0.052552\n",
            "WHEAT            Ridge with_network 336.687818 119.483158 662.160907 502.247002  26.527405 17.690052  201.034267  14.270566 -0.043931 1.557579\n",
            "\n",
            "Performance summary for MAIZE (no_network):\n",
            " Crop            Model FeatureSet   MAE_mean    MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "MAIZE GradientBoosting no_network 313.862896  85.853398 482.750324 120.876473  21.087316  3.958087  198.497805  47.354176  0.749383 0.046993\n",
            "MAIZE     RandomForest no_network 376.799511  87.747856 574.426513 118.722287  26.262696  5.236804  240.105444  50.202630  0.639275 0.075655\n",
            "MAIZE     RollingMean3 no_network 411.342864  67.375418 624.980603 117.254522  30.732666  7.672710  272.011111  28.027403  0.564621 0.132262\n",
            "MAIZE            Naive no_network 441.248900  63.026417 684.525442 114.964330  33.041197  6.729251  280.456667  20.061139  0.474319 0.160844\n",
            "MAIZE            Ridge no_network 493.338743 111.774660 903.122745 414.999959  34.188951 15.630863  283.790868  33.207092 -0.352393 1.674681\n",
            "\n",
            "Performance summary for MAIZE (with_network):\n",
            " Crop            Model   FeatureSet   MAE_mean   MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "MAIZE GradientBoosting with_network 315.291645 84.473811 483.010986 120.749421  21.129050  3.882308  200.701686  45.555095  0.749270 0.045273\n",
            "MAIZE     RandomForest with_network 377.535647 87.232507 576.073877 118.189162  26.295223  5.211158  239.501617  50.720832  0.636918 0.077050\n",
            "MAIZE            Ridge with_network 474.673119 90.040940 829.051130 297.814022  32.994577 13.699354  282.542594  34.966562 -0.029003 1.118953\n",
            "\n",
            "Performance summary for GROUNDNUT (no_network):\n",
            "     Crop            Model FeatureSet    MAE_mean     MAE_std   RMSE_mean    RMSE_std  MAPE_mean   MAPE_std  MedAE_mean  MedAE_std     R2_mean     R2_std\n",
            "GROUNDNUT GradientBoosting no_network  189.546668   21.739359  259.996821   33.161955  22.721778   4.765814  140.706227  11.110661    0.635510   0.099549\n",
            "GROUNDNUT     RandomForest no_network  216.144636   20.795673  296.138173   26.954853  28.412451   7.663522  161.099966  14.826017    0.524185   0.126366\n",
            "GROUNDNUT     RollingMean3 no_network  258.092815    5.476935  361.549183    8.479045  34.409183   9.384620  187.533889   5.217050    0.265647   0.279369\n",
            "GROUNDNUT            Naive no_network  278.694932    6.916585  410.431888   18.567299  37.158237   8.231032  187.663333  10.544313    0.068161   0.298333\n",
            "GROUNDNUT            Ridge no_network 1643.409552 2403.674569 5206.651128 8429.501855 224.485390 340.924153  229.056697  58.179539 -560.715655 972.044411\n",
            "\n",
            "Performance summary for GROUNDNUT (with_network):\n",
            "     Crop            Model   FeatureSet    MAE_mean     MAE_std   RMSE_mean    RMSE_std  MAPE_mean   MAPE_std  MedAE_mean  MedAE_std     R2_mean     R2_std\n",
            "GROUNDNUT GradientBoosting with_network  191.274763   21.971336  261.653096   34.166340  22.654692   4.134609  143.362483  10.014773    0.631877   0.095325\n",
            "GROUNDNUT     RandomForest with_network  216.656905   20.589271  296.471684   26.419670  28.464100   7.742664  162.164073  14.323204    0.522732   0.128078\n",
            "GROUNDNUT            Ridge with_network 1634.867304 2387.927674 5182.212579 8385.379181 223.327216 338.959519  229.785651  57.273829 -555.066947 962.254697\n",
            "\n",
            "Performance summary for COTTON (no_network):\n",
            "  Crop            Model FeatureSet   MAE_mean    MAE_std  RMSE_mean   RMSE_std  MAPE_mean   MAPE_std  MedAE_mean  MedAE_std    R2_mean    R2_std\n",
            "COTTON GradientBoosting no_network  60.911090  18.306034  85.178531  22.250383  68.356137  70.105055   43.182801  14.460119   0.684602  0.024353\n",
            "COTTON     RandomForest no_network  78.571871  28.648977 108.853315  32.045128 158.676332 215.629303   55.803603  24.061771   0.487047  0.082740\n",
            "COTTON     RollingMean3 no_network  87.042258  25.609208 131.133188  29.531046 193.622751 274.986427   54.452222  21.383443   0.243818  0.071782\n",
            "COTTON            Naive no_network  90.299430  26.244987 141.972908  34.581519 130.772025 163.225927   53.973333  17.345671   0.118915  0.070537\n",
            "COTTON            Ridge no_network 163.113494 126.309664 401.381878 479.510122 278.619264 245.876600   72.996542  16.772108 -16.000262 28.376068\n",
            "\n",
            "Performance summary for COTTON (with_network):\n",
            "  Crop            Model   FeatureSet   MAE_mean    MAE_std  RMSE_mean   RMSE_std  MAPE_mean   MAPE_std  MedAE_mean  MedAE_std    R2_mean    R2_std\n",
            "COTTON GradientBoosting with_network  61.370734  17.677477  86.379004  20.487394  63.929917  62.414117   43.749396  15.207782   0.672858  0.032861\n",
            "COTTON     RandomForest with_network  78.689822  28.719007 108.948499  32.133039 155.405254 210.043812   55.982694  24.904813   0.486113  0.084085\n",
            "COTTON            Ridge with_network 168.145071 135.073237 427.661990 526.003878 279.937540 241.534066   73.314748  17.552073 -18.896255 33.401596\n",
            "\n",
            "Performance summary for SUGARCANE (no_network):\n",
            "     Crop            Model FeatureSet    MAE_mean    MAE_std   RMSE_mean    RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "SUGARCANE GradientBoosting no_network  760.547624  94.741153 1102.763301  149.834810  25.756077  7.601969  521.452832  52.698526  0.820573 0.045766\n",
            "SUGARCANE     RandomForest no_network  873.435466 111.062147 1267.251528  182.742119  28.909624  8.874632  602.688900  43.530396  0.762568 0.064975\n",
            "SUGARCANE     RollingMean3 no_network  966.964358 166.797985 1516.566183  268.510097  23.867544  3.581923  580.038889  73.026207  0.658031 0.116251\n",
            "SUGARCANE            Naive no_network  984.857837 157.033767 1656.657328  315.149133  22.994042  2.742542  533.833333  30.119579  0.590504 0.149898\n",
            "SUGARCANE            Ridge no_network 1495.547998 742.621989 3331.663272 3146.333731  55.469388 17.523823  772.076768  62.744457 -1.548824 3.825707\n",
            "\n",
            "Performance summary for SUGARCANE (with_network):\n",
            "     Crop            Model   FeatureSet    MAE_mean    MAE_std   RMSE_mean    RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "SUGARCANE GradientBoosting with_network  753.775651  96.525301 1096.783757  149.226665  25.275968  7.756387  507.057093  58.955599  0.822514 0.045323\n",
            "SUGARCANE     RandomForest with_network  873.815568 112.806325 1264.962908  180.500795  28.805877  8.451989  602.867089  43.480200  0.763523 0.063931\n",
            "SUGARCANE            Ridge with_network 1406.205730 626.750901 3013.749748 2646.017657  50.670481 14.075450  752.979320  72.188678 -0.980920 2.864074\n",
            "\n",
            "===== FINAL SUMMARY (ADVANCED PROPOSED MODELS ONLY) =====\n",
            "  COTTON: Proposed model = GradientBoosting (FeatureSet=with_network), MAE_mean=61.37, R2_mean=0.673\n",
            "  GROUNDNUT: Proposed model = GradientBoosting (FeatureSet=with_network), MAE_mean=191.27, R2_mean=0.632\n",
            "  MAIZE: Proposed model = GradientBoosting (FeatureSet=with_network), MAE_mean=315.29, R2_mean=0.749\n",
            "  RICE: Proposed model = GradientBoosting (FeatureSet=with_network), MAE_mean=224.59, R2_mean=0.860\n",
            "  SUGARCANE: Proposed model = GradientBoosting (FeatureSet=with_network), MAE_mean=753.78, R2_mean=0.823\n",
            "  WHEAT: Proposed model = GradientBoosting (FeatureSet=with_network), MAE_mean=223.13, R2_mean=0.874\n",
            "Saved diagnostic plots for COTTON (GradientBoosting, feature set=with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved diagnostic plots for GROUNDNUT (GradientBoosting, feature set=with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved diagnostic plots for MAIZE (GradientBoosting, feature set=with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved diagnostic plots for RICE (GradientBoosting, feature set=with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved diagnostic plots for SUGARCANE (GradientBoosting, feature set=with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved diagnostic plots for WHEAT (GradientBoosting, feature set=with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "\n",
            "===== PIPELINE COMPLETE =====\n",
            "Rows after cleaning: 16146\n",
            "Years: 1966 - 2017\n",
            "Number of districts (by Dist Code): 311\n",
            "Crops modeled: ['RICE', 'WHEAT', 'MAIZE', 'GROUNDNUT', 'COTTON', 'SUGARCANE']\n",
            "Cleaned dataset with features: /content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\n",
            "Model performance summary: /content/drive/MyDrive/Shiny/ICRISAT/Results/model_performance_summary.csv\n",
            "Supervised panel CSV prefix: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_\n",
            "Key PDF plots saved in OUTPUT_DIR (diagnostic scatter + residuals for best advanced models).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import warnings\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")  # for headless PDF saving\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        ")\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# CONFIG\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "RAW_CSV_PATH = \"/content/drive/MyDrive/Shiny/ICRISAT/Data/icrisat_raw.csv\"\n",
        "CLEANED_CSV_PATH = \"/content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Shiny/ICRISAT/Results\"\n",
        "\n",
        "SUPERVISED_PANEL_PREFIX = os.path.join(OUTPUT_DIR, \"supervised_panel_\")\n",
        "MODEL_PER_FOLD_CSV = os.path.join(OUTPUT_DIR, \"model_per_fold_raw.csv\")\n",
        "MODEL_PERF_SUMMARY_CSV = os.path.join(OUTPUT_DIR, \"model_performance_summary.csv\")\n",
        "BEST_MODELS_CSV = os.path.join(OUTPUT_DIR, \"best_models_advanced_only.csv\")\n",
        "\n",
        "CROPS = [\"RICE\", \"WHEAT\", \"MAIZE\", \"GROUNDNUT\", \"COTTON\", \"SUGARCANE\"]\n",
        "RANDOM_STATE = 42\n",
        "N_FOLDS = 3\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# UTILS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def mape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    \"\"\"Mean Absolute Percentage Error in %, safely handling zeros.\"\"\"\n",
        "    y_true = np.array(y_true, dtype=float)\n",
        "    y_pred = np.array(y_pred, dtype=float)\n",
        "    denom = np.where(y_true == 0, np.nan, np.abs(y_true))\n",
        "    return np.nanmean(np.abs(y_true - y_pred) / denom) * 100.0\n",
        "\n",
        "\n",
        "def median_ae(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    y_true = np.array(y_true, dtype=float)\n",
        "    y_pred = np.array(y_pred, dtype=float)\n",
        "    return float(np.median(np.abs(y_true - y_pred)))\n",
        "\n",
        "\n",
        "def safe_print(*args, **kwargs):\n",
        "    \"\"\"Wrapper to avoid crashing on weird encodings.\"\"\"\n",
        "    try:\n",
        "        print(*args, **kwargs)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# LOADING + BASIC EDA\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def load_data() -> Tuple[pd.DataFrame, str]:\n",
        "    \"\"\"Load raw CSV if available, otherwise fall back to existing cleaned dataset.\"\"\"\n",
        "    if os.path.exists(RAW_CSV_PATH):\n",
        "        safe_print(f\"RAW_CSV_PATH found: {RAW_CSV_PATH}\")\n",
        "        df = pd.read_csv(RAW_CSV_PATH)\n",
        "        source_type = \"raw\"\n",
        "    elif os.path.exists(CLEANED_CSV_PATH):\n",
        "        safe_print(\"RAW_CSV_PATH not found.\")\n",
        "        safe_print(f\"Falling back to existing CLEANED dataset: {CLEANED_CSV_PATH}\\n\")\n",
        "        df = pd.read_csv(CLEANED_CSV_PATH)\n",
        "        source_type = \"cleaned\"\n",
        "    else:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Neither raw ({RAW_CSV_PATH}) nor cleaned ({CLEANED_CSV_PATH}) dataset is available.\"\n",
        "        )\n",
        "    return df, source_type\n",
        "\n",
        "\n",
        "def basic_eda(df: pd.DataFrame) -> None:\n",
        "    safe_print(\"===== BASIC EDA =====\")\n",
        "    key_cols = [\"Dist Code\", \"Year\"]\n",
        "    if all(k in df.columns for k in key_cols):\n",
        "        dup = df.duplicated(subset=key_cols).sum()\n",
        "        safe_print(f\"Duplicate (Dist Code, Year) rows: {dup}\")\n",
        "        safe_print(f\"Key (Dist Code, Year) is {'NOT ' if dup>0 else ''}unique.\\n\")\n",
        "    else:\n",
        "        safe_print(\"Warning: 'Dist Code' / 'Year' not found for uniqueness check.\\n\")\n",
        "\n",
        "    safe_print(f\"Rows: {len(df):d}, Columns: {df.shape[1]:d}\")\n",
        "\n",
        "    if \"Year\" in df.columns:\n",
        "        safe_print(f\"Time range: {int(df['Year'].min())} - {int(df['Year'].max())}\")\n",
        "\n",
        "    state_cols = [c for c in df.columns if \"STATE\" in c.upper() or \"STATE NAME\" in c.upper()]\n",
        "    if state_cols:\n",
        "        sc = state_cols[0]\n",
        "        safe_print(f\"Unique States: {df[sc].nunique()}\")\n",
        "\n",
        "    yield_cols = [c for c in df.columns if \"YIELD (Kg per ha)\" in c]\n",
        "    crops = sorted(list({c.split(\" YIELD\")[0].strip() for c in yield_cols}))\n",
        "    safe_print(f\"Detected crops (count={len(crops)}): {crops[:23]}...\\n\")\n",
        "\n",
        "    if yield_cols:\n",
        "        miss_info = (\n",
        "            pd.DataFrame(\n",
        "                {\n",
        "                    \"YieldColumn\": yield_cols,\n",
        "                    \"MissingPct\": [df[col].isna().mean() * 100.0 for col in yield_cols],\n",
        "                }\n",
        "            )\n",
        "            .sort_values(\"MissingPct\")\n",
        "            .reset_index(drop=True)\n",
        "        )\n",
        "        safe_print(\"Yield missingness (% of NaN):\")\n",
        "        safe_print(miss_info.to_string(index=False))\n",
        "        safe_print()\n",
        "\n",
        "        for col in [\"RICE YIELD (Kg per ha)\",\n",
        "                    \"WHEAT YIELD (Kg per ha)\",\n",
        "                    \"MAIZE YIELD (Kg per ha)\",\n",
        "                    \"GROUNDNUT YIELD (Kg per ha)\",\n",
        "                    \"COTTON YIELD (Kg per ha)\",\n",
        "                    \"SUGARCANE YIELD (Kg per ha)\"]:\n",
        "            if col in df.columns:\n",
        "                safe_print(f\"Summary for {col.split(' YIELD')[0]} yield:\")\n",
        "                safe_print(df[col].describe())\n",
        "                safe_print()\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# CLEANING YIELDS + DIVERSIFICATION\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def clean_yields(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clip extreme outliers and replace negatives for all yield columns.\"\"\"\n",
        "    safe_print(\"===== CLEANING DATA =====\")\n",
        "    df = df.copy()\n",
        "    yield_cols = [c for c in df.columns if \"YIELD (Kg per ha)\" in c]\n",
        "\n",
        "    for col in yield_cols:\n",
        "        s = df[col].copy()\n",
        "        old_max = s.max()\n",
        "        s = s.clip(lower=0)\n",
        "        if (s > 0).sum() > 0:\n",
        "            q = s[s > 0].quantile(0.995)\n",
        "            s = s.clip(upper=q)\n",
        "            new_max = float(s.max())\n",
        "            if new_max < old_max:\n",
        "                safe_print(f\"Clipped {col.split(' YIELD')[0]} yield: old max={old_max:.2f}, new max={new_max:.2f}\")\n",
        "        df[col] = s\n",
        "\n",
        "    safe_print()\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_diversification_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Compute simple diversification features using AREA columns if available.\n",
        "    Uses 1 - HHI (Simpson-like) and number of active crops.\n",
        "    \"\"\"\n",
        "    safe_print(\"===== COMPUTING DIVERSIFICATION =====\")\n",
        "    df = df.copy()\n",
        "\n",
        "    yield_cols = [c for c in df.columns if \"YIELD (Kg per ha)\" in c]\n",
        "    crop_names = [c.split(\" YIELD\")[0].strip() for c in yield_cols]\n",
        "\n",
        "    crop_area_cols = {}\n",
        "    for crop in crop_names:\n",
        "        candidates = [c for c in df.columns if crop in c and \"AREA\" in c.upper()]\n",
        "        if candidates:\n",
        "            crop_area_cols[crop] = candidates[0]\n",
        "\n",
        "    if not crop_area_cols:\n",
        "        safe_print(\"No AREA columns detected  diversification features will be zeros.\\n\")\n",
        "        df[\"diversity_simpson\"] = 0.0\n",
        "        df[\"num_active_crops\"] = 0\n",
        "        return df\n",
        "\n",
        "    area_mat = df[[crop_area_cols[c] for c in crop_area_cols]].fillna(0.0).values\n",
        "    total_area = area_mat.sum(axis=1)\n",
        "    total_area_safe = np.where(total_area == 0, 1.0, total_area)\n",
        "    shares = area_mat / total_area_safe[:, None]\n",
        "    hhi = (shares ** 2).sum(axis=1)\n",
        "    simpson = 1.0 - hhi\n",
        "    num_active = (area_mat > 0).sum(axis=1)\n",
        "\n",
        "    df[\"diversity_simpson\"] = simpson\n",
        "    df[\"num_active_crops\"] = num_active\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# NETWORKS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def build_district_network(df: pd.DataFrame) -> Tuple[nx.Graph, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Build a simple district similarity network using yield profiles\n",
        "    in a reference window (20082017).\n",
        "    Returns:\n",
        "        G: NetworkX graph\n",
        "        dist_features: DataFrame with ['Dist Code', 'net_degree', 'net_strength', 'net_closeness', 'net_betweenness']\n",
        "    \"\"\"\n",
        "    safe_print(\"===== BUILDING DISTRICT SIMILARITY NETWORK =====\")\n",
        "    df_ref = df.copy()\n",
        "    if \"Year\" in df_ref.columns:\n",
        "        df_ref = df_ref[(df_ref[\"Year\"] >= 2008) & (df_ref[\"Year\"] <= 2017)]\n",
        "\n",
        "    if \"Dist Code\" not in df_ref.columns:\n",
        "        safe_print(\"No 'Dist Code' column: cannot build district network.\")\n",
        "        return nx.Graph(), pd.DataFrame(columns=[\"Dist Code\"])\n",
        "\n",
        "    yield_cols = [c for c in df_ref.columns if \"YIELD (Kg per ha)\" in c]\n",
        "    if not yield_cols:\n",
        "        safe_print(\"No YIELD columns found: cannot build district network.\")\n",
        "        return nx.Graph(), pd.DataFrame(columns=[\"Dist Code\"])\n",
        "\n",
        "    prof = (\n",
        "        df_ref.groupby(\"Dist Code\")[yield_cols]\n",
        "        .mean()\n",
        "        .fillna(0.0)\n",
        "    )\n",
        "\n",
        "    if prof.shape[0] == 0:\n",
        "        safe_print(\"No district profiles after filtering.\")\n",
        "        return nx.Graph(), pd.DataFrame(columns=[\"Dist Code\"])\n",
        "\n",
        "    arr = prof.values\n",
        "    norms = np.linalg.norm(arr, axis=1)\n",
        "    norms_safe = np.where(norms == 0, 1.0, norms)\n",
        "    arr_norm = arr / norms_safe[:, None]\n",
        "\n",
        "    sim = arr_norm @ arr_norm.T\n",
        "\n",
        "    dist_codes = prof.index.tolist()\n",
        "    G = nx.Graph()\n",
        "    for di in dist_codes:\n",
        "        G.add_node(di)\n",
        "\n",
        "    thr = 0.6\n",
        "    n = sim.shape[0]\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            w = float(sim[i, j])\n",
        "            if w >= thr:\n",
        "                G.add_edge(dist_codes[i], dist_codes[j], weight=w)\n",
        "\n",
        "    safe_print(f\"Network reference window: 2008-2017\")\n",
        "    safe_print(f\"District network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\\n\")\n",
        "\n",
        "    if G.number_of_nodes() == 0:\n",
        "        return G, pd.DataFrame(columns=[\"Dist Code\"])\n",
        "\n",
        "    deg = dict(G.degree())\n",
        "    strength = {n: sum(d[\"weight\"] for _, _, d in G.edges(n, data=True)) for n in G.nodes}\n",
        "    closeness = nx.closeness_centrality(G)\n",
        "    betw = nx.betweenness_centrality(G, normalized=True)\n",
        "\n",
        "    dist_features = pd.DataFrame({\n",
        "        \"Dist Code\": list(G.nodes),\n",
        "        \"net_degree\": [deg[d] for d in G.nodes],\n",
        "        \"net_strength\": [strength[d] for d in G.nodes],\n",
        "        \"net_closeness\": [closeness[d] for d in G.nodes],\n",
        "        \"net_betweenness\": [betw[d] for d in G.nodes],\n",
        "    })\n",
        "\n",
        "    return G, dist_features\n",
        "\n",
        "\n",
        "def build_crop_cooccurrence_network(df: pd.DataFrame) -> nx.Graph:\n",
        "    \"\"\"\n",
        "    Simple crop co-occurrence network (for descriptive use; not fed into models here).\n",
        "    Nodes: crops; edge weight = number of district-years where both are active.\n",
        "    \"\"\"\n",
        "    safe_print(\"===== BUILDING CROP-COOCCURRENCE NETWORK =====\")\n",
        "    yield_cols = [c for c in df.columns if \"YIELD (Kg per ha)\" in c]\n",
        "    if not yield_cols:\n",
        "        safe_print(\"No YIELD columns, skipping crop network.\\n\")\n",
        "        return nx.Graph()\n",
        "\n",
        "    crop_names = [c.split(\" YIELD\")[0].strip() for c in yield_cols]\n",
        "    crop_idx = {col: crop_names[i] for i, col in enumerate(yield_cols)}\n",
        "\n",
        "    G = nx.Graph()\n",
        "    for crop in crop_names:\n",
        "        G.add_node(crop)\n",
        "\n",
        "    key_cols = [c for c in [\"Dist Code\", \"Year\"] if c in df.columns]\n",
        "    if not key_cols:\n",
        "        rows = [df]\n",
        "    else:\n",
        "        rows = [g for _, g in df.groupby(key_cols)]\n",
        "\n",
        "    from itertools import combinations\n",
        "\n",
        "    for sub in rows:\n",
        "        vals = sub[yield_cols].fillna(0.0)\n",
        "        active_mask = (vals > 0).any(axis=0)\n",
        "        active_cols = [c for c, m in zip(yield_cols, active_mask) if m]\n",
        "        active_crops = [crop_idx[c] for c in active_cols]\n",
        "        for c1, c2 in combinations(sorted(set(active_crops)), 2):\n",
        "            if G.has_edge(c1, c2):\n",
        "                G[c1][c2][\"weight\"] += 1\n",
        "            else:\n",
        "                G.add_edge(c1, c2, weight=1)\n",
        "\n",
        "    safe_print(f\"Crop network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\\n\")\n",
        "    return G\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# SUPERVISED PANEL PREPARATION\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def prepare_panel_for_crop(\n",
        "    df: pd.DataFrame,\n",
        "    crop: str\n",
        ") -> Tuple[pd.DataFrame, str, List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    Build supervised panel for a given crop:\n",
        "      - adds lags & rolling mean\n",
        "      - identifies feature columns and network feature subset.\n",
        "    Returns:\n",
        "      panel, yield_col, feature_cols, network_feature_cols\n",
        "    \"\"\"\n",
        "    yield_candidates = [c for c in df.columns if c.startswith(crop) and \"YIELD (Kg per ha)\" in c]\n",
        "    if not yield_candidates:\n",
        "        raise ValueError(f\"Yield column for crop '{crop}' not found.\")\n",
        "    yield_col = yield_candidates[0]\n",
        "\n",
        "    if \"Dist Code\" not in df.columns or \"Year\" not in df.columns:\n",
        "        raise ValueError(\"Both 'Dist Code' and 'Year' must be present in the dataset.\")\n",
        "\n",
        "    panel = df.copy()\n",
        "    panel = panel.sort_values([\"Dist Code\", \"Year\"])\n",
        "    grp = panel.groupby(\"Dist Code\")[yield_col]\n",
        "\n",
        "    panel[f\"{crop}_lag1\"] = grp.shift(1)\n",
        "    panel[f\"{crop}_lag2\"] = grp.shift(2)\n",
        "    panel[f\"{crop}_lag3\"] = grp.shift(3)\n",
        "    panel[f\"{crop}_roll3\"] = grp.shift(1).rolling(window=3, min_periods=1).mean()\n",
        "\n",
        "    excluded = {\"Dist Code\", \"Year\", yield_col}\n",
        "    feature_cols = []\n",
        "    for col in panel.columns:\n",
        "        if col in excluded:\n",
        "            continue\n",
        "        if np.issubdtype(panel[col].dtype, np.number):\n",
        "            feature_cols.append(col)\n",
        "\n",
        "    network_feature_cols = [\n",
        "        c for c in feature_cols\n",
        "        if c.lower().startswith(\"net_\")\n",
        "        or \"network\" in c.lower()\n",
        "        or \"centrality\" in c.lower()\n",
        "    ]\n",
        "\n",
        "    return panel, yield_col, feature_cols, network_feature_cols\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# TIME-SERIES CROSS-VALIDATION SPLITS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def time_series_folds(years: np.ndarray, n_folds: int = N_FOLDS) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    \"\"\"\n",
        "    Make simple expanding-window time-based folds.\n",
        "    Returns list of (train_years, test_years).\n",
        "    \"\"\"\n",
        "    years_unique = np.sort(np.unique(years))\n",
        "    n_years = len(years_unique)\n",
        "    if n_years < n_folds + 1:\n",
        "        warnings.warn(f\"Too few years ({n_years}) for {n_folds} folds; using single split.\")\n",
        "        mid = n_years // 2\n",
        "        return [(years_unique[:mid], years_unique[mid:])]\n",
        "\n",
        "    split_indices = [\n",
        "        int((i + 1) * n_years / (n_folds + 1))\n",
        "        for i in range(n_folds)\n",
        "    ]\n",
        "\n",
        "    folds = []\n",
        "    for i in range(n_folds):\n",
        "        train_end_idx = split_indices[i]\n",
        "        test_start_idx = train_end_idx\n",
        "        test_end_idx = split_indices[i + 1] if i + 1 < len(split_indices) else n_years\n",
        "\n",
        "        train_years = years_unique[:train_end_idx]\n",
        "        test_years = years_unique[test_start_idx:test_end_idx]\n",
        "        if len(train_years) == 0 or len(test_years) == 0:\n",
        "            continue\n",
        "        folds.append((train_years, test_years))\n",
        "\n",
        "    return folds\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# MODEL TRAINING + EVALUATION\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def evaluate_models_for_crop(\n",
        "    crop: str,\n",
        "    panel: pd.DataFrame,\n",
        "    yield_col: str,\n",
        "    feature_cols: List[str],\n",
        "    network_feature_cols: List[str],\n",
        ") -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Evaluate Naive, RollingMean3, Ridge, RandomForest, GradientBoosting\n",
        "    under no_network / with_network feature sets.\n",
        "    Returns list of per-fold metric dicts.\n",
        "    \"\"\"\n",
        "    records = []\n",
        "\n",
        "    mask_valid = panel[yield_col].notna() & (panel[yield_col] > 0)\n",
        "    panel_valid = panel.loc[mask_valid].copy()\n",
        "\n",
        "    years = panel_valid[\"Year\"].values\n",
        "    folds = time_series_folds(years, n_folds=N_FOLDS)\n",
        "    if not folds:\n",
        "        warnings.warn(f\"No valid folds for crop {crop}; skipping.\")\n",
        "        return records\n",
        "\n",
        "    non_network_feature_cols = [c for c in feature_cols if c not in network_feature_cols]\n",
        "    if not non_network_feature_cols:\n",
        "        non_network_feature_cols = feature_cols\n",
        "        network_feature_cols = []\n",
        "\n",
        "    ridge_no_net = Ridge(alpha=1.0, random_state=RANDOM_STATE)\n",
        "    ridge_with_net = Ridge(alpha=1.0, random_state=RANDOM_STATE)\n",
        "\n",
        "    rf_no_net = RandomForestRegressor(\n",
        "        n_estimators=300,\n",
        "        max_depth=None,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "    rf_with_net = RandomForestRegressor(\n",
        "        n_estimators=300,\n",
        "        max_depth=None,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    gb_no_net = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
        "    gb_with_net = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
        "\n",
        "    fold_id = 0\n",
        "    for train_years, test_years in folds:\n",
        "        fold_id += 1\n",
        "        train_mask = panel_valid[\"Year\"].isin(train_years)\n",
        "        test_mask = panel_valid[\"Year\"].isin(test_years)\n",
        "\n",
        "        train_df = panel_valid.loc[train_mask]\n",
        "        test_df = panel_valid.loc[test_mask]\n",
        "\n",
        "        if len(train_df) == 0 or len(test_df) == 0:\n",
        "            continue\n",
        "\n",
        "        y_train = train_df[yield_col].values\n",
        "        y_test = test_df[yield_col].values\n",
        "\n",
        "        lag_col = f\"{crop}_lag1\"\n",
        "        roll3_col = f\"{crop}_roll3\"\n",
        "\n",
        "        # -----------------------------\n",
        "        # Baseline 1: Naive (lag-1)\n",
        "        # -----------------------------\n",
        "        if lag_col in test_df.columns:\n",
        "            y_pred_naive = test_df[lag_col].values.astype(float)\n",
        "            mean_train = y_train.mean()\n",
        "            y_pred_naive = np.where(np.isnan(y_pred_naive), mean_train, y_pred_naive)\n",
        "        else:\n",
        "            y_pred_naive = np.full_like(y_test, y_train.mean(), dtype=float)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred_naive)\n",
        "        rmse = mean_squared_error(y_test, y_pred_naive) ** 0.5\n",
        "        mape_val = mape(y_test, y_pred_naive)\n",
        "        medae = median_ae(y_test, y_pred_naive)\n",
        "        r2 = r2_score(y_test, y_pred_naive)\n",
        "\n",
        "        safe_print(f\"{crop} | Naive | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "\n",
        "        records.append({\n",
        "            \"Crop\": crop,\n",
        "            \"Model\": \"Naive\",\n",
        "            \"FeatureSet\": \"no_network\",\n",
        "            \"Fold\": fold_id,\n",
        "            \"MAE\": mae,\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAPE\": mape_val,\n",
        "            \"MedAE\": medae,\n",
        "            \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # -----------------------------\n",
        "        # Baseline 2: RollingMean3\n",
        "        # -----------------------------\n",
        "        if roll3_col in test_df.columns:\n",
        "            y_pred_roll3 = test_df[roll3_col].values.astype(float)\n",
        "            mean_train = y_train.mean()\n",
        "            y_pred_roll3 = np.where(np.isnan(y_pred_roll3), mean_train, y_pred_roll3)\n",
        "        else:\n",
        "            y_pred_roll3 = np.full_like(y_test, y_train.mean(), dtype=float)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred_roll3)\n",
        "        rmse = mean_squared_error(y_test, y_pred_roll3) ** 0.5\n",
        "        mape_val = mape(y_test, y_pred_roll3)\n",
        "        medae = median_ae(y_test, y_pred_roll3)\n",
        "        r2 = r2_score(y_test, y_pred_roll3)\n",
        "\n",
        "        safe_print(f\"{crop} | RollingMean3 | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "\n",
        "        records.append({\n",
        "            \"Crop\": crop,\n",
        "            \"Model\": \"RollingMean3\",\n",
        "            \"FeatureSet\": \"no_network\",\n",
        "            \"Fold\": fold_id,\n",
        "            \"MAE\": mae,\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAPE\": mape_val,\n",
        "            \"MedAE\": medae,\n",
        "            \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # -----------------------------\n",
        "        # Advanced models: no_network\n",
        "        # -----------------------------\n",
        "        X_train_no_net = train_df[non_network_feature_cols].fillna(0.0).values\n",
        "        X_test_no_net = test_df[non_network_feature_cols].fillna(0.0).values\n",
        "\n",
        "        # Ridge no_network\n",
        "        ridge_no_net.fit(X_train_no_net, y_train)\n",
        "        y_pred = ridge_no_net.predict(X_test_no_net)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        safe_print(f\"{crop} | Ridge | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop,\n",
        "            \"Model\": \"Ridge\",\n",
        "            \"FeatureSet\": \"no_network\",\n",
        "            \"Fold\": fold_id,\n",
        "            \"MAE\": mae,\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAPE\": mape_val,\n",
        "            \"MedAE\": medae,\n",
        "            \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # RandomForest no_network\n",
        "        rf_no_net.fit(X_train_no_net, y_train)\n",
        "        y_pred = rf_no_net.predict(X_test_no_net)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        safe_print(f\"{crop} | RandomForest | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop,\n",
        "            \"Model\": \"RandomForest\",\n",
        "            \"FeatureSet\": \"no_network\",\n",
        "            \"Fold\": fold_id,\n",
        "            \"MAE\": mae,\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAPE\": mape_val,\n",
        "            \"MedAE\": medae,\n",
        "            \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # GradientBoosting no_network\n",
        "        gb_no_net.fit(X_train_no_net, y_train)\n",
        "        y_pred = gb_no_net.predict(X_test_no_net)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        safe_print(f\"{crop} | GradientBoosting | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop,\n",
        "            \"Model\": \"GradientBoosting\",\n",
        "            \"FeatureSet\": \"no_network\",\n",
        "            \"Fold\": fold_id,\n",
        "            \"MAE\": mae,\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAPE\": mape_val,\n",
        "            \"MedAE\": medae,\n",
        "            \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # -----------------------------\n",
        "        # Advanced models: with_network\n",
        "        # -----------------------------\n",
        "        if network_feature_cols:\n",
        "            feature_cols_with_net = non_network_feature_cols + network_feature_cols\n",
        "        else:\n",
        "            feature_cols_with_net = non_network_feature_cols\n",
        "\n",
        "        X_train_with_net = train_df[feature_cols_with_net].fillna(0.0).values\n",
        "        X_test_with_net = test_df[feature_cols_with_net].fillna(0.0).values\n",
        "\n",
        "        # Ridge with_network\n",
        "        ridge_with_net.fit(X_train_with_net, y_train)\n",
        "        y_pred = ridge_with_net.predict(X_test_with_net)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        safe_print(f\"{crop} | Ridge | with_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop,\n",
        "            \"Model\": \"Ridge\",\n",
        "            \"FeatureSet\": \"with_network\",\n",
        "            \"Fold\": fold_id,\n",
        "            \"MAE\": mae,\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAPE\": mape_val,\n",
        "            \"MedAE\": medae,\n",
        "            \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # RandomForest with_network\n",
        "        rf_with_net.fit(X_train_with_net, y_train)\n",
        "        y_pred = rf_with_net.predict(X_test_with_net)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        safe_print(f\"{crop} | RandomForest | with_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop,\n",
        "            \"Model\": \"RandomForest\",\n",
        "            \"FeatureSet\": \"with_network\",\n",
        "            \"Fold\": fold_id,\n",
        "            \"MAE\": mae,\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAPE\": mape_val,\n",
        "            \"MedAE\": medae,\n",
        "            \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # GradientBoosting with_network\n",
        "        gb_with_net.fit(X_train_with_net, y_train)\n",
        "        y_pred = gb_with_net.predict(X_test_with_net)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        safe_print(f\"{crop} | GradientBoosting | with_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop,\n",
        "            \"Model\": \"GradientBoosting\",\n",
        "            \"FeatureSet\": \"with_network\",\n",
        "            \"Fold\": fold_id,\n",
        "            \"MAE\": mae,\n",
        "            \"RMSE\": rmse,\n",
        "            \"MAPE\": mape_val,\n",
        "            \"MedAE\": medae,\n",
        "            \"R2\": r2,\n",
        "        })\n",
        "\n",
        "    return records\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# MODEL SELECTION (ADVANCED ONLY) + SUMMARY\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def summarise_performance(per_fold_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    agg = (\n",
        "        per_fold_df\n",
        "        .groupby([\"Crop\", \"Model\", \"FeatureSet\"])\n",
        "        .agg(\n",
        "            MAE_mean=(\"MAE\", \"mean\"),\n",
        "            MAE_std=(\"MAE\", \"std\"),\n",
        "            RMSE_mean=(\"RMSE\", \"mean\"),\n",
        "            RMSE_std=(\"RMSE\", \"std\"),\n",
        "            MAPE_mean=(\"MAPE\", \"mean\"),\n",
        "            MAPE_std=(\"MAPE\", \"std\"),\n",
        "            MedAE_mean=(\"MedAE\", \"mean\"),\n",
        "            MedAE_std=(\"MedAE\", \"std\"),\n",
        "            R2_mean=(\"R2\", \"mean\"),\n",
        "            R2_std=(\"R2\", \"std\"),\n",
        "        )\n",
        "        .reset_index()\n",
        "    )\n",
        "    return agg\n",
        "\n",
        "\n",
        "def select_best_advanced_models(perf_summary: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Restrict best-model selection to advanced models only:\n",
        "    Ridge, RandomForest, GradientBoosting.\n",
        "    Preference:\n",
        "      1) lower MAE_mean\n",
        "      2) within 1% of best MAE_mean, highest R2_mean\n",
        "      3) prefer with_network when available\n",
        "    \"\"\"\n",
        "    advanced_models = [\"Ridge\", \"RandomForest\", \"GradientBoosting\"]\n",
        "    best_rows = []\n",
        "\n",
        "    for crop in sorted(perf_summary[\"Crop\"].unique()):\n",
        "        sub = perf_summary[\n",
        "            (perf_summary[\"Crop\"] == crop)\n",
        "            & (perf_summary[\"Model\"].isin(advanced_models))\n",
        "        ]\n",
        "        if sub.empty:\n",
        "            continue\n",
        "\n",
        "        sub_with_net = sub[sub[\"FeatureSet\"] == \"with_network\"]\n",
        "        if not sub_with_net.empty:\n",
        "            cand = sub_with_net\n",
        "        else:\n",
        "            cand = sub\n",
        "\n",
        "        min_mae = cand[\"MAE_mean\"].min()\n",
        "        mae_tol = min_mae * 1.01  # 1% tolerance\n",
        "        cand = cand[cand[\"MAE_mean\"] <= mae_tol]\n",
        "\n",
        "        best_idx = cand[\"R2_mean\"].idxmax()\n",
        "        best_row = cand.loc[best_idx].copy()\n",
        "        best_rows.append(best_row)\n",
        "\n",
        "    best_df = pd.DataFrame(best_rows).reset_index(drop=True)\n",
        "    if not best_df.empty:\n",
        "        best_df[\"ModelLabel\"] = [\n",
        "            f\"Proposed_{m}_{fs}\"\n",
        "            for m, fs in zip(best_df[\"Model\"], best_df[\"FeatureSet\"])\n",
        "        ]\n",
        "    return best_df\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# DIAGNOSTIC PLOTS FOR BEST MODELS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def fit_model_for_diagnostics(\n",
        "    crop: str,\n",
        "    panel: pd.DataFrame,\n",
        "    yield_col: str,\n",
        "    feature_cols: List[str],\n",
        "    network_feature_cols: List[str],\n",
        "    model_name: str,\n",
        "    feature_set: str,\n",
        "):\n",
        "    \"\"\"Fit advanced model on all available data for diagnostics (no CV here).\"\"\"\n",
        "    mask_valid = panel[yield_col].notna() & (panel[yield_col] > 0)\n",
        "    df = panel.loc[mask_valid].copy()\n",
        "    y = df[yield_col].values\n",
        "\n",
        "    non_network_feature_cols = [c for c in feature_cols if c not in network_feature_cols]\n",
        "    if feature_set == \"no_network\" or not network_feature_cols:\n",
        "        X_cols = non_network_feature_cols\n",
        "    else:\n",
        "        X_cols = non_network_feature_cols + network_feature_cols\n",
        "\n",
        "    X = df[X_cols].fillna(0.0).values\n",
        "\n",
        "    if model_name == \"Ridge\":\n",
        "        model = Ridge(alpha=1.0, random_state=RANDOM_STATE)\n",
        "    elif model_name == \"RandomForest\":\n",
        "        model = RandomForestRegressor(\n",
        "            n_estimators=300,\n",
        "            max_depth=None,\n",
        "            min_samples_leaf=1,\n",
        "            n_jobs=-1,\n",
        "            random_state=RANDOM_STATE,\n",
        "        )\n",
        "    elif model_name == \"GradientBoosting\":\n",
        "        model = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
        "    else:\n",
        "        raise ValueError(f\"Diagnostics only implemented for advanced models, got {model_name}.\")\n",
        "\n",
        "    model.fit(X, y)\n",
        "    y_pred = model.predict(X)\n",
        "\n",
        "    return df, y, y_pred, X_cols\n",
        "\n",
        "\n",
        "def save_diagnostic_plots(\n",
        "    crop: str,\n",
        "    model_name: str,\n",
        "    feature_set: str,\n",
        "    df: pd.DataFrame,\n",
        "    y_true: np.ndarray,\n",
        "    y_pred: np.ndarray,\n",
        "):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = mean_squared_error(y_true, y_pred) ** 0.5\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.scatter(y_true, y_pred, alpha=0.3)\n",
        "    lims = [\n",
        "        min(y_true.min(), y_pred.min()),\n",
        "        max(y_true.max(), y_pred.max()),\n",
        "    ]\n",
        "    plt.plot(lims, lims)\n",
        "    plt.xlabel(\"Observed yield (kg/ha)\")\n",
        "    plt.ylabel(\"Predicted yield (kg/ha)\")\n",
        "    plt.title(f\"{crop}  {model_name} ({feature_set})\\nMAE={mae:.1f}, RMSE={rmse:.1f}, R={r2:.3f}\")\n",
        "    plt.tight_layout()\n",
        "    scatter_path = os.path.join(\n",
        "        OUTPUT_DIR,\n",
        "        f\"{crop}_{model_name}_{feature_set}_diagnostic_scatter.pdf\",\n",
        "    )\n",
        "    plt.savefig(scatter_path)\n",
        "    plt.close()\n",
        "\n",
        "    residuals = y_true - y_pred\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.scatter(y_pred, residuals, alpha=0.3)\n",
        "    plt.axhline(0.0, linestyle=\"--\")\n",
        "    plt.xlabel(\"Predicted yield (kg/ha)\")\n",
        "    plt.ylabel(\"Residual (observed - predicted)\")\n",
        "    plt.title(f\"{crop}  {model_name} ({feature_set}) residuals\")\n",
        "    plt.tight_layout()\n",
        "    resid_path = os.path.join(\n",
        "        OUTPUT_DIR,\n",
        "        f\"{crop}_{model_name}_{feature_set}_diagnostic_residuals.pdf\",\n",
        "    )\n",
        "    plt.savefig(resid_path)\n",
        "    plt.close()\n",
        "\n",
        "    safe_print(\n",
        "        f\"Saved diagnostic plots for {crop} ({model_name}, feature set={feature_set}) to {OUTPUT_DIR}.\"\n",
        "    )\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# MAIN PIPELINE\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def main():\n",
        "    df, source_type = load_data()\n",
        "    safe_print(f\"Data source type: {source_type}\")\n",
        "    basic_eda(df)\n",
        "\n",
        "    df = clean_yields(df)\n",
        "    df = compute_diversification_features(df)\n",
        "\n",
        "    dist_graph, dist_feats = build_district_network(df)\n",
        "    crop_graph = build_crop_cooccurrence_network(df)\n",
        "\n",
        "    if not dist_feats.empty:\n",
        "        df = df.merge(dist_feats, on=\"Dist Code\", how=\"left\")\n",
        "\n",
        "    df.to_csv(CLEANED_CSV_PATH, index=False)\n",
        "    safe_print(f\"Saved cleaned dataset with features to: {CLEANED_CSV_PATH}\\n\")\n",
        "\n",
        "    all_records = []\n",
        "    panels_by_crop: Dict[str, Dict] = {}\n",
        "\n",
        "    for crop in CROPS:\n",
        "        panel, y_col, feat_cols, net_cols = prepare_panel_for_crop(df, crop)\n",
        "\n",
        "        panel_path = f\"{SUPERVISED_PANEL_PREFIX}{crop.lower()}.csv\"\n",
        "        panel.to_csv(panel_path, index=False)\n",
        "        safe_print(f\"Saved supervised panel for {crop} to: {panel_path}\\n\")\n",
        "\n",
        "        panels_by_crop[crop] = {\n",
        "            \"panel\": panel,\n",
        "            \"yield_col\": y_col,\n",
        "            \"feature_cols\": feat_cols,\n",
        "            \"network_feature_cols\": net_cols,\n",
        "        }\n",
        "\n",
        "        crop_records = evaluate_models_for_crop(\n",
        "            crop=crop,\n",
        "            panel=panel,\n",
        "            yield_col=y_col,\n",
        "            feature_cols=feat_cols,\n",
        "            network_feature_cols=net_cols,\n",
        "        )\n",
        "        all_records.extend(crop_records)\n",
        "\n",
        "    per_fold_df = pd.DataFrame(all_records)\n",
        "    per_fold_df.to_csv(MODEL_PER_FOLD_CSV, index=False)\n",
        "    safe_print(f\"\\nSaved per-fold model results to: {MODEL_PER_FOLD_CSV}\")\n",
        "\n",
        "    perf_summary = summarise_performance(per_fold_df)\n",
        "    perf_summary.to_csv(MODEL_PERF_SUMMARY_CSV, index=False)\n",
        "    safe_print(f\"Saved model performance summary to: {MODEL_PERF_SUMMARY_CSV}\\n\")\n",
        "\n",
        "    for crop in CROPS:\n",
        "        for fs in [\"no_network\", \"with_network\"]:\n",
        "            sub = perf_summary[(perf_summary[\"Crop\"] == crop) & (perf_summary[\"FeatureSet\"] == fs)]\n",
        "            if sub.empty:\n",
        "                continue\n",
        "            safe_print(f\"Performance summary for {crop} ({fs}):\")\n",
        "            safe_print(sub.sort_values(\"MAE_mean\").to_string(index=False))\n",
        "            safe_print()\n",
        "\n",
        "    best_df = select_best_advanced_models(perf_summary)\n",
        "    best_df.to_csv(BEST_MODELS_CSV, index=False)\n",
        "\n",
        "    safe_print(\"===== FINAL SUMMARY (ADVANCED PROPOSED MODELS ONLY) =====\")\n",
        "    for row in best_df.itertuples(index=False):\n",
        "        safe_print(\n",
        "            f\"  {row.Crop}: Proposed model = {row.Model} (FeatureSet={row.FeatureSet}), \"\n",
        "            f\"MAE_mean={row.MAE_mean:.2f}, R2_mean={row.R2_mean:.3f}\"\n",
        "        )\n",
        "\n",
        "    for row in best_df.itertuples(index=False):\n",
        "        crop = row.Crop\n",
        "        model_name = row.Model\n",
        "        feature_set = row.FeatureSet\n",
        "\n",
        "        meta = panels_by_crop[crop]\n",
        "        panel = meta[\"panel\"]\n",
        "        y_col = meta[\"yield_col\"]\n",
        "        feat_cols = meta[\"feature_cols\"]\n",
        "        net_cols = meta[\"network_feature_cols\"]\n",
        "\n",
        "        df_diag, y_true, y_pred, _ = fit_model_for_diagnostics(\n",
        "            crop=crop,\n",
        "            panel=panel,\n",
        "            yield_col=y_col,\n",
        "            feature_cols=feat_cols,\n",
        "            network_feature_cols=net_cols,\n",
        "            model_name=model_name,\n",
        "            feature_set=feature_set,\n",
        "        )\n",
        "\n",
        "        save_diagnostic_plots(\n",
        "            crop=crop,\n",
        "            model_name=model_name,\n",
        "            feature_set=feature_set,\n",
        "            df=df_diag,\n",
        "            y_true=y_true,\n",
        "            y_pred=y_pred,\n",
        "        )\n",
        "\n",
        "    safe_print(\"\\n===== PIPELINE COMPLETE =====\")\n",
        "    if \"Year\" in df.columns:\n",
        "        safe_print(f\"Rows after cleaning: {len(df)}\")\n",
        "        safe_print(f\"Years: {int(df['Year'].min())} - {int(df['Year'].max())}\")\n",
        "    safe_print(f\"Number of districts (by Dist Code): {df['Dist Code'].nunique() if 'Dist Code' in df.columns else 'N/A'}\")\n",
        "    safe_print(f\"Crops modeled: {CROPS}\")\n",
        "    safe_print(f\"Cleaned dataset with features: {CLEANED_CSV_PATH}\")\n",
        "    safe_print(f\"Model performance summary: {MODEL_PERF_SUMMARY_CSV}\")\n",
        "    safe_print(f\"Supervised panel CSV prefix: {SUPERVISED_PANEL_PREFIX}\")\n",
        "    safe_print(\"Key PDF plots saved in OUTPUT_DIR (diagnostic scatter + residuals for best advanced models).\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EhRFYtKclJJ",
        "outputId": "fa3b1941-d16d-4eff-98ea-7d56da8d188c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ENHANCED AGRICULTURAL YIELD PREDICTION PIPELINE\n",
            "======================================================================\n",
            "\n",
            "RAW_CSV_PATH not found.\n",
            "Falling back to existing CLEANED dataset: /content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\n",
            "\n",
            "Data source type: cleaned\n",
            "===== BASIC EDA =====\n",
            "Duplicate (Dist Code, Year) rows: 0\n",
            "Key (Dist Code, Year) is unique.\n",
            "\n",
            "Rows: 16146, Columns: 95\n",
            "Time range: 1966 - 2017\n",
            "Unique States: 20\n",
            "Detected crops (count=23): ['BARLEY', 'CASTOR', 'CHICKPEA', 'COTTON', 'FINGER MILLET', 'GROUNDNUT', 'KHARIF SORGHUM', 'LINSEED', 'MAIZE', 'MINOR PULSES', 'OILSEEDS', 'PEARL MILLET', 'PIGEONPEA', 'RABI SORGHUM', 'RAPESEED AND MUSTARD', 'RICE', 'SAFFLOWER', 'SESAMUM', 'SORGHUM', 'SOYABEAN', 'SUGARCANE', 'SUNFLOWER', 'WHEAT']...\n",
            "\n",
            "Yield missingness (% of NaN):\n",
            "                           YieldColumn  MissingPct\n",
            "                RICE YIELD (Kg per ha)         0.0\n",
            "               WHEAT YIELD (Kg per ha)         0.0\n",
            "      KHARIF SORGHUM YIELD (Kg per ha)         0.0\n",
            "        RABI SORGHUM YIELD (Kg per ha)         0.0\n",
            "             SORGHUM YIELD (Kg per ha)         0.0\n",
            "        PEARL MILLET YIELD (Kg per ha)         0.0\n",
            "               MAIZE YIELD (Kg per ha)         0.0\n",
            "       FINGER MILLET YIELD (Kg per ha)         0.0\n",
            "              BARLEY YIELD (Kg per ha)         0.0\n",
            "            CHICKPEA YIELD (Kg per ha)         0.0\n",
            "           PIGEONPEA YIELD (Kg per ha)         0.0\n",
            "        MINOR PULSES YIELD (Kg per ha)         0.0\n",
            "           GROUNDNUT YIELD (Kg per ha)         0.0\n",
            "             SESAMUM YIELD (Kg per ha)         0.0\n",
            "RAPESEED AND MUSTARD YIELD (Kg per ha)         0.0\n",
            "           SAFFLOWER YIELD (Kg per ha)         0.0\n",
            "              CASTOR YIELD (Kg per ha)         0.0\n",
            "             LINSEED YIELD (Kg per ha)         0.0\n",
            "           SUNFLOWER YIELD (Kg per ha)         0.0\n",
            "            SOYABEAN YIELD (Kg per ha)         0.0\n",
            "            OILSEEDS YIELD (Kg per ha)         0.0\n",
            "           SUGARCANE YIELD (Kg per ha)         0.0\n",
            "              COTTON YIELD (Kg per ha)         0.0\n",
            "\n",
            "Summary for RICE yield:\n",
            "count    16146.000000\n",
            "mean      1483.290702\n",
            "std        945.010569\n",
            "min          0.000000\n",
            "25%        800.000000\n",
            "50%       1333.210000\n",
            "75%       2113.517500\n",
            "max       4104.220225\n",
            "Name: RICE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for WHEAT yield:\n",
            "count    16146.000000\n",
            "mean      1489.251300\n",
            "std       1071.684468\n",
            "min          0.000000\n",
            "25%        750.000000\n",
            "50%       1347.450000\n",
            "75%       2131.580000\n",
            "max       4484.001525\n",
            "Name: WHEAT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for MAIZE yield:\n",
            "count    16146.000000\n",
            "mean      1394.218224\n",
            "std       1115.318055\n",
            "min          0.000000\n",
            "25%        696.890000\n",
            "50%       1159.065000\n",
            "75%       1863.640000\n",
            "max       5897.193975\n",
            "Name: MAIZE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for GROUNDNUT yield:\n",
            "count    16146.000000\n",
            "mean       759.271954\n",
            "std        598.966934\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%        774.410000\n",
            "75%       1085.037500\n",
            "max       2540.999725\n",
            "Name: GROUNDNUT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for COTTON yield:\n",
            "count    16146.000000\n",
            "mean       119.821739\n",
            "std        167.337989\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%        202.270000\n",
            "max        740.163350\n",
            "Name: COTTON YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for SUGARCANE yield:\n",
            "count    16146.000000\n",
            "mean      4484.083204\n",
            "std       3105.530811\n",
            "min          0.000000\n",
            "25%       2000.000000\n",
            "50%       4502.210000\n",
            "75%       6704.605000\n",
            "max      12000.000000\n",
            "Name: SUGARCANE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "===== CLEANING DATA =====\n",
            "\n",
            "===== COMPUTING DIVERSIFICATION =====\n",
            "===== BUILDING ENHANCED DISTRICT SIMILARITY NETWORK =====\n",
            "Network reference window: 2008-2017\n",
            "District network: 311 nodes, 2996 edges\n",
            "Network density: 6.2% (target: 5-20%)\n",
            "\n",
            "===== BUILDING CROP-COOCCURRENCE NETWORK =====\n",
            "Crop network: 23 nodes, 253 edges\n",
            "\n",
            "Saved cleaned dataset with features to: /content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PROCESSING RICE\n",
            "======================================================================\n",
            "  Removing highly correlated features: ['DIVERSIFICATION_INDEX', 'DIST_STRENGTH', 'net_closeness_x', 'net_degree_y', 'net_strength_y', 'net_closeness_y', 'net_betweenness_y', 'net_strength']\n",
            "  Total features: 94, Network features: 8\n",
            "Saved supervised panel for RICE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_rice.csv\n",
            "\n",
            "RICE | Naive | no_network | Fold 1: MAE=283.12, RMSE=388.58, MAPE=28.65, MedAE=206.41, R2=0.741\n",
            "RICE | RollingMean3 | no_network | Fold 1: MAE=261.17, RMSE=354.54, MAPE=25.65, MedAE=200.58, R2=0.785\n",
            "RICE | Ridge | no_network | Fold 1: MAE=241.42, RMSE=942.27, MAPE=24.55, MedAE=56.13, R2=-0.522\n",
            "RICE | RandomForest | no_network | Fold 1: MAE=46.50, RMSE=110.35, MAPE=4.00, MedAE=15.81, R2=0.979\n",
            "RICE | GradientBoosting | no_network | Fold 1: MAE=64.63, RMSE=110.81, MAPE=5.80, MedAE=40.34, R2=0.979\n",
            "RICE | Ridge | with_network | Fold 1: MAE=203.29, RMSE=799.43, MAPE=20.01, MedAE=56.69, R2=-0.095\n",
            "RICE | RandomForest | with_network | Fold 1: MAE=46.93, RMSE=111.70, MAPE=4.03, MedAE=15.51, R2=0.979\n",
            "RICE | GradientBoosting | with_network | Fold 1: MAE=63.85, RMSE=107.23, MAPE=5.85, MedAE=40.69, R2=0.980\n",
            "RICE | Naive | no_network | Fold 2: MAE=281.83, RMSE=403.88, MAPE=22.80, MedAE=194.60, R2=0.779\n",
            "RICE | RollingMean3 | no_network | Fold 2: MAE=243.52, RMSE=345.71, MAPE=19.73, MedAE=170.77, R2=0.838\n",
            "RICE | Ridge | no_network | Fold 2: MAE=37.34, RMSE=51.16, MAPE=2.78, MedAE=29.40, R2=0.996\n",
            "RICE | RandomForest | no_network | Fold 2: MAE=27.74, RMSE=65.53, MAPE=2.04, MedAE=10.50, R2=0.994\n",
            "RICE | GradientBoosting | no_network | Fold 2: MAE=48.65, RMSE=71.56, MAPE=3.87, MedAE=33.97, R2=0.993\n",
            "RICE | Ridge | with_network | Fold 2: MAE=39.18, RMSE=53.36, MAPE=2.87, MedAE=31.05, R2=0.996\n",
            "RICE | RandomForest | with_network | Fold 2: MAE=28.03, RMSE=66.21, MAPE=2.07, MedAE=10.40, R2=0.994\n",
            "RICE | GradientBoosting | with_network | Fold 2: MAE=49.08, RMSE=72.61, MAPE=3.90, MedAE=34.30, R2=0.993\n",
            "RICE | Naive | no_network | Fold 3: MAE=296.28, RMSE=459.69, MAPE=19.00, MedAE=178.54, R2=0.759\n",
            "RICE | RollingMean3 | no_network | Fold 3: MAE=286.20, RMSE=419.19, MAPE=18.09, MedAE=191.22, R2=0.800\n",
            "RICE | Ridge | no_network | Fold 3: MAE=35.51, RMSE=51.37, MAPE=2.18, MedAE=24.51, R2=0.997\n",
            "RICE | RandomForest | no_network | Fold 3: MAE=32.66, RMSE=87.57, MAPE=1.97, MedAE=10.76, R2=0.991\n",
            "RICE | GradientBoosting | no_network | Fold 3: MAE=55.88, RMSE=84.13, MAPE=3.76, MedAE=37.99, R2=0.992\n",
            "RICE | Ridge | with_network | Fold 3: MAE=36.57, RMSE=52.95, MAPE=2.25, MedAE=25.53, R2=0.997\n",
            "RICE | RandomForest | with_network | Fold 3: MAE=32.74, RMSE=87.82, MAPE=1.95, MedAE=10.80, R2=0.991\n",
            "RICE | GradientBoosting | with_network | Fold 3: MAE=56.42, RMSE=85.09, MAPE=3.76, MedAE=38.57, R2=0.992\n",
            "\n",
            "======================================================================\n",
            "PROCESSING WHEAT\n",
            "======================================================================\n",
            "  Removing highly correlated features: ['DIVERSIFICATION_INDEX', 'DIST_STRENGTH', 'net_closeness_x', 'net_degree_y', 'net_strength_y', 'net_closeness_y', 'net_betweenness_y', 'net_strength']\n",
            "  Total features: 94, Network features: 8\n",
            "Saved supervised panel for WHEAT to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_wheat.csv\n",
            "\n",
            "WHEAT | Naive | no_network | Fold 1: MAE=256.38, RMSE=366.30, MAPE=20.11, MedAE=179.57, R2=0.752\n",
            "WHEAT | RollingMean3 | no_network | Fold 1: MAE=243.36, RMSE=335.36, MAPE=18.90, MedAE=179.21, R2=0.792\n",
            "WHEAT | Ridge | no_network | Fold 1: MAE=180.24, RMSE=539.93, MAPE=19.18, MedAE=45.55, R2=0.462\n",
            "WHEAT | RandomForest | no_network | Fold 1: MAE=56.42, RMSE=145.63, MAPE=3.70, MedAE=16.47, R2=0.961\n",
            "WHEAT | GradientBoosting | no_network | Fold 1: MAE=60.02, RMSE=124.86, MAPE=4.20, MedAE=32.55, R2=0.971\n",
            "WHEAT | Ridge | with_network | Fold 1: MAE=166.12, RMSE=486.70, MAPE=17.75, MedAE=47.10, R2=0.563\n",
            "WHEAT | RandomForest | with_network | Fold 1: MAE=55.76, RMSE=144.64, MAPE=3.61, MedAE=15.36, R2=0.961\n",
            "WHEAT | GradientBoosting | with_network | Fold 1: MAE=58.68, RMSE=119.18, MAPE=4.26, MedAE=33.49, R2=0.974\n",
            "WHEAT | Naive | no_network | Fold 2: MAE=266.28, RMSE=380.48, MAPE=17.55, MedAE=192.28, R2=0.825\n",
            "WHEAT | RollingMean3 | no_network | Fold 2: MAE=239.63, RMSE=333.89, MAPE=15.99, MedAE=173.52, R2=0.865\n",
            "WHEAT | Ridge | no_network | Fold 2: MAE=33.27, RMSE=45.42, MAPE=2.18, MedAE=26.41, R2=0.997\n",
            "WHEAT | RandomForest | no_network | Fold 2: MAE=39.36, RMSE=93.24, MAPE=2.00, MedAE=11.43, R2=0.989\n",
            "WHEAT | GradientBoosting | no_network | Fold 2: MAE=57.45, RMSE=97.45, MAPE=3.28, MedAE=33.06, R2=0.988\n",
            "WHEAT | Ridge | with_network | Fold 2: MAE=33.26, RMSE=45.54, MAPE=2.19, MedAE=26.00, R2=0.997\n",
            "WHEAT | RandomForest | with_network | Fold 2: MAE=40.14, RMSE=94.81, MAPE=2.03, MedAE=11.60, R2=0.989\n",
            "WHEAT | GradientBoosting | with_network | Fold 2: MAE=58.60, RMSE=99.78, MAPE=3.32, MedAE=33.84, R2=0.988\n",
            "WHEAT | Naive | no_network | Fold 3: MAE=338.37, RMSE=497.47, MAPE=18.76, MedAE=222.74, R2=0.776\n",
            "WHEAT | RollingMean3 | no_network | Fold 3: MAE=324.36, RMSE=463.30, MAPE=17.35, MedAE=222.22, R2=0.805\n",
            "WHEAT | Ridge | no_network | Fold 3: MAE=31.56, RMSE=45.01, MAPE=1.61, MedAE=23.35, R2=0.998\n",
            "WHEAT | RandomForest | no_network | Fold 3: MAE=66.76, RMSE=162.01, MAPE=2.69, MedAE=12.44, R2=0.976\n",
            "WHEAT | GradientBoosting | no_network | Fold 3: MAE=74.98, RMSE=123.06, MAPE=3.50, MedAE=42.85, R2=0.986\n",
            "WHEAT | Ridge | with_network | Fold 3: MAE=31.99, RMSE=45.67, MAPE=1.63, MedAE=23.19, R2=0.998\n",
            "WHEAT | RandomForest | with_network | Fold 3: MAE=67.49, RMSE=163.28, MAPE=2.71, MedAE=12.63, R2=0.976\n",
            "WHEAT | GradientBoosting | with_network | Fold 3: MAE=75.36, RMSE=124.90, MAPE=3.49, MedAE=42.04, R2=0.986\n",
            "\n",
            "======================================================================\n",
            "PROCESSING MAIZE\n",
            "======================================================================\n",
            "  Removing highly correlated features: ['DIVERSIFICATION_INDEX', 'DIST_STRENGTH', 'net_closeness_x', 'net_degree_y', 'net_strength_y', 'net_closeness_y', 'net_betweenness_y', 'net_strength']\n",
            "  Total features: 94, Network features: 8\n",
            "Saved supervised panel for MAIZE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_maize.csv\n",
            "\n",
            "MAIZE | Naive | no_network | Fold 1: MAE=399.22, RMSE=623.06, MAPE=36.64, MedAE=259.91, R2=0.312\n",
            "MAIZE | RollingMean3 | no_network | Fold 1: MAE=379.21, RMSE=571.01, MAPE=34.87, MedAE=260.04, R2=0.422\n",
            "MAIZE | Ridge | no_network | Fold 1: MAE=619.96, RMSE=2478.53, MAPE=45.56, MedAE=74.61, R2=-9.887\n",
            "MAIZE | RandomForest | no_network | Fold 1: MAE=56.37, RMSE=149.06, MAPE=4.26, MedAE=17.53, R2=0.961\n",
            "MAIZE | GradientBoosting | no_network | Fold 1: MAE=72.05, RMSE=127.82, MAPE=6.50, MedAE=44.10, R2=0.971\n",
            "MAIZE | Ridge | with_network | Fold 1: MAE=615.06, RMSE=2493.91, MAPE=45.07, MedAE=79.19, R2=-10.022\n",
            "MAIZE | RandomForest | with_network | Fold 1: MAE=56.77, RMSE=149.75, MAPE=4.28, MedAE=18.15, R2=0.960\n",
            "MAIZE | GradientBoosting | with_network | Fold 1: MAE=71.80, RMSE=127.10, MAPE=6.43, MedAE=43.91, R2=0.971\n",
            "MAIZE | Naive | no_network | Fold 2: MAE=410.81, RMSE=613.36, MAPE=28.27, MedAE=281.45, R2=0.477\n",
            "MAIZE | RollingMean3 | no_network | Fold 2: MAE=366.05, RMSE=544.43, MAPE=24.63, MedAE=251.96, R2=0.588\n",
            "MAIZE | Ridge | no_network | Fold 2: MAE=34.29, RMSE=50.15, MAPE=2.30, MedAE=24.96, R2=0.997\n",
            "MAIZE | RandomForest | no_network | Fold 2: MAE=36.17, RMSE=127.99, MAPE=1.76, MedAE=10.14, R2=0.977\n",
            "MAIZE | GradientBoosting | no_network | Fold 2: MAE=54.52, RMSE=98.85, MAPE=3.52, MedAE=34.14, R2=0.986\n",
            "MAIZE | Ridge | with_network | Fold 2: MAE=35.21, RMSE=51.35, MAPE=2.35, MedAE=25.72, R2=0.996\n",
            "MAIZE | RandomForest | with_network | Fold 2: MAE=36.56, RMSE=128.27, MAPE=1.78, MedAE=10.37, R2=0.977\n",
            "MAIZE | GradientBoosting | with_network | Fold 2: MAE=54.46, RMSE=99.36, MAPE=3.53, MedAE=33.74, R2=0.986\n",
            "MAIZE | Naive | no_network | Fold 3: MAE=513.72, RMSE=817.16, MAPE=27.94, MedAE=300.00, R2=0.634\n",
            "MAIZE | RollingMean3 | no_network | Fold 3: MAE=488.77, RMSE=759.50, MAPE=25.87, MedAE=304.04, R2=0.684\n",
            "MAIZE | Ridge | no_network | Fold 3: MAE=33.22, RMSE=49.10, MAPE=1.69, MedAE=22.76, R2=0.999\n",
            "MAIZE | RandomForest | no_network | Fold 3: MAE=83.31, RMSE=215.35, MAPE=2.78, MedAE=12.32, R2=0.975\n",
            "MAIZE | GradientBoosting | no_network | Fold 3: MAE=78.16, RMSE=131.61, MAPE=3.83, MedAE=43.71, R2=0.990\n",
            "MAIZE | Ridge | with_network | Fold 3: MAE=34.46, RMSE=50.68, MAPE=1.76, MedAE=23.34, R2=0.999\n",
            "MAIZE | RandomForest | with_network | Fold 3: MAE=83.54, RMSE=215.67, MAPE=2.81, MedAE=12.10, R2=0.974\n",
            "MAIZE | GradientBoosting | with_network | Fold 3: MAE=77.33, RMSE=129.02, MAPE=3.81, MedAE=44.19, R2=0.991\n",
            "\n",
            "======================================================================\n",
            "PROCESSING GROUNDNUT\n",
            "======================================================================\n",
            "  Removing highly correlated features: ['DIVERSIFICATION_INDEX', 'DIST_STRENGTH', 'net_closeness_x', 'net_degree_y', 'net_strength_y', 'net_closeness_y', 'net_betweenness_y', 'net_strength']\n",
            "  Total features: 94, Network features: 8\n",
            "Saved supervised panel for GROUNDNUT to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_groundnut.csv\n",
            "\n",
            "GROUNDNUT | Naive | no_network | Fold 1: MAE=271.23, RMSE=391.11, MAPE=35.40, MedAE=193.55, R2=-0.154\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 1: MAE=263.89, RMSE=363.36, MAPE=33.86, MedAE=193.34, R2=0.004\n",
            "GROUNDNUT | Ridge | no_network | Fold 1: MAE=377.49, RMSE=1150.20, MAPE=53.55, MedAE=97.12, R2=-8.982\n",
            "GROUNDNUT | RandomForest | no_network | Fold 1: MAE=69.74, RMSE=126.63, MAPE=8.84, MedAE=27.41, R2=0.879\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 1: MAE=58.83, RMSE=87.89, MAPE=7.91, MedAE=40.79, R2=0.942\n",
            "GROUNDNUT | Ridge | with_network | Fold 1: MAE=371.73, RMSE=1202.20, MAPE=52.94, MedAE=94.70, R2=-9.905\n",
            "GROUNDNUT | RandomForest | with_network | Fold 1: MAE=70.34, RMSE=127.88, MAPE=8.91, MedAE=27.71, R2=0.877\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 1: MAE=58.66, RMSE=87.38, MAPE=7.85, MedAE=40.32, R2=0.942\n",
            "GROUNDNUT | Naive | no_network | Fold 2: MAE=284.88, RMSE=412.05, MAPE=31.37, MedAE=193.95, R2=-0.049\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 2: MAE=253.01, RMSE=352.31, MAPE=27.43, MedAE=186.02, R2=0.233\n",
            "GROUNDNUT | Ridge | no_network | Fold 2: MAE=43.11, RMSE=56.15, MAPE=4.65, MedAE=34.20, R2=0.981\n",
            "GROUNDNUT | RandomForest | no_network | Fold 2: MAE=24.89, RMSE=63.77, MAPE=2.59, MedAE=7.91, R2=0.975\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 2: MAE=35.09, RMSE=56.93, MAPE=4.14, MedAE=23.21, R2=0.980\n",
            "GROUNDNUT | Ridge | with_network | Fold 2: MAE=43.52, RMSE=56.69, MAPE=4.68, MedAE=34.45, R2=0.980\n",
            "GROUNDNUT | RandomForest | with_network | Fold 2: MAE=24.99, RMSE=63.73, MAPE=2.61, MedAE=8.00, R2=0.975\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 2: MAE=35.63, RMSE=56.96, MAPE=4.23, MedAE=23.61, R2=0.980\n",
            "GROUNDNUT | Naive | no_network | Fold 3: MAE=279.97, RMSE=428.14, MAPE=26.07, MedAE=175.49, R2=0.407\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 3: MAE=257.37, RMSE=368.97, MAPE=23.47, MedAE=183.24, R2=0.560\n",
            "GROUNDNUT | Ridge | no_network | Fold 3: MAE=38.70, RMSE=50.60, MAPE=3.28, MedAE=30.70, R2=0.992\n",
            "GROUNDNUT | RandomForest | no_network | Fold 3: MAE=31.61, RMSE=71.98, MAPE=2.32, MedAE=7.83, R2=0.983\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 3: MAE=41.87, RMSE=63.65, MAPE=3.65, MedAE=26.93, R2=0.987\n",
            "GROUNDNUT | Ridge | with_network | Fold 3: MAE=39.14, RMSE=51.25, MAPE=3.30, MedAE=30.43, R2=0.992\n",
            "GROUNDNUT | RandomForest | with_network | Fold 3: MAE=31.93, RMSE=72.73, MAPE=2.34, MedAE=7.74, R2=0.983\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 3: MAE=42.19, RMSE=65.16, MAPE=3.60, MedAE=26.80, R2=0.986\n",
            "\n",
            "======================================================================\n",
            "PROCESSING COTTON\n",
            "======================================================================\n",
            "  Removing highly correlated features: ['DIVERSIFICATION_INDEX', 'DIST_STRENGTH', 'net_closeness_x', 'net_degree_y', 'net_strength_y', 'net_closeness_y', 'net_betweenness_y', 'net_strength']\n",
            "  Total features: 94, Network features: 8\n",
            "Saved supervised panel for COTTON to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_cotton.csv\n",
            "\n",
            "COTTON | Naive | no_network | Fold 1: MAE=71.09, RMSE=121.11, MAPE=31.84, MedAE=38.65, R2=0.199\n",
            "COTTON | RollingMean3 | no_network | Fold 1: MAE=68.11, RMSE=112.32, MAPE=29.56, MedAE=36.19, R2=0.311\n",
            "COTTON | Ridge | no_network | Fold 1: MAE=100.57, RMSE=335.25, MAPE=40.92, MedAE=20.63, R2=-5.141\n",
            "COTTON | RandomForest | no_network | Fold 1: MAE=18.63, RMSE=31.64, MAPE=7.11, MedAE=7.12, R2=0.945\n",
            "COTTON | GradientBoosting | no_network | Fold 1: MAE=37.53, RMSE=55.89, MAPE=17.73, MedAE=17.20, R2=0.829\n",
            "COTTON | Ridge | with_network | Fold 1: MAE=108.29, RMSE=360.25, MAPE=44.40, MedAE=20.97, R2=-6.092\n",
            "COTTON | RandomForest | with_network | Fold 1: MAE=18.83, RMSE=32.05, MAPE=7.17, MedAE=7.21, R2=0.944\n",
            "COTTON | GradientBoosting | with_network | Fold 1: MAE=36.12, RMSE=54.24, MAPE=17.05, MedAE=16.42, R2=0.839\n",
            "COTTON | Naive | no_network | Fold 2: MAE=79.60, RMSE=122.92, MAPE=31.10, MedAE=50.47, R2=0.064\n",
            "COTTON | RollingMean3 | no_network | Fold 2: MAE=76.83, RMSE=115.91, MAPE=29.53, MedAE=49.19, R2=0.168\n",
            "COTTON | Ridge | no_network | Fold 2: MAE=9.24, RMSE=11.87, MAPE=3.88, MedAE=7.75, R2=0.991\n",
            "COTTON | RandomForest | no_network | Fold 2: MAE=7.39, RMSE=15.89, MAPE=2.63, MedAE=2.93, R2=0.984\n",
            "COTTON | GradientBoosting | no_network | Fold 2: MAE=10.75, RMSE=15.80, MAPE=4.11, MedAE=7.50, R2=0.985\n",
            "COTTON | Ridge | with_network | Fold 2: MAE=9.12, RMSE=11.80, MAPE=3.85, MedAE=7.52, R2=0.991\n",
            "COTTON | RandomForest | with_network | Fold 2: MAE=7.59, RMSE=16.35, MAPE=2.70, MedAE=3.08, R2=0.983\n",
            "COTTON | GradientBoosting | with_network | Fold 2: MAE=11.44, RMSE=17.23, MAPE=4.41, MedAE=7.60, R2=0.982\n",
            "COTTON | Naive | no_network | Fold 3: MAE=120.20, RMSE=181.89, MAPE=35.92, MedAE=72.80, R2=0.094\n",
            "COTTON | RollingMean3 | no_network | Fold 3: MAE=116.18, RMSE=165.17, MAPE=34.07, MedAE=77.97, R2=0.253\n",
            "COTTON | Ridge | no_network | Fold 3: MAE=8.52, RMSE=11.18, MAPE=2.41, MedAE=6.58, R2=0.997\n",
            "COTTON | RandomForest | no_network | Fold 3: MAE=14.31, RMSE=25.41, MAPE=3.34, MedAE=5.11, R2=0.982\n",
            "COTTON | GradientBoosting | no_network | Fold 3: MAE=15.99, RMSE=24.26, MAPE=4.31, MedAE=9.61, R2=0.984\n",
            "COTTON | Ridge | with_network | Fold 3: MAE=8.84, RMSE=11.56, MAPE=2.50, MedAE=6.83, R2=0.996\n",
            "COTTON | RandomForest | with_network | Fold 3: MAE=14.52, RMSE=25.88, MAPE=3.39, MedAE=5.36, R2=0.982\n",
            "COTTON | GradientBoosting | with_network | Fold 3: MAE=15.87, RMSE=24.08, MAPE=4.30, MedAE=9.82, R2=0.984\n",
            "\n",
            "======================================================================\n",
            "PROCESSING SUGARCANE\n",
            "======================================================================\n",
            "  Removing highly correlated features: ['DIVERSIFICATION_INDEX', 'DIST_STRENGTH', 'net_closeness_x', 'net_degree_y', 'net_strength_y', 'net_closeness_y', 'net_betweenness_y', 'net_strength']\n",
            "  Total features: 94, Network features: 8\n",
            "Saved supervised panel for SUGARCANE to: /content/drive/MyDrive/Shiny/ICRISAT/Results/supervised_panel_sugarcane.csv\n",
            "\n",
            "SUGARCANE | Naive | no_network | Fold 1: MAE=879.27, RMSE=1412.06, MAPE=19.91, MedAE=541.67, R2=0.713\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 1: MAE=862.56, RMSE=1329.42, MAPE=19.42, MedAE=558.70, R2=0.746\n",
            "SUGARCANE | Ridge | no_network | Fold 1: MAE=1435.41, RMSE=4271.62, MAPE=43.68, MedAE=433.02, R2=-1.623\n",
            "SUGARCANE | RandomForest | no_network | Fold 1: MAE=149.73, RMSE=337.29, MAPE=4.71, MedAE=60.22, R2=0.984\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 1: MAE=245.00, RMSE=355.40, MAPE=6.99, MedAE=176.44, R2=0.982\n",
            "SUGARCANE | Ridge | with_network | Fold 1: MAE=1423.83, RMSE=4126.91, MAPE=40.41, MedAE=417.75, R2=-1.448\n",
            "SUGARCANE | RandomForest | with_network | Fold 1: MAE=150.86, RMSE=339.63, MAPE=4.72, MedAE=61.04, R2=0.983\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 1: MAE=253.60, RMSE=365.56, MAPE=7.38, MedAE=189.06, R2=0.981\n",
            "SUGARCANE | Naive | no_network | Fold 2: MAE=909.99, RMSE=1545.62, MAPE=21.84, MedAE=500.57, R2=0.635\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 2: MAE=879.00, RMSE=1396.06, MAPE=22.86, MedAE=520.06, R2=0.702\n",
            "SUGARCANE | Ridge | no_network | Fold 2: MAE=270.41, RMSE=363.76, MAPE=9.59, MedAE=204.24, R2=0.980\n",
            "SUGARCANE | RandomForest | no_network | Fold 2: MAE=124.20, RMSE=315.59, MAPE=10.61, MedAE=38.88, R2=0.985\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 2: MAE=226.31, RMSE=352.87, MAPE=11.76, MedAE=140.52, R2=0.981\n",
            "SUGARCANE | Ridge | with_network | Fold 2: MAE=274.07, RMSE=370.62, MAPE=9.40, MedAE=204.42, R2=0.979\n",
            "SUGARCANE | RandomForest | with_network | Fold 2: MAE=124.93, RMSE=313.07, MAPE=10.27, MedAE=39.01, R2=0.985\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 2: MAE=220.96, RMSE=344.41, MAPE=11.48, MedAE=141.42, R2=0.982\n",
            "SUGARCANE | Naive | no_network | Fold 3: MAE=1165.32, RMSE=2012.30, MAPE=25.81, MedAE=559.26, R2=0.423\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 3: MAE=1159.33, RMSE=1824.22, MAPE=26.81, MedAE=661.36, R2=0.526\n",
            "SUGARCANE | Ridge | no_network | Fold 3: MAE=233.56, RMSE=318.30, MAPE=9.30, MedAE=175.22, R2=0.986\n",
            "SUGARCANE | RandomForest | no_network | Fold 3: MAE=113.02, RMSE=268.60, MAPE=8.86, MedAE=35.77, R2=0.990\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 3: MAE=243.36, RMSE=389.73, MAPE=16.08, MedAE=151.81, R2=0.978\n",
            "SUGARCANE | Ridge | with_network | Fold 3: MAE=234.41, RMSE=325.88, MAPE=8.83, MedAE=172.18, R2=0.985\n",
            "SUGARCANE | RandomForest | with_network | Fold 3: MAE=114.50, RMSE=270.05, MAPE=8.88, MedAE=37.14, R2=0.990\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 3: MAE=252.84, RMSE=380.69, MAPE=16.50, MedAE=166.76, R2=0.979\n",
            "\n",
            "Saved per-fold model results to: /content/drive/MyDrive/Shiny/ICRISAT/Results/model_per_fold_raw.csv\n",
            "Saved model performance summary to: /content/drive/MyDrive/Shiny/ICRISAT/Results/model_performance_summary.csv\n",
            "\n",
            "\n",
            "===== STATISTICAL SIGNIFICANCE TESTS =====\n",
            "RICE: GB with_network vs no_network: Improvement=-0.11%, p=0.8980\n",
            "RICE: GB with_network vs Naive: Improvement=80.34%, p=0.0007\n",
            "WHEAT: GB with_network vs no_network: Improvement=-0.10%, p=0.9409\n",
            "WHEAT: GB with_network vs Naive: Improvement=77.63%, p=0.0082\n",
            "MAIZE: GB with_network vs no_network: Improvement=0.55%, p=0.2465\n",
            "MAIZE: GB with_network vs Naive: Improvement=84.62%, p=0.0075\n",
            "GROUNDNUT: GB with_network vs no_network: Improvement=-0.51%, p=0.3914\n",
            "GROUNDNUT: GB with_network vs Naive: Improvement=83.68%, p=0.0022\n",
            "COTTON: GB with_network vs no_network: Improvement=1.31%, p=0.6914\n",
            "COTTON: GB with_network vs Naive: Improvement=76.58%, p=0.0746\n",
            "SUGARCANE: GB with_network vs no_network: Improvement=-1.78%, p=0.4697\n",
            "SUGARCANE: GB with_network vs Naive: Improvement=75.38%, p=0.0135\n",
            "\n",
            "Saved statistical tests to: /content/drive/MyDrive/Shiny/ICRISAT/Results/statistical_significance_tests.csv\n",
            "\n",
            "\n",
            "===== TEMPORAL STABILITY ANALYSIS =====\n",
            "RICE: MAE slope=-3.71 (trend R=0.253), R slope=0.0057\n",
            "WHEAT: MAE slope=8.34 (trend R=0.747), R slope=0.0060\n",
            "MAIZE: MAE slope=2.76 (trend R=0.054), R slope=0.0097\n",
            "GROUNDNUT: MAE slope=-8.23 (trend R=0.482), R slope=0.0219\n",
            "COTTON: MAE slope=-10.13 (trend R=0.592), R slope=0.0724\n",
            "SUGARCANE: MAE slope=-0.38 (trend R=0.000), R slope=-0.0007\n",
            "\n",
            "Saved temporal stability analysis to: /content/drive/MyDrive/Shiny/ICRISAT/Results/temporal_stability_analysis.csv\n",
            "\n",
            "\n",
            "===== FEATURE IMPORTANCE ANALYSIS =====\n",
            "RICE: Network features contribute 0.1% of total importance\n",
            "WHEAT: Network features contribute 0.2% of total importance\n",
            "MAIZE: Network features contribute 0.0% of total importance\n",
            "GROUNDNUT: Network features contribute 0.0% of total importance\n",
            "COTTON: Network features contribute 0.3% of total importance\n",
            "SUGARCANE: Network features contribute 1.0% of total importance\n",
            "\n",
            "Saved feature importance to: /content/drive/MyDrive/Shiny/ICRISAT/Results/feature_importance_summary.csv\n",
            "\n",
            "\n",
            "Performance summary for RICE (no_network):\n",
            "Crop            Model FeatureSet   MAE_mean    MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "RICE     RandomForest no_network  35.629888   9.726721  87.815116  22.409883   2.671781  1.154628   12.358933   2.995752 0.988193 0.007982\n",
            "RICE GradientBoosting no_network  56.385280   7.999705  88.835966  20.042751   4.476352  1.148459   37.434683   3.225206 0.987985 0.007840\n",
            "RICE            Ridge no_network 104.753847 118.360004 348.265058 514.420948   9.835940 12.746134   36.681908  17.021738 0.490644 0.876558\n",
            "RICE     RollingMean3 no_network 263.631121  21.442914 373.147503  40.120840  21.159357  3.974767  187.521111  15.245244 0.807500 0.027730\n",
            "RICE            Naive no_network 287.078892   7.994603 417.382161  37.426210  23.481304  4.864475  193.183333  13.988904 0.759858 0.019067\n",
            "\n",
            "Performance summary for RICE (with_network):\n",
            "Crop            Model   FeatureSet  MAE_mean   MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "RICE     RandomForest with_network 35.897582  9.838486  88.579121  22.757787   2.683792  1.168339   12.236333   2.840931 0.987963 0.008220\n",
            "RICE GradientBoosting with_network 56.446548  7.385317  88.310769  17.534570   4.506421  1.167129   37.850529   3.255454 0.988302 0.006957\n",
            "RICE            Ridge with_network 93.012974 95.513517 301.913821 430.858534   8.376001 10.083074   37.756708  16.631735 0.632590 0.630268\n",
            "\n",
            "Performance summary for WHEAT (no_network):\n",
            " Crop            Model FeatureSet   MAE_mean   MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "WHEAT     RandomForest no_network  54.181876 13.834872 133.626382  35.919709   2.794973  0.854254   13.445917   2.662766 0.975514 0.014312\n",
            "WHEAT GradientBoosting no_network  64.151416  9.469706 115.125362  15.333025   3.658671  0.480187   36.153291   5.807020 0.981998 0.009392\n",
            "WHEAT            Ridge no_network  81.691099 85.353029 210.119083 285.622812   7.656614  9.984743   31.768363  12.033094 0.819228 0.309352\n",
            "WHEAT     RollingMean3 no_network 269.115101 47.879433 377.518940  74.293889  17.413323  1.456325  191.650000  26.629871 0.820936 0.038598\n",
            "WHEAT            Naive no_network 287.008345 44.754485 414.750688  71.985446  18.805290  1.282658  198.195000  22.185514 0.784219 0.036802\n",
            "\n",
            "Performance summary for WHEAT (with_network):\n",
            " Crop            Model   FeatureSet  MAE_mean   MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "WHEAT     RandomForest with_network 54.462622 13.719501 134.242005  35.400007   2.783568  0.792726   13.197617   1.940194 0.975446 0.013861\n",
            "WHEAT GradientBoosting with_network 64.213349  9.653155 114.619241  13.164358   3.693444  0.501306   36.459195   4.838655 0.982528 0.007638\n",
            "WHEAT            Ridge with_network 77.122632 77.078497 192.636139 254.662569   7.191722  9.148243   32.097155  13.072159 0.852822 0.251105\n",
            "\n",
            "Performance summary for MAIZE (no_network):\n",
            " Crop            Model FeatureSet   MAE_mean    MAE_std  RMSE_mean    RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "MAIZE     RandomForest no_network  58.616697  23.646656 164.135783   45.587459   2.933532  1.255536   13.330094   3.794286  0.970806 0.008921\n",
            "MAIZE GradientBoosting no_network  68.241932  12.269558 119.427419   17.925055   4.614842  1.637660   40.648718   5.644391  0.982655 0.010260\n",
            "MAIZE            Ridge no_network 229.156114 338.442276 859.263681 1402.329865  16.518379 25.154865   40.777385  29.319593 -2.630535 6.284100\n",
            "MAIZE     RollingMean3 no_network 411.342864  67.375418 624.980603  117.254522  28.454283  5.586503  272.011111  28.027403  0.564621 0.132262\n",
            "MAIZE            Naive no_network 441.248900  63.026417 684.525442  114.964330  30.949377  4.930170  280.456667  20.061139  0.474319 0.160844\n",
            "\n",
            "Performance summary for MAIZE (with_network):\n",
            " Crop            Model   FeatureSet   MAE_mean    MAE_std  RMSE_mean    RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "MAIZE     RandomForest with_network  58.955515  23.564138 164.563127   45.543188   2.958701  1.253636   13.539906   4.080959  0.970626 0.009078\n",
            "MAIZE GradientBoosting with_network  67.865949  11.930078 118.491766   16.595868   4.588016  1.598626   40.614168   5.951274  0.982841 0.010194\n",
            "MAIZE            Ridge with_network 228.241420 334.995044 865.312866 1410.408992  16.393956 24.839620   42.752682  31.581546 -2.675792 6.362265\n",
            "\n",
            "Performance summary for GROUNDNUT (no_network):\n",
            "     Crop            Model FeatureSet   MAE_mean    MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "GROUNDNUT     RandomForest no_network  42.079783  24.188426  87.462466  34.168962   4.584873  3.689872   14.383767  11.284133  0.945711 0.057918\n",
            "GROUNDNUT GradientBoosting no_network  45.263164  12.229012  69.487157  16.285302   5.233870  2.327004   30.309706   9.267962  0.969535 0.024336\n",
            "GROUNDNUT            Ridge no_network 153.102823 194.340464 418.983546 633.254389  20.495950 28.637102   54.007206  37.376967 -2.336585 5.755102\n",
            "GROUNDNUT     RollingMean3 no_network 258.092815   5.476935 361.549183   8.479045  28.252389  5.241044  187.533889   5.217050  0.265647 0.279369\n",
            "GROUNDNUT            Naive no_network 278.694932   6.916585 410.431888  18.567299  30.946737  4.681829  187.663333  10.544313  0.068161 0.298333\n",
            "\n",
            "Performance summary for GROUNDNUT (with_network):\n",
            "     Crop            Model   FeatureSet   MAE_mean    MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "GROUNDNUT     RandomForest with_network  42.419222  24.424315  88.111955  34.731538   4.619365  3.713947   14.483333  11.456921  0.944808 0.059193\n",
            "GROUNDNUT GradientBoosting with_network  45.492904  11.862321  69.831368  15.738973   5.226245  2.291167   30.242337   8.870603  0.969542 0.023722\n",
            "GROUNDNUT            Ridge with_network 151.463672 190.766585 436.716253 662.935661  20.307335 28.267963   53.191933  36.003569 -2.644477 6.287873\n",
            "\n",
            "Performance summary for COTTON (no_network):\n",
            "  Crop            Model FeatureSet  MAE_mean   MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "COTTON     RandomForest no_network 13.443697  5.669227  24.316006   7.931495   4.358927  2.408706    5.056559   2.095259  0.970652 0.021994\n",
            "COTTON GradientBoosting no_network 21.424456 14.194408  31.980927  21.132797   8.713036  7.806529   11.438492   5.099530  0.932584 0.089429\n",
            "COTTON            Ridge no_network 39.443327 52.935293 119.433440 186.902202  15.740357 21.821376   11.653565   7.795218 -1.051182 3.542232\n",
            "COTTON     RollingMean3 no_network 87.042258 25.609208 131.133188  29.531046  31.053157  2.612698   54.452222  21.383443  0.243818 0.071782\n",
            "COTTON            Naive no_network 90.299430 26.244987 141.972908  34.581519  32.953954  2.595243   53.973333  17.345671  0.118915 0.070537\n",
            "\n",
            "Performance summary for COTTON (with_network):\n",
            "  Crop            Model   FeatureSet  MAE_mean   MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "COTTON     RandomForest with_network 13.647021  5.671167  24.758837   7.910665   4.422621  2.403727    5.216533   2.071191  0.969659 0.022353\n",
            "COTTON GradientBoosting with_network 21.143648 13.159703  31.848340  19.689209   8.588586  7.331169   11.277519   4.587668  0.934999 0.082922\n",
            "COTTON            Ridge with_network 42.083450 57.334792 127.870233 201.248715  16.919067 23.812980   11.773282   7.968606 -1.367965 4.090802\n",
            "\n",
            "Performance summary for SUGARCANE (no_network):\n",
            "     Crop            Model FeatureSet   MAE_mean    MAE_std   RMSE_mean    RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "SUGARCANE     RandomForest no_network 128.984258  18.819817  307.157553   35.111405   8.059352  3.027405   44.956861  13.309369 0.986048 0.003237\n",
            "SUGARCANE GradientBoosting no_network 238.222199  10.352209  365.998502   20.593281  11.609868  4.549648  156.257034  18.370648 0.980392 0.001802\n",
            "SUGARCANE            Ridge no_network 646.460102 683.497484 1651.228057 2269.442538  20.855002 19.763223  270.829194 141.209758 0.114156 1.504311\n",
            "SUGARCANE     RollingMean3 no_network 966.964358 166.797985 1516.566183  268.510097  23.029916  3.694056  580.038889  73.026207 0.658031 0.116251\n",
            "SUGARCANE            Naive no_network 984.857837 157.033767 1656.657328  315.149133  22.517180  3.008027  533.833333  30.119579 0.590504 0.149898\n",
            "\n",
            "Performance summary for SUGARCANE (with_network):\n",
            "     Crop            Model   FeatureSet   MAE_mean    MAE_std   RMSE_mean    RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "SUGARCANE     RandomForest with_network 130.098361  18.720803  307.583906   35.115765   7.957069  2.886327   45.727861  13.289546 0.986015 0.003219\n",
            "SUGARCANE GradientBoosting with_network 242.469934  18.629654  363.555447   18.219457  11.788847  4.569266  165.745993  23.835180 0.980672 0.001249\n",
            "SUGARCANE            Ridge with_network 644.103231 675.552763 1607.803882 2181.722005  19.547969 18.072279  264.782117 133.447925 0.171903 1.403021\n",
            "\n",
            "======================================================================\n",
            "FINAL SUMMARY (BEST ADVANCED MODELS)\n",
            "======================================================================\n",
            "  COTTON: RandomForest (with_network) | MAE=13.65 (5.67), R=0.970 (0.022)\n",
            "  GROUNDNUT: RandomForest (with_network) | MAE=42.42 (24.42), R=0.945 (0.059)\n",
            "  MAIZE: RandomForest (with_network) | MAE=58.96 (23.56), R=0.971 (0.009)\n",
            "  RICE: RandomForest (with_network) | MAE=35.90 (9.84), R=0.988 (0.008)\n",
            "  SUGARCANE: RandomForest (with_network) | MAE=130.10 (18.72), R=0.986 (0.003)\n",
            "  WHEAT: RandomForest (with_network) | MAE=54.46 (13.72), R=0.975 (0.014)\n",
            "\n",
            "======================================================================\n",
            "GENERATING ENHANCED DIAGNOSTIC PLOTS\n",
            "======================================================================\n",
            "Saved enhanced diagnostic plots for COTTON (RandomForest, with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved enhanced diagnostic plots for GROUNDNUT (RandomForest, with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved enhanced diagnostic plots for MAIZE (RandomForest, with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved enhanced diagnostic plots for RICE (RandomForest, with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved enhanced diagnostic plots for SUGARCANE (RandomForest, with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "Saved enhanced diagnostic plots for WHEAT (RandomForest, with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results.\n",
            "\n",
            "======================================================================\n",
            "PIPELINE COMPLETE\n",
            "======================================================================\n",
            "Rows after cleaning: 16146\n",
            "Years: 1966 - 2017\n",
            "Districts: 311\n",
            "Crops modeled: ['RICE', 'WHEAT', 'MAIZE', 'GROUNDNUT', 'COTTON', 'SUGARCANE']\n",
            "\n",
            "Key outputs:\n",
            "  - Cleaned dataset: /content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\n",
            "  - Performance summary: /content/drive/MyDrive/Shiny/ICRISAT/Results/model_performance_summary.csv\n",
            "  - Statistical tests: /content/drive/MyDrive/Shiny/ICRISAT/Results/statistical_significance_tests.csv\n",
            "  - Temporal stability: /content/drive/MyDrive/Shiny/ICRISAT/Results/temporal_stability_analysis.csv\n",
            "  - Feature importance: /content/drive/MyDrive/Shiny/ICRISAT/Results/feature_importance_summary.csv\n",
            "  - Best models: /content/drive/MyDrive/Shiny/ICRISAT/Results/best_models_advanced_only.csv\n",
            "  - Diagnostic plots: /content/drive/MyDrive/Shiny/ICRISAT/Results/*.pdf\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import warnings\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "\n",
        "from scipy import stats\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# CONFIG\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "RAW_CSV_PATH = \"/content/drive/MyDrive/Shiny/ICRISAT/Data/icrisat_raw.csv\"\n",
        "CLEANED_CSV_PATH = \"/content/drive/MyDrive/Shiny/ICRISAT/Results/icrisat_cleaned_with_features.csv\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Shiny/ICRISAT/Results\"\n",
        "\n",
        "SUPERVISED_PANEL_PREFIX = os.path.join(OUTPUT_DIR, \"supervised_panel_\")\n",
        "MODEL_PER_FOLD_CSV = os.path.join(OUTPUT_DIR, \"model_per_fold_raw.csv\")\n",
        "MODEL_PERF_SUMMARY_CSV = os.path.join(OUTPUT_DIR, \"model_performance_summary.csv\")\n",
        "BEST_MODELS_CSV = os.path.join(OUTPUT_DIR, \"best_models_advanced_only.csv\")\n",
        "FEATURE_IMPORTANCE_CSV = os.path.join(OUTPUT_DIR, \"feature_importance_summary.csv\")\n",
        "STATISTICAL_TESTS_CSV = os.path.join(OUTPUT_DIR, \"statistical_significance_tests.csv\")\n",
        "TEMPORAL_STABILITY_CSV = os.path.join(OUTPUT_DIR, \"temporal_stability_analysis.csv\")\n",
        "\n",
        "CROPS = [\"RICE\", \"WHEAT\", \"MAIZE\", \"GROUNDNUT\", \"COTTON\", \"SUGARCANE\"]\n",
        "RANDOM_STATE = 42\n",
        "N_FOLDS = 3\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# UTILS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def safe_mape(y_true: np.ndarray, y_pred: np.ndarray, min_threshold: float = 100.0) -> float:\n",
        "    \"\"\"\n",
        "    Mean Absolute Percentage Error in %, with minimum threshold to avoid\n",
        "    division by near-zero values (especially important for cotton).\n",
        "    \"\"\"\n",
        "    y_true = np.array(y_true, dtype=float)\n",
        "    y_pred = np.array(y_pred, dtype=float)\n",
        "    mask = y_true > min_threshold\n",
        "    if not np.any(mask):\n",
        "        return np.nan\n",
        "    return np.mean(np.abs(y_true[mask] - y_pred[mask]) / y_true[mask]) * 100.0\n",
        "\n",
        "\n",
        "def median_ae(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    return float(np.median(np.abs(np.array(y_true) - np.array(y_pred))))\n",
        "\n",
        "\n",
        "def safe_print(*args, **kwargs):\n",
        "    try:\n",
        "        print(*args, **kwargs)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# LOADING + BASIC EDA\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def load_data() -> Tuple[pd.DataFrame, str]:\n",
        "    if os.path.exists(RAW_CSV_PATH):\n",
        "        safe_print(f\"RAW_CSV_PATH found: {RAW_CSV_PATH}\")\n",
        "        df = pd.read_csv(RAW_CSV_PATH)\n",
        "        source_type = \"raw\"\n",
        "    elif os.path.exists(CLEANED_CSV_PATH):\n",
        "        safe_print(\"RAW_CSV_PATH not found.\")\n",
        "        safe_print(f\"Falling back to existing CLEANED dataset: {CLEANED_CSV_PATH}\\n\")\n",
        "        df = pd.read_csv(CLEANED_CSV_PATH)\n",
        "        source_type = \"cleaned\"\n",
        "    else:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Neither raw ({RAW_CSV_PATH}) nor cleaned ({CLEANED_CSV_PATH}) dataset is available.\"\n",
        "        )\n",
        "    return df, source_type\n",
        "\n",
        "\n",
        "def basic_eda(df: pd.DataFrame) -> None:\n",
        "    safe_print(\"===== BASIC EDA =====\")\n",
        "    key_cols = [\"Dist Code\", \"Year\"]\n",
        "    if all(k in df.columns for k in key_cols):\n",
        "        dup = df.duplicated(subset=key_cols).sum()\n",
        "        safe_print(f\"Duplicate (Dist Code, Year) rows: {dup}\")\n",
        "        safe_print(f\"Key (Dist Code, Year) is {'NOT ' if dup>0 else ''}unique.\\n\")\n",
        "\n",
        "    safe_print(f\"Rows: {len(df):d}, Columns: {df.shape[1]:d}\")\n",
        "\n",
        "    if \"Year\" in df.columns:\n",
        "        safe_print(f\"Time range: {int(df['Year'].min())} - {int(df['Year'].max())}\")\n",
        "\n",
        "    state_cols = [c for c in df.columns if \"STATE\" in c.upper() or \"STATE NAME\" in c.upper()]\n",
        "    if state_cols:\n",
        "        safe_print(f\"Unique States: {df[state_cols[0]].nunique()}\")\n",
        "\n",
        "    yield_cols = [c for c in df.columns if \"YIELD (Kg per ha)\" in c]\n",
        "    crops = sorted(list({c.split(\" YIELD\")[0].strip() for c in yield_cols}))\n",
        "    safe_print(f\"Detected crops (count={len(crops)}): {crops[:23]}...\\n\")\n",
        "\n",
        "    if yield_cols:\n",
        "        miss_info = pd.DataFrame({\n",
        "            \"YieldColumn\": yield_cols,\n",
        "            \"MissingPct\": [df[col].isna().mean() * 100.0 for col in yield_cols],\n",
        "        }).sort_values(\"MissingPct\").reset_index(drop=True)\n",
        "        safe_print(\"Yield missingness (% of NaN):\")\n",
        "        safe_print(miss_info.to_string(index=False))\n",
        "        safe_print()\n",
        "\n",
        "        for col in [\"RICE YIELD (Kg per ha)\", \"WHEAT YIELD (Kg per ha)\",\n",
        "                    \"MAIZE YIELD (Kg per ha)\", \"GROUNDNUT YIELD (Kg per ha)\",\n",
        "                    \"COTTON YIELD (Kg per ha)\", \"SUGARCANE YIELD (Kg per ha)\"]:\n",
        "            if col in df.columns:\n",
        "                safe_print(f\"Summary for {col.split(' YIELD')[0]} yield:\")\n",
        "                safe_print(df[col].describe())\n",
        "                safe_print()\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# CLEANING YIELDS + DIVERSIFICATION\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def clean_yields(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    safe_print(\"===== CLEANING DATA =====\")\n",
        "    df = df.copy()\n",
        "    yield_cols = [c for c in df.columns if \"YIELD (Kg per ha)\" in c]\n",
        "\n",
        "    for col in yield_cols:\n",
        "        s = df[col].copy()\n",
        "        old_max = s.max()\n",
        "        s = s.clip(lower=0)\n",
        "        if (s > 0).sum() > 0:\n",
        "            q = s[s > 0].quantile(0.995)\n",
        "            s = s.clip(upper=q)\n",
        "            new_max = float(s.max())\n",
        "            if new_max < old_max:\n",
        "                safe_print(f\"Clipped {col.split(' YIELD')[0]} yield: \"\n",
        "                          f\"old max={old_max:.2f}, new max={new_max:.2f}\")\n",
        "        df[col] = s\n",
        "\n",
        "    safe_print()\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_diversification_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    safe_print(\"===== COMPUTING DIVERSIFICATION =====\")\n",
        "    df = df.copy()\n",
        "\n",
        "    yield_cols = [c for c in df.columns if \"YIELD (Kg per ha)\" in c]\n",
        "    crop_names = [c.split(\" YIELD\")[0].strip() for c in yield_cols]\n",
        "\n",
        "    crop_area_cols = {}\n",
        "    for crop in crop_names:\n",
        "        candidates = [c for c in df.columns if crop in c and \"AREA\" in c.upper()]\n",
        "        if candidates:\n",
        "            crop_area_cols[crop] = candidates[0]\n",
        "\n",
        "    if not crop_area_cols:\n",
        "        safe_print(\"No AREA columns detected  diversification features will be zeros.\\n\")\n",
        "        df[\"diversity_simpson\"] = 0.0\n",
        "        df[\"num_active_crops\"] = 0\n",
        "        return df\n",
        "\n",
        "    area_mat = df[[crop_area_cols[c] for c in crop_area_cols]].fillna(0.0).values\n",
        "    total_area = area_mat.sum(axis=1)\n",
        "    total_area_safe = np.where(total_area == 0, 1.0, total_area)\n",
        "    shares = area_mat / total_area_safe[:, None]\n",
        "    hhi = (shares ** 2).sum(axis=1)\n",
        "    simpson = 1.0 - hhi\n",
        "    num_active = (area_mat > 0).sum(axis=1)\n",
        "\n",
        "    df[\"diversity_simpson\"] = simpson\n",
        "    df[\"num_active_crops\"] = num_active\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# ENHANCED NETWORK CONSTRUCTION\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def build_district_network(df: pd.DataFrame) -> Tuple[nx.Graph, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    IMPROVED: Build district similarity network with:\n",
        "    - Higher correlation threshold (0.80) for meaningful connections\n",
        "    - Top-k pruning to maintain sparse, interpretable network\n",
        "    - Additional centrality measures\n",
        "    \"\"\"\n",
        "    safe_print(\"===== BUILDING ENHANCED DISTRICT SIMILARITY NETWORK =====\")\n",
        "    df_ref = df.copy()\n",
        "    if \"Year\" in df_ref.columns:\n",
        "        df_ref = df_ref[(df_ref[\"Year\"] >= 2008) & (df_ref[\"Year\"] <= 2017)]\n",
        "\n",
        "    if \"Dist Code\" not in df_ref.columns:\n",
        "        safe_print(\"No 'Dist Code' column: cannot build district network.\")\n",
        "        return nx.Graph(), pd.DataFrame(columns=[\"Dist Code\"])\n",
        "\n",
        "    yield_cols = [c for c in df_ref.columns if \"YIELD (Kg per ha)\" in c]\n",
        "    if not yield_cols:\n",
        "        safe_print(\"No YIELD columns found: cannot build district network.\")\n",
        "        return nx.Graph(), pd.DataFrame(columns=[\"Dist Code\"])\n",
        "\n",
        "    # Aggregate to district-level mean yields\n",
        "    prof = df_ref.groupby(\"Dist Code\")[yield_cols].mean().fillna(0.0)\n",
        "\n",
        "    if prof.shape[0] == 0:\n",
        "        safe_print(\"No district profiles after filtering.\")\n",
        "        return nx.Graph(), pd.DataFrame(columns=[\"Dist Code\"])\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    arr = prof.values\n",
        "    norms = np.linalg.norm(arr, axis=1)\n",
        "    norms_safe = np.where(norms == 0, 1.0, norms)\n",
        "    arr_norm = arr / norms_safe[:, None]\n",
        "    sim = arr_norm @ arr_norm.T\n",
        "\n",
        "    dist_codes = prof.index.tolist()\n",
        "    G = nx.Graph()\n",
        "    for di in dist_codes:\n",
        "        G.add_node(di)\n",
        "\n",
        "    # IMPROVED: Higher threshold for more meaningful connections\n",
        "    threshold = 0.80\n",
        "    n = sim.shape[0]\n",
        "    edges_added = []\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            w = float(sim[i, j])\n",
        "            if w >= threshold:\n",
        "                edges_added.append((dist_codes[i], dist_codes[j], w))\n",
        "\n",
        "    # IMPROVED: Keep only top-k strongest edges per node\n",
        "    max_edges_per_node = 15\n",
        "    node_edges = {node: [] for node in dist_codes}\n",
        "\n",
        "    for d1, d2, w in edges_added:\n",
        "        node_edges[d1].append((d2, w))\n",
        "        node_edges[d2].append((d1, w))\n",
        "\n",
        "    for node in dist_codes:\n",
        "        edges = sorted(node_edges[node], key=lambda x: x[1], reverse=True)[:max_edges_per_node]\n",
        "        for neighbor, weight in edges:\n",
        "            if not G.has_edge(node, neighbor):\n",
        "                G.add_edge(node, neighbor, weight=weight)\n",
        "\n",
        "    density = nx.density(G) if G.number_of_nodes() > 0 else 0.0\n",
        "    safe_print(f\"Network reference window: 2008-2017\")\n",
        "    safe_print(f\"District network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "    safe_print(f\"Network density: {density:.1%} (target: 5-20%)\\n\")\n",
        "\n",
        "    if G.number_of_nodes() == 0:\n",
        "        return G, pd.DataFrame(columns=[\"Dist Code\"])\n",
        "\n",
        "    # IMPROVED: Multiple centrality measures\n",
        "    deg = dict(G.degree())\n",
        "    strength = {n: sum(d[\"weight\"] for _, _, d in G.edges(n, data=True)) for n in G.nodes}\n",
        "\n",
        "    # Only compute closeness/betweenness if network is connected enough\n",
        "    if nx.is_connected(G):\n",
        "        closeness = nx.closeness_centrality(G)\n",
        "        betw = nx.betweenness_centrality(G, normalized=True)\n",
        "    else:\n",
        "        # For disconnected graphs, compute per component\n",
        "        closeness = {}\n",
        "        betw = {}\n",
        "        for component in nx.connected_components(G):\n",
        "            subG = G.subgraph(component)\n",
        "            comp_close = nx.closeness_centrality(subG)\n",
        "            comp_betw = nx.betweenness_centrality(subG, normalized=True)\n",
        "            closeness.update(comp_close)\n",
        "            betw.update(comp_betw)\n",
        "\n",
        "    eigenvector = nx.eigenvector_centrality(G, max_iter=1000, weight='weight')\n",
        "    clustering = nx.clustering(G, weight='weight')\n",
        "\n",
        "    dist_features = pd.DataFrame({\n",
        "        \"Dist Code\": list(G.nodes),\n",
        "        \"net_degree\": [deg[d] for d in G.nodes],\n",
        "        \"net_strength\": [strength[d] for d in G.nodes],\n",
        "        \"net_closeness\": [closeness[d] for d in G.nodes],\n",
        "        \"net_betweenness\": [betw[d] for d in G.nodes],\n",
        "        \"net_eigenvector\": [eigenvector[d] for d in G.nodes],\n",
        "        \"net_clustering\": [clustering[d] for d in G.nodes],\n",
        "    })\n",
        "\n",
        "    return G, dist_features\n",
        "\n",
        "\n",
        "def build_crop_cooccurrence_network(df: pd.DataFrame) -> nx.Graph:\n",
        "    safe_print(\"===== BUILDING CROP-COOCCURRENCE NETWORK =====\")\n",
        "    yield_cols = [c for c in df.columns if \"YIELD (Kg per ha)\" in c]\n",
        "    if not yield_cols:\n",
        "        safe_print(\"No YIELD columns, skipping crop network.\\n\")\n",
        "        return nx.Graph()\n",
        "\n",
        "    crop_names = [c.split(\" YIELD\")[0].strip() for c in yield_cols]\n",
        "    crop_idx = {col: crop_names[i] for i, col in enumerate(yield_cols)}\n",
        "\n",
        "    G = nx.Graph()\n",
        "    for crop in crop_names:\n",
        "        G.add_node(crop)\n",
        "\n",
        "    key_cols = [c for c in [\"Dist Code\", \"Year\"] if c in df.columns]\n",
        "    if not key_cols:\n",
        "        rows = [df]\n",
        "    else:\n",
        "        rows = [g for _, g in df.groupby(key_cols)]\n",
        "\n",
        "    from itertools import combinations\n",
        "\n",
        "    for sub in rows:\n",
        "        vals = sub[yield_cols].fillna(0.0)\n",
        "        active_mask = (vals > 0).any(axis=0)\n",
        "        active_cols = [c for c, m in zip(yield_cols, active_mask) if m]\n",
        "        active_crops = [crop_idx[c] for c in active_cols]\n",
        "        for c1, c2 in combinations(sorted(set(active_crops)), 2):\n",
        "            if G.has_edge(c1, c2):\n",
        "                G[c1][c2][\"weight\"] += 1\n",
        "            else:\n",
        "                G.add_edge(c1, c2, weight=1)\n",
        "\n",
        "    safe_print(f\"Crop network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\\n\")\n",
        "    return G\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# SUPERVISED PANEL PREPARATION WITH FEATURE ENGINEERING\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def prepare_panel_for_crop(df: pd.DataFrame, crop: str) -> Tuple[pd.DataFrame, str, List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    IMPROVED: Enhanced feature engineering with:\n",
        "    - Robust handling of multicollinearity\n",
        "    - Removal of near-zero variance features\n",
        "    - Proper scaling indicators\n",
        "    \"\"\"\n",
        "    yield_candidates = [c for c in df.columns if c.startswith(crop) and \"YIELD (Kg per ha)\" in c]\n",
        "    if not yield_candidates:\n",
        "        raise ValueError(f\"Yield column for crop '{crop}' not found.\")\n",
        "    yield_col = yield_candidates[0]\n",
        "\n",
        "    if \"Dist Code\" not in df.columns or \"Year\" not in df.columns:\n",
        "        raise ValueError(\"Both 'Dist Code' and 'Year' must be present in the dataset.\")\n",
        "\n",
        "    panel = df.copy()\n",
        "    panel = panel.sort_values([\"Dist Code\", \"Year\"])\n",
        "    grp = panel.groupby(\"Dist Code\")[yield_col]\n",
        "\n",
        "    # Temporal features\n",
        "    panel[f\"{crop}_lag1\"] = grp.shift(1)\n",
        "    panel[f\"{crop}_lag2\"] = grp.shift(2)\n",
        "    panel[f\"{crop}_lag3\"] = grp.shift(3)\n",
        "    panel[f\"{crop}_roll3\"] = grp.shift(1).rolling(window=3, min_periods=1).mean()\n",
        "\n",
        "    # IMPROVED: Year-over-year change\n",
        "    panel[f\"{crop}_yoy_change\"] = grp.diff(1)\n",
        "\n",
        "    # IMPROVED: Volatility measure (rolling std)\n",
        "    panel[f\"{crop}_roll3_std\"] = grp.shift(1).rolling(window=3, min_periods=2).std()\n",
        "\n",
        "    excluded = {\"Dist Code\", \"Year\", yield_col}\n",
        "    feature_cols = []\n",
        "    for col in panel.columns:\n",
        "        if col in excluded:\n",
        "            continue\n",
        "        if np.issubdtype(panel[col].dtype, np.number):\n",
        "            # IMPROVED: Check for near-zero variance\n",
        "            if panel[col].std() > 1e-6:\n",
        "                feature_cols.append(col)\n",
        "            else:\n",
        "                safe_print(f\"  Excluding near-zero variance feature: {col}\")\n",
        "\n",
        "    # IMPROVED: Check for perfect multicollinearity\n",
        "    numeric_panel = panel[feature_cols].fillna(0.0)\n",
        "    corr_matrix = numeric_panel.corr().abs()\n",
        "\n",
        "    # Find highly correlated pairs\n",
        "    upper_tri = corr_matrix.where(\n",
        "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
        "    )\n",
        "    to_drop = [col for col in upper_tri.columns if any(upper_tri[col] > 0.99)]\n",
        "\n",
        "    if to_drop:\n",
        "        safe_print(f\"  Removing highly correlated features: {to_drop}\")\n",
        "        feature_cols = [c for c in feature_cols if c not in to_drop]\n",
        "\n",
        "    network_feature_cols = [\n",
        "        c for c in feature_cols\n",
        "        if c.lower().startswith(\"net_\")\n",
        "        or \"network\" in c.lower()\n",
        "        or \"centrality\" in c.lower()\n",
        "    ]\n",
        "\n",
        "    safe_print(f\"  Total features: {len(feature_cols)}, Network features: {len(network_feature_cols)}\")\n",
        "\n",
        "    return panel, yield_col, feature_cols, network_feature_cols\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# TIME-SERIES CROSS-VALIDATION SPLITS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def time_series_folds(years: np.ndarray, n_folds: int = N_FOLDS) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    years_unique = np.sort(np.unique(years))\n",
        "    n_years = len(years_unique)\n",
        "    if n_years < n_folds + 1:\n",
        "        warnings.warn(f\"Too few years ({n_years}) for {n_folds} folds; using single split.\")\n",
        "        mid = n_years // 2\n",
        "        return [(years_unique[:mid], years_unique[mid:])]\n",
        "\n",
        "    split_indices = [int((i + 1) * n_years / (n_folds + 1)) for i in range(n_folds)]\n",
        "\n",
        "    folds = []\n",
        "    for i in range(n_folds):\n",
        "        train_end_idx = split_indices[i]\n",
        "        test_start_idx = train_end_idx\n",
        "        test_end_idx = split_indices[i + 1] if i + 1 < len(split_indices) else n_years\n",
        "\n",
        "        train_years = years_unique[:train_end_idx]\n",
        "        test_years = years_unique[test_start_idx:test_end_idx]\n",
        "        if len(train_years) == 0 or len(test_years) == 0:\n",
        "            continue\n",
        "        folds.append((train_years, test_years))\n",
        "\n",
        "    return folds\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# IMPROVED MODEL TRAINING WITH ROBUST RIDGE\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def create_robust_ridge(alpha: float = 10.0) -> Ridge:\n",
        "    \"\"\"IMPROVED: Ridge with higher regularization to handle multicollinearity\"\"\"\n",
        "    return Ridge(alpha=alpha, max_iter=10000, random_state=RANDOM_STATE)\n",
        "\n",
        "\n",
        "def evaluate_models_for_crop(\n",
        "    crop: str,\n",
        "    panel: pd.DataFrame,\n",
        "    yield_col: str,\n",
        "    feature_cols: List[str],\n",
        "    network_feature_cols: List[str],\n",
        ") -> Tuple[List[Dict], Dict]:\n",
        "    \"\"\"\n",
        "    IMPROVED: Returns both records and feature importance info\n",
        "    \"\"\"\n",
        "    records = []\n",
        "    feature_importance_data = {}\n",
        "\n",
        "    mask_valid = panel[yield_col].notna() & (panel[yield_col] > 0)\n",
        "    panel_valid = panel.loc[mask_valid].copy()\n",
        "\n",
        "    years = panel_valid[\"Year\"].values\n",
        "    folds = time_series_folds(years, n_folds=N_FOLDS)\n",
        "    if not folds:\n",
        "        warnings.warn(f\"No valid folds for crop {crop}; skipping.\")\n",
        "        return records, feature_importance_data\n",
        "\n",
        "    non_network_feature_cols = [c for c in feature_cols if c not in network_feature_cols]\n",
        "    if not non_network_feature_cols:\n",
        "        non_network_feature_cols = feature_cols\n",
        "        network_feature_cols = []\n",
        "\n",
        "    fold_id = 0\n",
        "    all_importances_gb_no_net = []\n",
        "    all_importances_gb_with_net = []\n",
        "\n",
        "    for train_years, test_years in folds:\n",
        "        fold_id += 1\n",
        "        train_mask = panel_valid[\"Year\"].isin(train_years)\n",
        "        test_mask = panel_valid[\"Year\"].isin(test_years)\n",
        "\n",
        "        train_df = panel_valid.loc[train_mask]\n",
        "        test_df = panel_valid.loc[test_mask]\n",
        "\n",
        "        if len(train_df) == 0 or len(test_df) == 0:\n",
        "            continue\n",
        "\n",
        "        y_train = train_df[yield_col].values\n",
        "        y_test = test_df[yield_col].values\n",
        "\n",
        "        lag_col = f\"{crop}_lag1\"\n",
        "        roll3_col = f\"{crop}_roll3\"\n",
        "\n",
        "        # Baseline 1: Naive\n",
        "        if lag_col in test_df.columns:\n",
        "            y_pred_naive = test_df[lag_col].values.astype(float)\n",
        "            mean_train = y_train.mean()\n",
        "            y_pred_naive = np.where(np.isnan(y_pred_naive), mean_train, y_pred_naive)\n",
        "        else:\n",
        "            y_pred_naive = np.full_like(y_test, y_train.mean(), dtype=float)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred_naive)\n",
        "        rmse = mean_squared_error(y_test, y_pred_naive) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred_naive)\n",
        "        medae = median_ae(y_test, y_pred_naive)\n",
        "        r2 = r2_score(y_test, y_pred_naive)\n",
        "\n",
        "        safe_print(f\"{crop} | Naive | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"Naive\", \"FeatureSet\": \"no_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # Baseline 2: RollingMean3\n",
        "        if roll3_col in test_df.columns:\n",
        "            y_pred_roll3 = test_df[roll3_col].values.astype(float)\n",
        "            mean_train = y_train.mean()\n",
        "            y_pred_roll3 = np.where(np.isnan(y_pred_roll3), mean_train, y_pred_roll3)\n",
        "        else:\n",
        "            y_pred_roll3 = np.full_like(y_test, y_train.mean(), dtype=float)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred_roll3)\n",
        "        rmse = mean_squared_error(y_test, y_pred_roll3) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred_roll3)\n",
        "        medae = median_ae(y_test, y_pred_roll3)\n",
        "        r2 = r2_score(y_test, y_pred_roll3)\n",
        "\n",
        "        safe_print(f\"{crop} | RollingMean3 | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"RollingMean3\", \"FeatureSet\": \"no_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # Advanced models: no_network\n",
        "        X_train_no_net = train_df[non_network_feature_cols].fillna(0.0).values\n",
        "        X_test_no_net = test_df[non_network_feature_cols].fillna(0.0).values\n",
        "\n",
        "        # IMPROVED: Robust scaling for Ridge\n",
        "        scaler_no_net = RobustScaler()\n",
        "        X_train_no_net_scaled = scaler_no_net.fit_transform(X_train_no_net)\n",
        "        X_test_no_net_scaled = scaler_no_net.transform(X_test_no_net)\n",
        "\n",
        "        # Ridge no_network\n",
        "        ridge_no_net = create_robust_ridge(alpha=10.0)\n",
        "        ridge_no_net.fit(X_train_no_net_scaled, y_train)\n",
        "        y_pred = ridge_no_net.predict(X_test_no_net_scaled)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        safe_print(f\"{crop} | Ridge | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"Ridge\", \"FeatureSet\": \"no_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # RandomForest no_network\n",
        "        rf_no_net = RandomForestRegressor(\n",
        "            n_estimators=300, max_depth=None, min_samples_leaf=1,\n",
        "            random_state=RANDOM_STATE, n_jobs=-1\n",
        "        )\n",
        "        rf_no_net.fit(X_train_no_net, y_train)\n",
        "        y_pred = rf_no_net.predict(X_test_no_net)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        safe_print(f\"{crop} | RandomForest | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"RandomForest\", \"FeatureSet\": \"no_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # GradientBoosting no_network\n",
        "        gb_no_net = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
        "        gb_no_net.fit(X_train_no_net, y_train)\n",
        "        y_pred = gb_no_net.predict(X_test_no_net)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        safe_print(f\"{crop} | GradientBoosting | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"GradientBoosting\", \"FeatureSet\": \"no_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # Store feature importance\n",
        "        all_importances_gb_no_net.append(gb_no_net.feature_importances_)\n",
        "\n",
        "        # Advanced models: with_network\n",
        "        if network_feature_cols:\n",
        "            feature_cols_with_net = non_network_feature_cols + network_feature_cols\n",
        "        else:\n",
        "            feature_cols_with_net = non_network_feature_cols\n",
        "\n",
        "        X_train_with_net = train_df[feature_cols_with_net].fillna(0.0).values\n",
        "        X_test_with_net = test_df[feature_cols_with_net].fillna(0.0).values\n",
        "\n",
        "        # IMPROVED: Robust scaling for Ridge\n",
        "        scaler_with_net = RobustScaler()\n",
        "        X_train_with_net_scaled = scaler_with_net.fit_transform(X_train_with_net)\n",
        "        X_test_with_net_scaled = scaler_with_net.transform(X_test_with_net)\n",
        "\n",
        "        # Ridge with_network\n",
        "        ridge_with_net = create_robust_ridge(alpha=10.0)\n",
        "        ridge_with_net.fit(X_train_with_net_scaled, y_train)\n",
        "        y_pred = ridge_with_net.predict(X_test_with_net_scaled)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        safe_print(f\"{crop} | Ridge | with_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"Ridge\", \"FeatureSet\": \"with_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # RandomForest with_network\n",
        "        rf_with_net = RandomForestRegressor(\n",
        "            n_estimators=300, max_depth=None, min_samples_leaf=1,\n",
        "            random_state=RANDOM_STATE, n_jobs=-1\n",
        "        )\n",
        "        rf_with_net.fit(X_train_with_net, y_train)\n",
        "        y_pred = rf_with_net.predict(X_test_with_net)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        safe_print(f\"{crop} | RandomForest | with_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"RandomForest\", \"FeatureSet\": \"with_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # GradientBoosting with_network\n",
        "        gb_with_net = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
        "        gb_with_net.fit(X_train_with_net, y_train)\n",
        "        y_pred = gb_with_net.predict(X_test_with_net)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        safe_print(f\"{crop} | GradientBoosting | with_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"GradientBoosting\", \"FeatureSet\": \"with_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # Store feature importance\n",
        "        all_importances_gb_with_net.append(gb_with_net.feature_importances_)\n",
        "\n",
        "    # Compute average feature importance across folds\n",
        "    if all_importances_gb_no_net:\n",
        "        avg_imp_no_net = np.mean(all_importances_gb_no_net, axis=0)\n",
        "        feature_importance_data['no_network'] = {\n",
        "            'features': non_network_feature_cols,\n",
        "            'importance': avg_imp_no_net\n",
        "        }\n",
        "\n",
        "    if all_importances_gb_with_net:\n",
        "        avg_imp_with_net = np.mean(all_importances_gb_with_net, axis=0)\n",
        "        feature_importance_data['with_network'] = {\n",
        "            'features': feature_cols_with_net,\n",
        "            'importance': avg_imp_with_net\n",
        "        }\n",
        "\n",
        "    return records, feature_importance_data\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# STATISTICAL SIGNIFICANCE TESTING\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def perform_statistical_tests(per_fold_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    IMPROVED: Test if GradientBoosting with_network significantly outperforms\n",
        "    GradientBoosting no_network and baselines using paired t-tests.\n",
        "    \"\"\"\n",
        "    safe_print(\"\\n===== STATISTICAL SIGNIFICANCE TESTS =====\")\n",
        "    test_results = []\n",
        "\n",
        "    for crop in CROPS:\n",
        "        crop_data = per_fold_df[per_fold_df[\"Crop\"] == crop]\n",
        "\n",
        "        # Get GradientBoosting scores\n",
        "        gb_with_net = crop_data[\n",
        "            (crop_data[\"Model\"] == \"GradientBoosting\") &\n",
        "            (crop_data[\"FeatureSet\"] == \"with_network\")\n",
        "        ][\"MAE\"].values\n",
        "\n",
        "        gb_no_net = crop_data[\n",
        "            (crop_data[\"Model\"] == \"GradientBoosting\") &\n",
        "            (crop_data[\"FeatureSet\"] == \"no_network\")\n",
        "        ][\"MAE\"].values\n",
        "\n",
        "        naive = crop_data[crop_data[\"Model\"] == \"Naive\"][\"MAE\"].values\n",
        "        rolling = crop_data[crop_data[\"Model\"] == \"RollingMean3\"][\"MAE\"].values\n",
        "\n",
        "        if len(gb_with_net) > 0 and len(gb_no_net) > 0 and len(gb_with_net) == len(gb_no_net):\n",
        "            # Test: GB with_network vs GB no_network\n",
        "            t_stat, p_val = stats.ttest_rel(gb_with_net, gb_no_net)\n",
        "            improvement = ((gb_no_net.mean() - gb_with_net.mean()) / gb_no_net.mean()) * 100\n",
        "\n",
        "            test_results.append({\n",
        "                \"Crop\": crop,\n",
        "                \"Comparison\": \"GB_with_net vs GB_no_net\",\n",
        "                \"Mean_MAE_1\": gb_with_net.mean(),\n",
        "                \"Mean_MAE_2\": gb_no_net.mean(),\n",
        "                \"Improvement_%\": improvement,\n",
        "                \"t_statistic\": t_stat,\n",
        "                \"p_value\": p_val,\n",
        "                \"Significant_05\": \"Yes\" if p_val < 0.05 else \"No\"\n",
        "            })\n",
        "\n",
        "            safe_print(f\"{crop}: GB with_network vs no_network: \"\n",
        "                      f\"Improvement={improvement:.2f}%, p={p_val:.4f}\")\n",
        "\n",
        "        if len(gb_with_net) > 0 and len(naive) > 0 and len(gb_with_net) == len(naive):\n",
        "            # Test: GB with_network vs Naive\n",
        "            t_stat, p_val = stats.ttest_rel(gb_with_net, naive)\n",
        "            improvement = ((naive.mean() - gb_with_net.mean()) / naive.mean()) * 100\n",
        "\n",
        "            test_results.append({\n",
        "                \"Crop\": crop,\n",
        "                \"Comparison\": \"GB_with_net vs Naive\",\n",
        "                \"Mean_MAE_1\": gb_with_net.mean(),\n",
        "                \"Mean_MAE_2\": naive.mean(),\n",
        "                \"Improvement_%\": improvement,\n",
        "                \"t_statistic\": t_stat,\n",
        "                \"p_value\": p_val,\n",
        "                \"Significant_05\": \"Yes\" if p_val < 0.05 else \"No\"\n",
        "            })\n",
        "\n",
        "            safe_print(f\"{crop}: GB with_network vs Naive: \"\n",
        "                      f\"Improvement={improvement:.2f}%, p={p_val:.4f}\")\n",
        "\n",
        "    safe_print()\n",
        "    return pd.DataFrame(test_results)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# TEMPORAL STABILITY ANALYSIS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def analyze_temporal_stability(\n",
        "    per_fold_df: pd.DataFrame,\n",
        "    panels_by_crop: Dict\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    IMPROVED: Analyze how model performance varies over time\n",
        "    to detect potential concept drift or temporal instability.\n",
        "    \"\"\"\n",
        "    safe_print(\"\\n===== TEMPORAL STABILITY ANALYSIS =====\")\n",
        "    stability_results = []\n",
        "\n",
        "    for crop in CROPS:\n",
        "        if crop not in panels_by_crop:\n",
        "            continue\n",
        "\n",
        "        panel = panels_by_crop[crop][\"panel\"]\n",
        "        yield_col = panels_by_crop[crop][\"yield_col\"]\n",
        "\n",
        "        # Get per-fold results\n",
        "        crop_folds = per_fold_df[\n",
        "            (per_fold_df[\"Crop\"] == crop) &\n",
        "            (per_fold_df[\"Model\"] == \"GradientBoosting\") &\n",
        "            (per_fold_df[\"FeatureSet\"] == \"with_network\")\n",
        "        ]\n",
        "\n",
        "        if len(crop_folds) == 0:\n",
        "            continue\n",
        "\n",
        "        # Check if performance degrades over folds (time)\n",
        "        mae_by_fold = crop_folds.sort_values(\"Fold\")[\"MAE\"].values\n",
        "        r2_by_fold = crop_folds.sort_values(\"Fold\")[\"R2\"].values\n",
        "\n",
        "        if len(mae_by_fold) >= 2:\n",
        "            # Compute trend (positive slope = degrading performance)\n",
        "            fold_nums = np.arange(len(mae_by_fold))\n",
        "            mae_slope, mae_intercept, mae_r, _, _ = stats.linregress(fold_nums, mae_by_fold)\n",
        "            r2_slope, r2_intercept, r2_r, _, _ = stats.linregress(fold_nums, r2_by_fold)\n",
        "\n",
        "            stability_results.append({\n",
        "                \"Crop\": crop,\n",
        "                \"MAE_Fold1\": mae_by_fold[0],\n",
        "                \"MAE_Fold_Last\": mae_by_fold[-1],\n",
        "                \"MAE_Slope\": mae_slope,\n",
        "                \"MAE_Trend_R2\": mae_r**2,\n",
        "                \"R2_Fold1\": r2_by_fold[0],\n",
        "                \"R2_Fold_Last\": r2_by_fold[-1],\n",
        "                \"R2_Slope\": r2_slope,\n",
        "                \"Performance_Stable\": \"Yes\" if abs(mae_slope) < 10 else \"No\"\n",
        "            })\n",
        "\n",
        "            safe_print(f\"{crop}: MAE slope={mae_slope:.2f} (trend R={mae_r**2:.3f}), \"\n",
        "                      f\"R slope={r2_slope:.4f}\")\n",
        "\n",
        "    safe_print()\n",
        "    return pd.DataFrame(stability_results)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# FEATURE IMPORTANCE ANALYSIS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def analyze_feature_importance(\n",
        "    feature_importance_by_crop: Dict,\n",
        "    output_path: str\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    IMPROVED: Comprehensive feature importance analysis with network contribution.\n",
        "    \"\"\"\n",
        "    safe_print(\"\\n===== FEATURE IMPORTANCE ANALYSIS =====\")\n",
        "    all_importance_records = []\n",
        "\n",
        "    for crop, imp_data in feature_importance_by_crop.items():\n",
        "        for feature_set in [\"no_network\", \"with_network\"]:\n",
        "            if feature_set not in imp_data:\n",
        "                continue\n",
        "\n",
        "            features = imp_data[feature_set]['features']\n",
        "            importances = imp_data[feature_set]['importance']\n",
        "\n",
        "            # Sort by importance\n",
        "            sorted_idx = np.argsort(importances)[::-1]\n",
        "\n",
        "            for rank, idx in enumerate(sorted_idx, 1):\n",
        "                is_network = any(x in features[idx].lower()\n",
        "                                for x in ['net_', 'network', 'centrality'])\n",
        "                is_temporal = any(x in features[idx].lower()\n",
        "                                 for x in ['lag', 'roll', 'yoy'])\n",
        "                is_diversity = any(x in features[idx].lower()\n",
        "                                  for x in ['diversity', 'num_active'])\n",
        "\n",
        "                all_importance_records.append({\n",
        "                    \"Crop\": crop,\n",
        "                    \"FeatureSet\": feature_set,\n",
        "                    \"Feature\": features[idx],\n",
        "                    \"Importance\": importances[idx],\n",
        "                    \"Rank\": rank,\n",
        "                    \"IsNetwork\": is_network,\n",
        "                    \"IsTemporal\": is_temporal,\n",
        "                    \"IsDiversity\": is_diversity\n",
        "                })\n",
        "\n",
        "        # Calculate network contribution\n",
        "        if \"with_network\" in imp_data:\n",
        "            features = imp_data[\"with_network\"]['features']\n",
        "            importances = imp_data[\"with_network\"]['importance']\n",
        "\n",
        "            network_mask = [any(x in f.lower() for x in ['net_', 'network', 'centrality'])\n",
        "                           for f in features]\n",
        "            network_importance = importances[network_mask].sum() if any(network_mask) else 0.0\n",
        "            total_importance = importances.sum()\n",
        "            network_pct = (network_importance / total_importance * 100) if total_importance > 0 else 0.0\n",
        "\n",
        "            safe_print(f\"{crop}: Network features contribute {network_pct:.1f}% of total importance\")\n",
        "\n",
        "    importance_df = pd.DataFrame(all_importance_records)\n",
        "    importance_df.to_csv(output_path, index=False)\n",
        "    safe_print(f\"\\nSaved feature importance to: {output_path}\\n\")\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# MODEL SELECTION + SUMMARY\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def summarise_performance(per_fold_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    agg = (\n",
        "        per_fold_df\n",
        "        .groupby([\"Crop\", \"Model\", \"FeatureSet\"])\n",
        "        .agg(\n",
        "            MAE_mean=(\"MAE\", \"mean\"),\n",
        "            MAE_std=(\"MAE\", \"std\"),\n",
        "            RMSE_mean=(\"RMSE\", \"mean\"),\n",
        "            RMSE_std=(\"RMSE\", \"std\"),\n",
        "            MAPE_mean=(\"MAPE\", \"mean\"),\n",
        "            MAPE_std=(\"MAPE\", \"std\"),\n",
        "            MedAE_mean=(\"MedAE\", \"mean\"),\n",
        "            MedAE_std=(\"MedAE\", \"std\"),\n",
        "            R2_mean=(\"R2\", \"mean\"),\n",
        "            R2_std=(\"R2\", \"std\"),\n",
        "        )\n",
        "        .reset_index()\n",
        "    )\n",
        "    return agg\n",
        "\n",
        "\n",
        "def select_best_advanced_models(perf_summary: pd.DataFrame) -> pd.DataFrame:\n",
        "    advanced_models = [\"Ridge\", \"RandomForest\", \"GradientBoosting\"]\n",
        "    best_rows = []\n",
        "\n",
        "    for crop in sorted(perf_summary[\"Crop\"].unique()):\n",
        "        sub = perf_summary[\n",
        "            (perf_summary[\"Crop\"] == crop)\n",
        "            & (perf_summary[\"Model\"].isin(advanced_models))\n",
        "        ]\n",
        "        if sub.empty:\n",
        "            continue\n",
        "\n",
        "        sub_with_net = sub[sub[\"FeatureSet\"] == \"with_network\"]\n",
        "        if not sub_with_net.empty:\n",
        "            cand = sub_with_net\n",
        "        else:\n",
        "            cand = sub\n",
        "\n",
        "        min_mae = cand[\"MAE_mean\"].min()\n",
        "        mae_tol = min_mae * 1.01\n",
        "        cand = cand[cand[\"MAE_mean\"] <= mae_tol]\n",
        "\n",
        "        best_idx = cand[\"R2_mean\"].idxmax()\n",
        "        best_row = cand.loc[best_idx].copy()\n",
        "        best_rows.append(best_row)\n",
        "\n",
        "    best_df = pd.DataFrame(best_rows).reset_index(drop=True)\n",
        "    if not best_df.empty:\n",
        "        best_df[\"ModelLabel\"] = [\n",
        "            f\"Proposed_{m}_{fs}\"\n",
        "            for m, fs in zip(best_df[\"Model\"], best_df[\"FeatureSet\"])\n",
        "        ]\n",
        "    return best_df\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# ENHANCED DIAGNOSTIC PLOTS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def save_enhanced_diagnostic_plots(\n",
        "    crop: str,\n",
        "    model_name: str,\n",
        "    feature_set: str,\n",
        "    y_true: np.ndarray,\n",
        "    y_pred: np.ndarray,\n",
        "    output_dir: str\n",
        "):\n",
        "    \"\"\"\n",
        "    IMPROVED: Enhanced diagnostic plots with publication-quality visualizations\n",
        "    \"\"\"\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = mean_squared_error(y_true, y_pred) ** 0.5\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    residuals = y_true - y_pred\n",
        "\n",
        "    # Create 2x2 subplot figure\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "    # 1. Predicted vs Observed\n",
        "    ax = axes[0, 0]\n",
        "    ax.scatter(y_true, y_pred, alpha=0.4, s=20, edgecolors='none')\n",
        "    lims = [min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())]\n",
        "    ax.plot(lims, lims, 'r--', linewidth=2, label='Perfect prediction')\n",
        "    ax.set_xlabel('Observed Yield (kg/ha)', fontsize=11)\n",
        "    ax.set_ylabel('Predicted Yield (kg/ha)', fontsize=11)\n",
        "    ax.set_title(f'{crop} - Predicted vs Observed\\nMAE={mae:.1f}, RMSE={rmse:.1f}, R={r2:.3f}',\n",
        "                 fontsize=12)\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    # 2. Residuals vs Predicted\n",
        "    ax = axes[0, 1]\n",
        "    ax.scatter(y_pred, residuals, alpha=0.4, s=20, edgecolors='none')\n",
        "    ax.axhline(0, color='r', linestyle='--', linewidth=2)\n",
        "    ax.set_xlabel('Predicted Yield (kg/ha)', fontsize=11)\n",
        "    ax.set_ylabel('Residual (kg/ha)', fontsize=11)\n",
        "    ax.set_title('Residual Plot', fontsize=12)\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    # 3. Residual Distribution\n",
        "    ax = axes[1, 0]\n",
        "    ax.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
        "    ax.axvline(0, color='r', linestyle='--', linewidth=2)\n",
        "    ax.set_xlabel('Residual (kg/ha)', fontsize=11)\n",
        "    ax.set_ylabel('Frequency', fontsize=11)\n",
        "    ax.set_title(f'Residual Distribution\\nMean={residuals.mean():.1f}, Std={residuals.std():.1f}',\n",
        "                 fontsize=12)\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    # 4. Q-Q Plot\n",
        "    ax = axes[1, 1]\n",
        "    stats.probplot(residuals, dist=\"norm\", plot=ax)\n",
        "    ax.set_title('Q-Q Plot (Normality Check)', fontsize=12)\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plot_path = os.path.join(\n",
        "        output_dir,\n",
        "        f\"{crop}_{model_name}_{feature_set}_comprehensive_diagnostics.pdf\"\n",
        "    )\n",
        "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    safe_print(f\"Saved enhanced diagnostic plots for {crop} ({model_name}, {feature_set}) to {output_dir}.\")\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# MAIN PIPELINE\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def main():\n",
        "    safe_print(\"=\"*70)\n",
        "    safe_print(\"ENHANCED AGRICULTURAL YIELD PREDICTION PIPELINE\")\n",
        "    safe_print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    df, source_type = load_data()\n",
        "    safe_print(f\"Data source type: {source_type}\")\n",
        "    basic_eda(df)\n",
        "\n",
        "    df = clean_yields(df)\n",
        "    df = compute_diversification_features(df)\n",
        "\n",
        "    dist_graph, dist_feats = build_district_network(df)\n",
        "    crop_graph = build_crop_cooccurrence_network(df)\n",
        "\n",
        "    if not dist_feats.empty:\n",
        "        df = df.merge(dist_feats, on=\"Dist Code\", how=\"left\")\n",
        "\n",
        "    df.to_csv(CLEANED_CSV_PATH, index=False)\n",
        "    safe_print(f\"Saved cleaned dataset with features to: {CLEANED_CSV_PATH}\\n\")\n",
        "\n",
        "    all_records = []\n",
        "    panels_by_crop: Dict[str, Dict] = {}\n",
        "    feature_importance_by_crop: Dict[str, Dict] = {}\n",
        "\n",
        "    for crop in CROPS:\n",
        "        safe_print(f\"\\n{'='*70}\")\n",
        "        safe_print(f\"PROCESSING {crop}\")\n",
        "        safe_print(f\"{'='*70}\")\n",
        "\n",
        "        panel, y_col, feat_cols, net_cols = prepare_panel_for_crop(df, crop)\n",
        "\n",
        "        panel_path = f\"{SUPERVISED_PANEL_PREFIX}{crop.lower()}.csv\"\n",
        "        panel.to_csv(panel_path, index=False)\n",
        "        safe_print(f\"Saved supervised panel for {crop} to: {panel_path}\\n\")\n",
        "\n",
        "        panels_by_crop[crop] = {\n",
        "            \"panel\": panel,\n",
        "            \"yield_col\": y_col,\n",
        "            \"feature_cols\": feat_cols,\n",
        "            \"network_feature_cols\": net_cols,\n",
        "        }\n",
        "\n",
        "        crop_records, feat_imp = evaluate_models_for_crop(\n",
        "            crop=crop,\n",
        "            panel=panel,\n",
        "            yield_col=y_col,\n",
        "            feature_cols=feat_cols,\n",
        "            network_feature_cols=net_cols,\n",
        "        )\n",
        "        all_records.extend(crop_records)\n",
        "        feature_importance_by_crop[crop] = feat_imp\n",
        "\n",
        "    per_fold_df = pd.DataFrame(all_records)\n",
        "    per_fold_df.to_csv(MODEL_PER_FOLD_CSV, index=False)\n",
        "    safe_print(f\"\\nSaved per-fold model results to: {MODEL_PER_FOLD_CSV}\")\n",
        "\n",
        "    perf_summary = summarise_performance(per_fold_df)\n",
        "    perf_summary.to_csv(MODEL_PERF_SUMMARY_CSV, index=False)\n",
        "    safe_print(f\"Saved model performance summary to: {MODEL_PERF_SUMMARY_CSV}\\n\")\n",
        "\n",
        "    # NEW: Statistical significance tests\n",
        "    stat_tests = perform_statistical_tests(per_fold_df)\n",
        "    stat_tests.to_csv(STATISTICAL_TESTS_CSV, index=False)\n",
        "    safe_print(f\"Saved statistical tests to: {STATISTICAL_TESTS_CSV}\\n\")\n",
        "\n",
        "    # NEW: Temporal stability analysis\n",
        "    stability_analysis = analyze_temporal_stability(per_fold_df, panels_by_crop)\n",
        "    stability_analysis.to_csv(TEMPORAL_STABILITY_CSV, index=False)\n",
        "    safe_print(f\"Saved temporal stability analysis to: {TEMPORAL_STABILITY_CSV}\\n\")\n",
        "\n",
        "    # NEW: Feature importance analysis\n",
        "    analyze_feature_importance(feature_importance_by_crop, FEATURE_IMPORTANCE_CSV)\n",
        "\n",
        "    for crop in CROPS:\n",
        "        for fs in [\"no_network\", \"with_network\"]:\n",
        "            sub = perf_summary[(perf_summary[\"Crop\"] == crop) & (perf_summary[\"FeatureSet\"] == fs)]\n",
        "            if sub.empty:\n",
        "                continue\n",
        "            safe_print(f\"\\nPerformance summary for {crop} ({fs}):\")\n",
        "            safe_print(sub.sort_values(\"MAE_mean\").to_string(index=False))\n",
        "\n",
        "    best_df = select_best_advanced_models(perf_summary)\n",
        "    best_df.to_csv(BEST_MODELS_CSV, index=False)\n",
        "\n",
        "    safe_print(\"\\n\" + \"=\"*70)\n",
        "    safe_print(\"FINAL SUMMARY (BEST ADVANCED MODELS)\")\n",
        "    safe_print(\"=\"*70)\n",
        "    for row in best_df.itertuples(index=False):\n",
        "        safe_print(\n",
        "            f\"  {row.Crop}: {row.Model} ({row.FeatureSet}) | \"\n",
        "            f\"MAE={row.MAE_mean:.2f} ({row.MAE_std:.2f}), R={row.R2_mean:.3f} ({row.R2_std:.3f})\"\n",
        "        )\n",
        "\n",
        "    # Generate enhanced diagnostic plots\n",
        "    safe_print(\"\\n\" + \"=\"*70)\n",
        "    safe_print(\"GENERATING ENHANCED DIAGNOSTIC PLOTS\")\n",
        "    safe_print(\"=\"*70)\n",
        "\n",
        "    for row in best_df.itertuples(index=False):\n",
        "        crop = row.Crop\n",
        "        meta = panels_by_crop[crop]\n",
        "        panel = meta[\"panel\"]\n",
        "        y_col = meta[\"yield_col\"]\n",
        "        feat_cols = meta[\"feature_cols\"]\n",
        "        net_cols = meta[\"network_feature_cols\"]\n",
        "\n",
        "        # Fit on full data for diagnostics\n",
        "        mask_valid = panel[y_col].notna() & (panel[y_col] > 0)\n",
        "        panel_valid = panel.loc[mask_valid].copy()\n",
        "\n",
        "        non_net_cols = [c for c in feat_cols if c not in net_cols]\n",
        "        if row.FeatureSet == \"with_network\" and net_cols:\n",
        "            use_cols = non_net_cols + net_cols\n",
        "        else:\n",
        "            use_cols = non_net_cols\n",
        "\n",
        "        X = panel_valid[use_cols].fillna(0.0).values\n",
        "        y = panel_valid[y_col].values\n",
        "\n",
        "        if row.Model == \"GradientBoosting\":\n",
        "            model = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
        "        elif row.Model == \"RandomForest\":\n",
        "            model = RandomForestRegressor(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "        elif row.Model == \"Ridge\":\n",
        "            scaler = RobustScaler()\n",
        "            X = scaler.fit_transform(X)\n",
        "            model = create_robust_ridge(alpha=10.0)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        model.fit(X, y)\n",
        "        y_pred = model.predict(X)\n",
        "\n",
        "        save_enhanced_diagnostic_plots(\n",
        "            crop=crop,\n",
        "            model_name=row.Model,\n",
        "            feature_set=row.FeatureSet,\n",
        "            y_true=y,\n",
        "            y_pred=y_pred,\n",
        "            output_dir=OUTPUT_DIR\n",
        "        )\n",
        "\n",
        "    safe_print(\"\\n\" + \"=\"*70)\n",
        "    safe_print(\"PIPELINE COMPLETE\")\n",
        "    safe_print(\"=\"*70)\n",
        "    safe_print(f\"Rows after cleaning: {len(df)}\")\n",
        "    if \"Year\" in df.columns:\n",
        "        safe_print(f\"Years: {int(df['Year'].min())} - {int(df['Year'].max())}\")\n",
        "    safe_print(f\"Districts: {df['Dist Code'].nunique() if 'Dist Code' in df.columns else 'N/A'}\")\n",
        "    safe_print(f\"Crops modeled: {CROPS}\")\n",
        "    safe_print(f\"\\nKey outputs:\")\n",
        "    safe_print(f\"  - Cleaned dataset: {CLEANED_CSV_PATH}\")\n",
        "    safe_print(f\"  - Performance summary: {MODEL_PERF_SUMMARY_CSV}\")\n",
        "    safe_print(f\"  - Statistical tests: {STATISTICAL_TESTS_CSV}\")\n",
        "    safe_print(f\"  - Temporal stability: {TEMPORAL_STABILITY_CSV}\")\n",
        "    safe_print(f\"  - Feature importance: {FEATURE_IMPORTANCE_CSV}\")\n",
        "    safe_print(f\"  - Best models: {BEST_MODELS_CSV}\")\n",
        "    safe_print(f\"  - Diagnostic plots: {OUTPUT_DIR}/*.pdf\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHah9s9nD-Rq",
        "outputId": "5545d2ed-0116-4ed8-80ba-c37221c7fb0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "ENHANCED AGRICULTURAL YIELD PREDICTION PIPELINE\n",
            "======================================================================\n",
            "\n",
            "RAW_CSV_PATH not found.\n",
            "Falling back to existing CLEANED dataset: /content/drive/MyDrive/Shiny/ICRISAT/Results1/icrisat_cleaned_with_features.csv\n",
            "\n",
            "Data source type: cleaned\n",
            "===== BASIC EDA =====\n",
            "Duplicate (Dist Code, Year) rows: 0\n",
            "Key (Dist Code, Year) is unique.\n",
            "\n",
            "Rows: 16146, Columns: 85\n",
            "Time range: 1966 - 2017\n",
            "Unique States: 20\n",
            "Detected crops (count=23): ['BARLEY', 'CASTOR', 'CHICKPEA', 'COTTON', 'FINGER MILLET', 'GROUNDNUT', 'KHARIF SORGHUM', 'LINSEED', 'MAIZE', 'MINOR PULSES', 'OILSEEDS', 'PEARL MILLET', 'PIGEONPEA', 'RABI SORGHUM', 'RAPESEED AND MUSTARD', 'RICE', 'SAFFLOWER', 'SESAMUM', 'SORGHUM', 'SOYABEAN', 'SUGARCANE', 'SUNFLOWER', 'WHEAT']...\n",
            "\n",
            "Yield missingness (% of NaN):\n",
            "                           YieldColumn  MissingPct\n",
            "                RICE YIELD (Kg per ha)         0.0\n",
            "               WHEAT YIELD (Kg per ha)         0.0\n",
            "      KHARIF SORGHUM YIELD (Kg per ha)         0.0\n",
            "        RABI SORGHUM YIELD (Kg per ha)         0.0\n",
            "             SORGHUM YIELD (Kg per ha)         0.0\n",
            "        PEARL MILLET YIELD (Kg per ha)         0.0\n",
            "               MAIZE YIELD (Kg per ha)         0.0\n",
            "       FINGER MILLET YIELD (Kg per ha)         0.0\n",
            "              BARLEY YIELD (Kg per ha)         0.0\n",
            "            CHICKPEA YIELD (Kg per ha)         0.0\n",
            "           PIGEONPEA YIELD (Kg per ha)         0.0\n",
            "        MINOR PULSES YIELD (Kg per ha)         0.0\n",
            "           GROUNDNUT YIELD (Kg per ha)         0.0\n",
            "             SESAMUM YIELD (Kg per ha)         0.0\n",
            "RAPESEED AND MUSTARD YIELD (Kg per ha)         0.0\n",
            "           SAFFLOWER YIELD (Kg per ha)         0.0\n",
            "              CASTOR YIELD (Kg per ha)         0.0\n",
            "             LINSEED YIELD (Kg per ha)         0.0\n",
            "           SUNFLOWER YIELD (Kg per ha)         0.0\n",
            "            SOYABEAN YIELD (Kg per ha)         0.0\n",
            "            OILSEEDS YIELD (Kg per ha)         0.0\n",
            "           SUGARCANE YIELD (Kg per ha)         0.0\n",
            "              COTTON YIELD (Kg per ha)         0.0\n",
            "\n",
            "Summary for RICE yield:\n",
            "count    16146.000000\n",
            "mean      1483.292542\n",
            "std        945.021594\n",
            "min         -1.000000\n",
            "25%        800.000000\n",
            "50%       1333.210000\n",
            "75%       2113.517500\n",
            "max       4104.539500\n",
            "Name: RICE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for WHEAT yield:\n",
            "count    16146.000000\n",
            "mean      1489.257600\n",
            "std       1071.711149\n",
            "min         -1.000000\n",
            "25%        750.000000\n",
            "50%       1347.450000\n",
            "75%       2131.580000\n",
            "max       4484.845500\n",
            "Name: WHEAT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for MAIZE yield:\n",
            "count    16146.000000\n",
            "mean      1394.223418\n",
            "std       1115.348199\n",
            "min         -1.000000\n",
            "25%        696.890000\n",
            "50%       1159.065000\n",
            "75%       1863.640000\n",
            "max       5897.884500\n",
            "Name: MAIZE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for GROUNDNUT yield:\n",
            "count    16146.000000\n",
            "mean       759.274042\n",
            "std        598.975772\n",
            "min         -1.000000\n",
            "25%          0.000000\n",
            "50%        774.410000\n",
            "75%       1085.037500\n",
            "max       2541.269500\n",
            "Name: GROUNDNUT YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for COTTON yield:\n",
            "count    16146.000000\n",
            "mean       119.822151\n",
            "std        167.343629\n",
            "min         -1.000000\n",
            "25%          0.000000\n",
            "50%          0.000000\n",
            "75%        202.270000\n",
            "max        740.297000\n",
            "Name: COTTON YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "Summary for SUGARCANE yield:\n",
            "count    16146.000000\n",
            "mean      4484.068278\n",
            "std       3105.552367\n",
            "min         -1.000000\n",
            "25%       2000.000000\n",
            "50%       4502.210000\n",
            "75%       6704.605000\n",
            "max      12000.000000\n",
            "Name: SUGARCANE YIELD (Kg per ha), dtype: float64\n",
            "\n",
            "===== CLEANING DATA =====\n",
            "\n",
            "===== COMPUTING DIVERSIFICATION =====\n",
            "===== BUILDING ENHANCED DISTRICT SIMILARITY NETWORK =====\n",
            "Network reference window: 2008-2017\n",
            "District network: 311 nodes, 2996 edges\n",
            "Network density: 6.2% (target: 5-20%)\n",
            "\n",
            "===== BUILDING CROP-COOCCURRENCE NETWORK =====\n",
            "Crop network: 23 nodes, 253 edges\n",
            "\n",
            "Saved cleaned dataset with features to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/icrisat_cleaned_with_features.csv\n",
            "\n",
            "\n",
            "======================================================================\n",
            "PROCESSING RICE\n",
            "======================================================================\n",
            "  Removing highly correlated features: ['DIVERSIFICATION_INDEX', 'net_strength']\n",
            "  Total features: 92, Network features: 5\n",
            "Saved supervised panel for RICE to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/supervised_panel_rice.csv\n",
            "\n",
            "RICE | Naive | no_network | Fold 1: MAE=283.13, RMSE=388.58, MAPE=28.65, MedAE=206.41, R2=0.741\n",
            "RICE | RollingMean3 | no_network | Fold 1: MAE=261.17, RMSE=354.54, MAPE=25.65, MedAE=200.58, R2=0.785\n",
            "RICE | Ridge | no_network | Fold 1: MAE=249.81, RMSE=987.91, MAPE=25.40, MedAE=56.27, R2=-0.672\n",
            "RICE | RandomForest | no_network | Fold 1: MAE=46.49, RMSE=110.70, MAPE=4.00, MedAE=15.56, R2=0.979\n",
            "RICE | GradientBoosting | no_network | Fold 1: MAE=65.20, RMSE=113.60, MAPE=5.79, MedAE=40.63, R2=0.978\n",
            "RICE | Ridge | with_network | Fold 1: MAE=212.64, RMSE=850.20, MAPE=21.05, MedAE=55.95, R2=-0.239\n",
            "RICE | RandomForest | with_network | Fold 1: MAE=46.89, RMSE=111.06, MAPE=4.03, MedAE=15.72, R2=0.979\n",
            "RICE | GradientBoosting | with_network | Fold 1: MAE=65.44, RMSE=113.00, MAPE=5.89, MedAE=40.80, R2=0.978\n",
            "RICE | Naive | no_network | Fold 2: MAE=281.83, RMSE=403.88, MAPE=22.80, MedAE=194.60, R2=0.779\n",
            "RICE | RollingMean3 | no_network | Fold 2: MAE=243.53, RMSE=345.71, MAPE=19.73, MedAE=170.77, R2=0.838\n",
            "RICE | Ridge | no_network | Fold 2: MAE=37.00, RMSE=50.84, MAPE=2.78, MedAE=28.72, R2=0.997\n",
            "RICE | RandomForest | no_network | Fold 2: MAE=27.63, RMSE=64.89, MAPE=2.04, MedAE=10.10, R2=0.994\n",
            "RICE | GradientBoosting | no_network | Fold 2: MAE=49.93, RMSE=73.37, MAPE=3.95, MedAE=34.98, R2=0.993\n",
            "RICE | Ridge | with_network | Fold 2: MAE=38.42, RMSE=52.46, MAPE=2.85, MedAE=30.32, R2=0.996\n",
            "RICE | RandomForest | with_network | Fold 2: MAE=27.82, RMSE=65.48, MAPE=2.06, MedAE=10.29, R2=0.994\n",
            "RICE | GradientBoosting | with_network | Fold 2: MAE=49.35, RMSE=72.82, MAPE=3.92, MedAE=34.58, R2=0.993\n",
            "RICE | Naive | no_network | Fold 3: MAE=296.29, RMSE=459.69, MAPE=19.00, MedAE=178.54, R2=0.759\n",
            "RICE | RollingMean3 | no_network | Fold 3: MAE=286.20, RMSE=419.20, MAPE=18.09, MedAE=191.22, R2=0.800\n",
            "RICE | Ridge | no_network | Fold 3: MAE=35.47, RMSE=51.34, MAPE=2.17, MedAE=24.46, R2=0.997\n",
            "RICE | RandomForest | no_network | Fold 3: MAE=32.85, RMSE=88.13, MAPE=1.97, MedAE=10.65, R2=0.991\n",
            "RICE | GradientBoosting | no_network | Fold 3: MAE=56.19, RMSE=84.64, MAPE=3.77, MedAE=38.03, R2=0.992\n",
            "RICE | Ridge | with_network | Fold 3: MAE=36.34, RMSE=52.59, MAPE=2.23, MedAE=25.16, R2=0.997\n",
            "RICE | RandomForest | with_network | Fold 3: MAE=32.92, RMSE=88.16, MAPE=1.97, MedAE=10.80, R2=0.991\n",
            "RICE | GradientBoosting | with_network | Fold 3: MAE=57.69, RMSE=87.54, MAPE=3.81, MedAE=38.85, R2=0.991\n",
            "\n",
            "======================================================================\n",
            "PROCESSING WHEAT\n",
            "======================================================================\n",
            "  Removing highly correlated features: ['DIVERSIFICATION_INDEX', 'net_strength']\n",
            "  Total features: 92, Network features: 5\n",
            "Saved supervised panel for WHEAT to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/supervised_panel_wheat.csv\n",
            "\n",
            "WHEAT | Naive | no_network | Fold 1: MAE=256.38, RMSE=366.30, MAPE=20.11, MedAE=179.57, R2=0.752\n",
            "WHEAT | RollingMean3 | no_network | Fold 1: MAE=243.36, RMSE=335.36, MAPE=18.90, MedAE=179.21, R2=0.792\n",
            "WHEAT | Ridge | no_network | Fold 1: MAE=173.13, RMSE=519.90, MAPE=18.69, MedAE=45.11, R2=0.501\n",
            "WHEAT | RandomForest | no_network | Fold 1: MAE=55.45, RMSE=143.15, MAPE=3.72, MedAE=16.46, R2=0.962\n",
            "WHEAT | GradientBoosting | no_network | Fold 1: MAE=55.76, RMSE=102.80, MAPE=4.19, MedAE=34.58, R2=0.980\n",
            "WHEAT | Ridge | with_network | Fold 1: MAE=162.47, RMSE=483.85, MAPE=17.76, MedAE=48.31, R2=0.568\n",
            "WHEAT | RandomForest | with_network | Fold 1: MAE=55.35, RMSE=143.98, MAPE=3.59, MedAE=15.51, R2=0.962\n",
            "WHEAT | GradientBoosting | with_network | Fold 1: MAE=56.98, RMSE=111.62, MAPE=4.14, MedAE=33.37, R2=0.977\n",
            "WHEAT | Naive | no_network | Fold 2: MAE=266.29, RMSE=380.49, MAPE=17.55, MedAE=192.28, R2=0.825\n",
            "WHEAT | RollingMean3 | no_network | Fold 2: MAE=239.64, RMSE=333.90, MAPE=15.99, MedAE=173.52, R2=0.865\n",
            "WHEAT | Ridge | no_network | Fold 2: MAE=33.07, RMSE=45.11, MAPE=2.13, MedAE=26.07, R2=0.998\n",
            "WHEAT | RandomForest | no_network | Fold 2: MAE=39.58, RMSE=93.82, MAPE=2.01, MedAE=11.30, R2=0.989\n",
            "WHEAT | GradientBoosting | no_network | Fold 2: MAE=58.14, RMSE=99.55, MAPE=3.30, MedAE=33.08, R2=0.988\n",
            "WHEAT | Ridge | with_network | Fold 2: MAE=32.92, RMSE=44.92, MAPE=2.14, MedAE=25.74, R2=0.998\n",
            "WHEAT | RandomForest | with_network | Fold 2: MAE=39.77, RMSE=94.07, MAPE=2.02, MedAE=11.35, R2=0.989\n",
            "WHEAT | GradientBoosting | with_network | Fold 2: MAE=58.22, RMSE=99.85, MAPE=3.30, MedAE=33.38, R2=0.988\n",
            "WHEAT | Naive | no_network | Fold 3: MAE=338.39, RMSE=497.48, MAPE=18.76, MedAE=222.74, R2=0.776\n",
            "WHEAT | RollingMean3 | no_network | Fold 3: MAE=324.38, RMSE=463.32, MAPE=17.35, MedAE=222.22, R2=0.806\n",
            "WHEAT | Ridge | no_network | Fold 3: MAE=31.48, RMSE=44.69, MAPE=1.61, MedAE=23.01, R2=0.998\n",
            "WHEAT | RandomForest | no_network | Fold 3: MAE=66.94, RMSE=162.38, MAPE=2.70, MedAE=12.19, R2=0.976\n",
            "WHEAT | GradientBoosting | no_network | Fold 3: MAE=74.97, RMSE=123.26, MAPE=3.47, MedAE=41.48, R2=0.986\n",
            "WHEAT | Ridge | with_network | Fold 3: MAE=31.82, RMSE=45.22, MAPE=1.63, MedAE=23.53, R2=0.998\n",
            "WHEAT | RandomForest | with_network | Fold 3: MAE=67.13, RMSE=162.60, MAPE=2.70, MedAE=12.28, R2=0.976\n",
            "WHEAT | GradientBoosting | with_network | Fold 3: MAE=74.81, RMSE=124.48, MAPE=3.49, MedAE=41.65, R2=0.986\n",
            "\n",
            "======================================================================\n",
            "PROCESSING MAIZE\n",
            "======================================================================\n",
            "  Removing highly correlated features: ['DIVERSIFICATION_INDEX', 'net_strength']\n",
            "  Total features: 92, Network features: 5\n",
            "Saved supervised panel for MAIZE to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/supervised_panel_maize.csv\n",
            "\n",
            "MAIZE | Naive | no_network | Fold 1: MAE=399.22, RMSE=623.08, MAPE=36.64, MedAE=259.91, R2=0.312\n",
            "MAIZE | RollingMean3 | no_network | Fold 1: MAE=379.21, RMSE=571.02, MAPE=34.87, MedAE=260.04, R2=0.422\n",
            "MAIZE | Ridge | no_network | Fold 1: MAE=667.45, RMSE=2702.75, MAPE=48.85, MedAE=74.59, R2=-11.945\n",
            "MAIZE | RandomForest | no_network | Fold 1: MAE=56.24, RMSE=149.04, MAPE=4.23, MedAE=17.60, R2=0.961\n",
            "MAIZE | GradientBoosting | no_network | Fold 1: MAE=71.75, RMSE=127.84, MAPE=6.44, MedAE=43.68, R2=0.971\n",
            "MAIZE | Ridge | with_network | Fold 1: MAE=651.27, RMSE=2659.01, MAPE=47.63, MedAE=78.65, R2=-11.530\n",
            "MAIZE | RandomForest | with_network | Fold 1: MAE=56.33, RMSE=148.41, MAPE=4.25, MedAE=17.77, R2=0.961\n",
            "MAIZE | GradientBoosting | with_network | Fold 1: MAE=71.85, RMSE=127.19, MAPE=6.44, MedAE=43.91, R2=0.971\n",
            "MAIZE | Naive | no_network | Fold 2: MAE=410.81, RMSE=613.36, MAPE=28.27, MedAE=281.45, R2=0.477\n",
            "MAIZE | RollingMean3 | no_network | Fold 2: MAE=366.05, RMSE=544.43, MAPE=24.63, MedAE=251.96, R2=0.588\n",
            "MAIZE | Ridge | no_network | Fold 2: MAE=34.06, RMSE=49.98, MAPE=2.26, MedAE=24.41, R2=0.997\n",
            "MAIZE | RandomForest | no_network | Fold 2: MAE=36.34, RMSE=128.41, MAPE=1.76, MedAE=10.28, R2=0.977\n",
            "MAIZE | GradientBoosting | no_network | Fold 2: MAE=54.00, RMSE=96.81, MAPE=3.48, MedAE=33.88, R2=0.987\n",
            "MAIZE | Ridge | with_network | Fold 2: MAE=34.95, RMSE=51.18, MAPE=2.31, MedAE=25.04, R2=0.996\n",
            "MAIZE | RandomForest | with_network | Fold 2: MAE=36.69, RMSE=129.58, MAPE=1.77, MedAE=10.20, R2=0.977\n",
            "MAIZE | GradientBoosting | with_network | Fold 2: MAE=53.81, RMSE=98.12, MAPE=3.45, MedAE=33.39, R2=0.987\n",
            "MAIZE | Naive | no_network | Fold 3: MAE=513.74, RMSE=817.19, MAPE=27.94, MedAE=300.00, R2=0.634\n",
            "MAIZE | RollingMean3 | no_network | Fold 3: MAE=488.79, RMSE=759.53, MAPE=25.87, MedAE=304.04, R2=0.684\n",
            "MAIZE | Ridge | no_network | Fold 3: MAE=32.97, RMSE=48.87, MAPE=1.67, MedAE=22.57, R2=0.999\n",
            "MAIZE | RandomForest | no_network | Fold 3: MAE=82.10, RMSE=212.67, MAPE=2.77, MedAE=12.03, R2=0.975\n",
            "MAIZE | GradientBoosting | no_network | Fold 3: MAE=76.50, RMSE=126.95, MAPE=3.80, MedAE=43.59, R2=0.991\n",
            "MAIZE | Ridge | with_network | Fold 3: MAE=34.07, RMSE=50.38, MAPE=1.73, MedAE=23.13, R2=0.999\n",
            "MAIZE | RandomForest | with_network | Fold 3: MAE=82.15, RMSE=212.21, MAPE=2.78, MedAE=12.01, R2=0.975\n",
            "MAIZE | GradientBoosting | with_network | Fold 3: MAE=76.56, RMSE=127.22, MAPE=3.80, MedAE=43.59, R2=0.991\n",
            "\n",
            "======================================================================\n",
            "PROCESSING GROUNDNUT\n",
            "======================================================================\n",
            "  Removing highly correlated features: ['DIVERSIFICATION_INDEX', 'net_strength']\n",
            "  Total features: 92, Network features: 5\n",
            "Saved supervised panel for GROUNDNUT to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/supervised_panel_groundnut.csv\n",
            "\n",
            "GROUNDNUT | Naive | no_network | Fold 1: MAE=271.23, RMSE=391.11, MAPE=35.40, MedAE=193.55, R2=-0.154\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 1: MAE=263.90, RMSE=363.37, MAPE=33.86, MedAE=193.34, R2=0.004\n",
            "GROUNDNUT | Ridge | no_network | Fold 1: MAE=365.70, RMSE=1079.61, MAPE=51.78, MedAE=93.63, R2=-7.794\n",
            "GROUNDNUT | RandomForest | no_network | Fold 1: MAE=69.12, RMSE=125.63, MAPE=8.77, MedAE=27.19, R2=0.881\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 1: MAE=61.80, RMSE=95.28, MAPE=8.20, MedAE=39.87, R2=0.932\n",
            "GROUNDNUT | Ridge | with_network | Fold 1: MAE=365.72, RMSE=1105.80, MAPE=51.87, MedAE=95.11, R2=-8.226\n",
            "GROUNDNUT | RandomForest | with_network | Fold 1: MAE=69.69, RMSE=126.63, MAPE=8.84, MedAE=28.04, R2=0.879\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 1: MAE=61.58, RMSE=94.74, MAPE=8.11, MedAE=40.36, R2=0.932\n",
            "GROUNDNUT | Naive | no_network | Fold 2: MAE=284.88, RMSE=412.05, MAPE=31.37, MedAE=193.95, R2=-0.049\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 2: MAE=253.01, RMSE=352.31, MAPE=27.43, MedAE=186.02, R2=0.233\n",
            "GROUNDNUT | Ridge | no_network | Fold 2: MAE=43.18, RMSE=56.14, MAPE=4.64, MedAE=34.23, R2=0.981\n",
            "GROUNDNUT | RandomForest | no_network | Fold 2: MAE=24.95, RMSE=63.97, MAPE=2.62, MedAE=8.04, R2=0.975\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 2: MAE=35.86, RMSE=58.84, MAPE=4.34, MedAE=23.21, R2=0.979\n",
            "GROUNDNUT | Ridge | with_network | Fold 2: MAE=43.43, RMSE=56.46, MAPE=4.66, MedAE=34.80, R2=0.980\n",
            "GROUNDNUT | RandomForest | with_network | Fold 2: MAE=24.95, RMSE=63.63, MAPE=2.61, MedAE=7.98, R2=0.975\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 2: MAE=36.40, RMSE=58.50, MAPE=4.33, MedAE=23.66, R2=0.979\n",
            "GROUNDNUT | Naive | no_network | Fold 3: MAE=279.98, RMSE=428.15, MAPE=26.07, MedAE=175.49, R2=0.407\n",
            "GROUNDNUT | RollingMean3 | no_network | Fold 3: MAE=257.38, RMSE=368.99, MAPE=23.47, MedAE=183.24, R2=0.560\n",
            "GROUNDNUT | Ridge | no_network | Fold 3: MAE=38.49, RMSE=50.31, MAPE=3.26, MedAE=30.68, R2=0.992\n",
            "GROUNDNUT | RandomForest | no_network | Fold 3: MAE=31.37, RMSE=71.89, MAPE=2.30, MedAE=7.74, R2=0.983\n",
            "GROUNDNUT | GradientBoosting | no_network | Fold 3: MAE=42.37, RMSE=64.49, MAPE=3.67, MedAE=27.16, R2=0.987\n",
            "GROUNDNUT | Ridge | with_network | Fold 3: MAE=38.53, RMSE=50.37, MAPE=3.26, MedAE=30.25, R2=0.992\n",
            "GROUNDNUT | RandomForest | with_network | Fold 3: MAE=31.68, RMSE=72.12, MAPE=2.33, MedAE=7.75, R2=0.983\n",
            "GROUNDNUT | GradientBoosting | with_network | Fold 3: MAE=41.82, RMSE=64.09, MAPE=3.61, MedAE=26.88, R2=0.987\n",
            "\n",
            "======================================================================\n",
            "PROCESSING COTTON\n",
            "======================================================================\n",
            "  Removing highly correlated features: ['DIVERSIFICATION_INDEX', 'net_strength']\n",
            "  Total features: 92, Network features: 5\n",
            "Saved supervised panel for COTTON to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/supervised_panel_cotton.csv\n",
            "\n",
            "COTTON | Naive | no_network | Fold 1: MAE=71.10, RMSE=121.12, MAPE=31.84, MedAE=38.65, R2=0.198\n",
            "COTTON | RollingMean3 | no_network | Fold 1: MAE=68.11, RMSE=112.33, MAPE=29.56, MedAE=36.19, R2=0.311\n",
            "COTTON | Ridge | no_network | Fold 1: MAE=86.49, RMSE=292.51, MAPE=34.60, MedAE=19.95, R2=-3.675\n",
            "COTTON | RandomForest | no_network | Fold 1: MAE=18.78, RMSE=32.21, MAPE=7.13, MedAE=7.01, R2=0.943\n",
            "COTTON | GradientBoosting | no_network | Fold 1: MAE=32.26, RMSE=49.72, MAPE=14.71, MedAE=15.46, R2=0.865\n",
            "COTTON | Ridge | with_network | Fold 1: MAE=93.00, RMSE=313.73, MAPE=37.52, MedAE=19.95, R2=-4.378\n",
            "COTTON | RandomForest | with_network | Fold 1: MAE=19.16, RMSE=32.73, MAPE=7.34, MedAE=6.96, R2=0.941\n",
            "COTTON | GradientBoosting | with_network | Fold 1: MAE=31.45, RMSE=49.86, MAPE=13.88, MedAE=13.71, R2=0.864\n",
            "COTTON | Naive | no_network | Fold 2: MAE=79.60, RMSE=122.92, MAPE=31.10, MedAE=50.47, R2=0.064\n",
            "COTTON | RollingMean3 | no_network | Fold 2: MAE=76.84, RMSE=115.91, MAPE=29.53, MedAE=49.19, R2=0.168\n",
            "COTTON | Ridge | no_network | Fold 2: MAE=9.39, RMSE=12.04, MAPE=3.91, MedAE=7.60, R2=0.991\n",
            "COTTON | RandomForest | no_network | Fold 2: MAE=7.39, RMSE=15.91, MAPE=2.62, MedAE=2.92, R2=0.984\n",
            "COTTON | GradientBoosting | no_network | Fold 2: MAE=10.59, RMSE=15.68, MAPE=4.05, MedAE=7.54, R2=0.985\n",
            "COTTON | Ridge | with_network | Fold 2: MAE=9.41, RMSE=12.10, MAPE=3.95, MedAE=7.74, R2=0.991\n",
            "COTTON | RandomForest | with_network | Fold 2: MAE=7.46, RMSE=16.05, MAPE=2.65, MedAE=2.97, R2=0.984\n",
            "COTTON | GradientBoosting | with_network | Fold 2: MAE=10.72, RMSE=15.94, MAPE=4.10, MedAE=7.45, R2=0.984\n",
            "COTTON | Naive | no_network | Fold 3: MAE=120.21, RMSE=181.90, MAPE=35.92, MedAE=72.80, R2=0.094\n",
            "COTTON | RollingMean3 | no_network | Fold 3: MAE=116.19, RMSE=165.18, MAPE=34.07, MedAE=77.97, R2=0.253\n",
            "COTTON | Ridge | no_network | Fold 3: MAE=8.72, RMSE=11.40, MAPE=2.48, MedAE=6.85, R2=0.996\n",
            "COTTON | RandomForest | no_network | Fold 3: MAE=14.51, RMSE=25.91, MAPE=3.38, MedAE=5.13, R2=0.982\n",
            "COTTON | GradientBoosting | no_network | Fold 3: MAE=16.36, RMSE=24.81, MAPE=4.36, MedAE=10.33, R2=0.983\n",
            "COTTON | Ridge | with_network | Fold 3: MAE=8.71, RMSE=11.43, MAPE=2.46, MedAE=6.90, R2=0.996\n",
            "COTTON | RandomForest | with_network | Fold 3: MAE=14.69, RMSE=26.14, MAPE=3.43, MedAE=5.24, R2=0.981\n",
            "COTTON | GradientBoosting | with_network | Fold 3: MAE=16.13, RMSE=24.13, MAPE=4.35, MedAE=10.32, R2=0.984\n",
            "\n",
            "======================================================================\n",
            "PROCESSING SUGARCANE\n",
            "======================================================================\n",
            "  Removing highly correlated features: ['DIVERSIFICATION_INDEX', 'net_strength']\n",
            "  Total features: 92, Network features: 5\n",
            "Saved supervised panel for SUGARCANE to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/supervised_panel_sugarcane.csv\n",
            "\n",
            "SUGARCANE | Naive | no_network | Fold 1: MAE=879.27, RMSE=1412.06, MAPE=19.91, MedAE=541.67, R2=0.713\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 1: MAE=862.56, RMSE=1329.42, MAPE=19.42, MedAE=558.70, R2=0.746\n",
            "SUGARCANE | Ridge | no_network | Fold 1: MAE=1615.02, RMSE=4792.35, MAPE=46.94, MedAE=452.96, R2=-2.301\n",
            "SUGARCANE | RandomForest | no_network | Fold 1: MAE=147.86, RMSE=333.57, MAPE=4.68, MedAE=60.33, R2=0.984\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 1: MAE=240.67, RMSE=352.10, MAPE=7.09, MedAE=172.39, R2=0.982\n",
            "SUGARCANE | Ridge | with_network | Fold 1: MAE=1725.44, RMSE=5170.16, MAPE=48.72, MedAE=454.78, R2=-2.842\n",
            "SUGARCANE | RandomForest | with_network | Fold 1: MAE=150.99, RMSE=340.26, MAPE=4.71, MedAE=61.14, R2=0.983\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 1: MAE=263.49, RMSE=374.87, MAPE=7.54, MedAE=196.38, R2=0.980\n",
            "SUGARCANE | Naive | no_network | Fold 2: MAE=909.99, RMSE=1545.62, MAPE=21.84, MedAE=500.57, R2=0.635\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 2: MAE=879.00, RMSE=1396.06, MAPE=22.86, MedAE=520.06, R2=0.702\n",
            "SUGARCANE | Ridge | no_network | Fold 2: MAE=271.56, RMSE=364.04, MAPE=9.72, MedAE=204.04, R2=0.980\n",
            "SUGARCANE | RandomForest | no_network | Fold 2: MAE=124.11, RMSE=316.67, MAPE=10.66, MedAE=39.01, R2=0.985\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 2: MAE=223.24, RMSE=346.80, MAPE=11.68, MedAE=138.57, R2=0.982\n",
            "SUGARCANE | Ridge | with_network | Fold 2: MAE=273.75, RMSE=366.44, MAPE=9.96, MedAE=206.87, R2=0.979\n",
            "SUGARCANE | RandomForest | with_network | Fold 2: MAE=124.75, RMSE=318.26, MAPE=10.57, MedAE=37.59, R2=0.985\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 2: MAE=221.79, RMSE=344.92, MAPE=11.54, MedAE=139.85, R2=0.982\n",
            "SUGARCANE | Naive | no_network | Fold 3: MAE=1165.32, RMSE=2012.30, MAPE=25.81, MedAE=559.26, R2=0.423\n",
            "SUGARCANE | RollingMean3 | no_network | Fold 3: MAE=1159.33, RMSE=1824.22, MAPE=26.81, MedAE=661.36, R2=0.526\n",
            "SUGARCANE | Ridge | no_network | Fold 3: MAE=233.98, RMSE=318.34, MAPE=9.50, MedAE=176.07, R2=0.986\n",
            "SUGARCANE | RandomForest | no_network | Fold 3: MAE=113.03, RMSE=265.93, MAPE=8.84, MedAE=35.83, R2=0.990\n",
            "SUGARCANE | GradientBoosting | no_network | Fold 3: MAE=243.28, RMSE=387.91, MAPE=15.58, MedAE=150.94, R2=0.979\n",
            "SUGARCANE | Ridge | with_network | Fold 3: MAE=233.59, RMSE=319.88, MAPE=9.47, MedAE=173.84, R2=0.985\n",
            "SUGARCANE | RandomForest | with_network | Fold 3: MAE=113.29, RMSE=268.43, MAPE=8.94, MedAE=35.67, R2=0.990\n",
            "SUGARCANE | GradientBoosting | with_network | Fold 3: MAE=251.07, RMSE=385.84, MAPE=15.94, MedAE=161.97, R2=0.979\n",
            "\n",
            "Saved per-fold model results to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/model_per_fold_raw.csv\n",
            "Saved model performance summary to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/model_performance_summary.csv\n",
            "\n",
            "\n",
            "===== STATISTICAL SIGNIFICANCE TESTS =====\n",
            "RICE: GB with_network vs no_network: Improvement=-0.67%, p=0.5895\n",
            "RICE: GB with_network vs Naive: Improvement=79.97%, p=0.0007\n",
            "WHEAT: GB with_network vs no_network: Improvement=-0.60%, p=0.4656\n",
            "WHEAT: GB with_network vs Naive: Improvement=77.93%, p=0.0080\n",
            "MAIZE: GB with_network vs no_network: Improvement=0.01%, p=0.9390\n",
            "MAIZE: GB with_network vs Naive: Improvement=84.72%, p=0.0076\n",
            "GROUNDNUT: GB with_network vs no_network: Improvement=0.17%, p=0.8320\n",
            "GROUNDNUT: GB with_network vs Naive: Improvement=83.28%, p=0.0025\n",
            "COTTON: GB with_network vs no_network: Improvement=1.54%, p=0.3812\n",
            "COTTON: GB with_network vs Naive: Improvement=78.48%, p=0.0627\n",
            "SUGARCANE: GB with_network vs no_network: Improvement=-4.13%, p=0.3028\n",
            "SUGARCANE: GB with_network vs Naive: Improvement=75.08%, p=0.0145\n",
            "\n",
            "Saved statistical tests to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/statistical_significance_tests.csv\n",
            "\n",
            "\n",
            "===== TEMPORAL STABILITY ANALYSIS =====\n",
            "RICE: MAE slope=-3.87 (trend R=0.232), R slope=0.0066\n",
            "WHEAT: MAE slope=8.92 (trend R=0.802), R slope=0.0045\n",
            "MAIZE: MAE slope=2.35 (trend R=0.038), R slope=0.0099\n",
            "GROUNDNUT: MAE slope=-9.88 (trend R=0.556), R slope=0.0272\n",
            "COTTON: MAE slope=-7.66 (trend R=0.508), R slope=0.0600\n",
            "SUGARCANE: MAE slope=-6.21 (trend R=0.084), R slope=-0.0005\n",
            "\n",
            "Saved temporal stability analysis to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/temporal_stability_analysis.csv\n",
            "\n",
            "\n",
            "===== FEATURE IMPORTANCE ANALYSIS =====\n",
            "RICE: Network features contribute 0.1% of total importance\n",
            "WHEAT: Network features contribute 0.2% of total importance\n",
            "MAIZE: Network features contribute 0.0% of total importance\n",
            "GROUNDNUT: Network features contribute 0.0% of total importance\n",
            "COTTON: Network features contribute 0.3% of total importance\n",
            "SUGARCANE: Network features contribute 0.9% of total importance\n",
            "\n",
            "Saved feature importance to: /content/drive/MyDrive/Shiny/ICRISAT/Results1/feature_importance_summary.csv\n",
            "\n",
            "\n",
            "Performance summary for RICE (no_network):\n",
            "Crop            Model FeatureSet   MAE_mean    MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "RICE     RandomForest no_network  35.658242   9.739312  87.906845  22.906591   2.670542  1.152711   12.105322   3.004331 0.988148 0.008080\n",
            "RICE GradientBoosting no_network  57.108590   7.678731  90.535270  20.751536   4.503671  1.120503   37.879397   2.824866 0.987478 0.008318\n",
            "RICE            Ridge no_network 107.428759 123.311702 363.365821 540.873959  10.117457 13.238964   36.482357  17.267550 0.440335 0.963737\n",
            "RICE     RollingMean3 no_network 263.634126  21.445324 373.151037  40.123647  21.159430  3.974712  187.521111  15.245244 0.807501 0.027731\n",
            "RICE            Naive no_network 287.081819   7.997375 417.385413  37.429195  23.481378  4.864414  193.183333  13.988904 0.759860 0.019068\n",
            "\n",
            "Performance summary for RICE (with_network):\n",
            "Crop            Model   FeatureSet  MAE_mean    MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "RICE     RandomForest with_network 35.875551   9.870445  88.233480  22.786981   2.687989  1.166796   12.270128   3.001521 0.988067 0.008115\n",
            "RICE GradientBoosting with_network 57.492082   8.043693  91.119438  20.325035   4.540064  1.169464   38.076384   3.181869 0.987402 0.008077\n",
            "RICE            Ridge with_network 95.798042 101.190132 318.418043 460.536114   8.711182 10.691004   37.144292  16.488579 0.584805 0.713182\n",
            "\n",
            "Performance summary for WHEAT (no_network):\n",
            " Crop            Model FeatureSet   MAE_mean   MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "WHEAT     RandomForest no_network  53.986953 13.736925 133.118694  35.366210   2.807426  0.860103   13.318572   2.760145 0.975874 0.013576\n",
            "WHEAT GradientBoosting no_network  62.955461 10.476458 108.538403  12.851236   3.655961  0.474457   36.379974   4.478423 0.984906 0.003918\n",
            "WHEAT            Ridge no_network  79.227037 81.322879 203.233166 274.244609   7.477160  9.712140   31.399061  11.975535 0.832303 0.286758\n",
            "WHEAT     RollingMean3 no_network 269.123518 47.886907 377.526100  74.301262  17.413507  1.456230  191.650000  26.629871 0.820940 0.038598\n",
            "WHEAT            Naive no_network 287.017619 44.764259 414.757573  71.993420  18.805498  1.282566  198.195000  22.185514 0.784225 0.036804\n",
            "\n",
            "Performance summary for WHEAT (with_network):\n",
            " Crop            Model   FeatureSet  MAE_mean   MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std  R2_mean   R2_std\n",
            "WHEAT     RandomForest with_network 54.083442 13.724549 133.549585  35.438298   2.769456  0.785888   13.046983   2.185127 0.975688 0.013768\n",
            "WHEAT GradientBoosting with_network 63.335909  9.956367 111.984139  12.322263   3.643387  0.437263   36.134976   4.775213 0.983628 0.005817\n",
            "WHEAT            Ridge with_network 75.740377 75.114511 191.329848 253.330663   7.176997  9.170077   32.527905  13.713843 0.854556 0.248195\n",
            "\n",
            "Performance summary for MAIZE (no_network):\n",
            " Crop            Model FeatureSet   MAE_mean    MAE_std  RMSE_mean    RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "MAIZE     RandomForest no_network  58.225309  22.943507 163.370561   43.920099   2.919203  1.240240   13.301350   3.826197  0.970972 0.009002\n",
            "MAIZE GradientBoosting no_network  67.416365  11.857897 117.199397   17.665164   4.569868  1.623732   40.387071   5.631919  0.983058 0.010618\n",
            "MAIZE            Ridge no_network 244.826778 366.005694 933.867207 1531.895032  17.591124 27.073870   40.525577  29.512875 -3.316696 7.472597\n",
            "MAIZE     RollingMean3 no_network 411.349292  67.384159 624.994844  117.269443  28.454403  5.586437  272.011111  28.027403  0.564622 0.132270\n",
            "MAIZE            Naive no_network 441.257157  63.037447 684.542954  114.981911  30.949536  4.930064  280.456667  20.061139  0.474318 0.160853\n",
            "\n",
            "Performance summary for MAIZE (with_network):\n",
            " Crop            Model   FeatureSet   MAE_mean    MAE_std  RMSE_mean    RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "MAIZE     RandomForest with_network  58.389415  22.798856 163.403001   43.304869   2.935621  1.246863   13.326256   3.949973  0.970977 0.008697\n",
            "MAIZE GradientBoosting with_network  67.408391  12.007379 117.510846   16.793431   4.564290  1.630622   40.297645   5.987703  0.983025 0.010374\n",
            "MAIZE            Ridge with_network 240.095406 356.086643 920.189778 1505.862070  17.222838 26.331676   42.270201  31.517417 -3.178250 7.232584\n",
            "\n",
            "Performance summary for GROUNDNUT (no_network):\n",
            "     Crop            Model FeatureSet   MAE_mean    MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "GROUNDNUT     RandomForest no_network  41.813035  23.863837  87.165729  33.548735   4.564445  3.648587   14.323511  11.145984  0.946308 0.056798\n",
            "GROUNDNUT GradientBoosting no_network  46.675462  13.499284  72.870592  19.612342   5.401800  2.442721   30.078788   8.705056  0.965557 0.029758\n",
            "GROUNDNUT            Ridge no_network 149.119302 187.576485 395.352455 592.592391  19.893799 27.625648   52.847911  35.362374 -1.940646 5.069409\n",
            "GROUNDNUT     RollingMean3 no_network 258.095792   5.476529 361.554540   8.484762  28.252496  5.240936  187.533889   5.217050  0.265656 0.279370\n",
            "GROUNDNUT            Naive no_network 278.698410   6.917361 410.438178  18.573352  30.946878  4.681659  187.663333  10.544313  0.068172 0.298337\n",
            "\n",
            "Performance summary for GROUNDNUT (with_network):\n",
            "     Crop            Model   FeatureSet   MAE_mean    MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "GROUNDNUT     RandomForest with_network  42.105022  24.123231  87.457147  34.184782   4.593677  3.682887   14.591983  11.647757  0.945734 0.057919\n",
            "GROUNDNUT GradientBoosting with_network  46.597739  13.252310  72.444017  19.513666   5.349162  2.418549   30.297755   8.858714  0.965952 0.029431\n",
            "GROUNDNUT            Ridge with_network 149.226570 187.501442 404.209504 607.603432  19.928043 27.670610   53.387023  36.205773 -2.084677 5.318666\n",
            "\n",
            "Performance summary for COTTON (no_network):\n",
            "  Crop            Model FeatureSet  MAE_mean   MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "COTTON     RandomForest no_network 13.558936  5.757137  24.678282   8.222745   4.377140  2.412671    5.018001   2.044078  0.969748 0.022943\n",
            "COTTON GradientBoosting no_network 19.735525 11.223560  30.070960  17.622887   7.707169  6.066715   11.111445   4.017840  0.944276 0.068743\n",
            "COTTON            Ridge no_network 34.866878 44.707887 105.319049 162.115384  13.663287 18.146293   11.468907   7.354404 -0.562538 2.695536\n",
            "COTTON     RollingMean3 no_network 87.045468 25.612253 131.140202  29.534641  31.053644  2.613074   54.452222  21.383443  0.243815 0.071785\n",
            "COTTON            Naive no_network 90.302896 26.248544 141.980352  34.585180  32.954443  2.595697   53.973333  17.345671  0.118915 0.070520\n",
            "\n",
            "Performance summary for COTTON (with_network):\n",
            "  Crop            Model   FeatureSet  MAE_mean   MAE_std  RMSE_mean   RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "COTTON     RandomForest with_network 13.771382  5.902017  24.971564   8.397619   4.473373  2.510873    5.057410   1.999210  0.968941 0.023816\n",
            "COTTON GradientBoosting with_network 19.431418 10.754718  29.977448  17.701000   7.444237  5.575496   10.494116   3.137001  0.944160 0.069284\n",
            "COTTON            Ridge with_network 37.037892 48.462674 112.418430 174.342502  14.644159 19.826159   11.527822   7.307919 -0.796847 3.101287\n",
            "\n",
            "Performance summary for SUGARCANE (no_network):\n",
            "     Crop            Model FeatureSet   MAE_mean    MAE_std   RMSE_mean    RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "SUGARCANE     RandomForest no_network 128.332403  17.796218  305.390869   35.206130   8.061311  3.070556   45.055244  13.324626  0.986200 0.003249\n",
            "SUGARCANE GradientBoosting no_network 235.729484  10.896846  362.268000   22.362471  11.449318  4.250141  153.967936  17.113445  0.980788 0.001935\n",
            "SUGARCANE            Ridge no_network 706.854547 786.721868 1824.906725 2569.978891  22.055278 21.552607  277.690190 152.433867 -0.112004 1.896002\n",
            "SUGARCANE     RollingMean3 no_network 966.964358 166.797985 1516.566183  268.510097  23.029916  3.694056  580.038889  73.026207  0.658031 0.116251\n",
            "SUGARCANE            Naive no_network 984.857837 157.033767 1656.657328  315.149133  22.517180  3.008027  533.833333  30.119579  0.590504 0.149898\n",
            "\n",
            "Performance summary for SUGARCANE (with_network):\n",
            "     Crop            Model   FeatureSet   MAE_mean    MAE_std   RMSE_mean    RMSE_std  MAPE_mean  MAPE_std  MedAE_mean  MedAE_std   R2_mean   R2_std\n",
            "SUGARCANE     RandomForest with_network 129.676838  19.326294  308.987323   36.802312   8.075126  3.027208   44.799439  14.183968  0.985869 0.003403\n",
            "SUGARCANE GradientBoosting with_network 245.453515  21.409931  368.544715   21.179401  11.673877  4.198490  166.068542  28.483936  0.980136 0.001528\n",
            "SUGARCANE            Ridge with_network 744.261959 849.964671 1952.159702 2786.963239  22.717262 22.521310  278.495389 153.555915 -0.292488 2.208255\n",
            "\n",
            "======================================================================\n",
            "FINAL SUMMARY (BEST ADVANCED MODELS)\n",
            "======================================================================\n",
            "  COTTON: RandomForest (with_network) | MAE=13.77 (5.90), R=0.969 (0.024)\n",
            "  GROUNDNUT: RandomForest (with_network) | MAE=42.11 (24.12), R=0.946 (0.058)\n",
            "  MAIZE: RandomForest (with_network) | MAE=58.39 (22.80), R=0.971 (0.009)\n",
            "  RICE: RandomForest (with_network) | MAE=35.88 (9.87), R=0.988 (0.008)\n",
            "  SUGARCANE: RandomForest (with_network) | MAE=129.68 (19.33), R=0.986 (0.003)\n",
            "  WHEAT: RandomForest (with_network) | MAE=54.08 (13.72), R=0.976 (0.014)\n",
            "\n",
            "======================================================================\n",
            "GENERATING ENHANCED DIAGNOSTIC PLOTS\n",
            "======================================================================\n",
            "Saved enhanced diagnostic plots for COTTON (RandomForest, with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results1.\n",
            "Saved enhanced diagnostic plots for GROUNDNUT (RandomForest, with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results1.\n",
            "Saved enhanced diagnostic plots for MAIZE (RandomForest, with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results1.\n",
            "Saved enhanced diagnostic plots for RICE (RandomForest, with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results1.\n",
            "Saved enhanced diagnostic plots for SUGARCANE (RandomForest, with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results1.\n",
            "Saved enhanced diagnostic plots for WHEAT (RandomForest, with_network) to /content/drive/MyDrive/Shiny/ICRISAT/Results1.\n",
            "\n",
            "======================================================================\n",
            "PIPELINE COMPLETE\n",
            "======================================================================\n",
            "Rows after cleaning: 16146\n",
            "Years: 1966 - 2017\n",
            "Districts: 311\n",
            "Crops modeled: ['RICE', 'WHEAT', 'MAIZE', 'GROUNDNUT', 'COTTON', 'SUGARCANE']\n",
            "\n",
            "Key outputs:\n",
            "  - Cleaned dataset: /content/drive/MyDrive/Shiny/ICRISAT/Results1/icrisat_cleaned_with_features.csv\n",
            "  - Performance summary: /content/drive/MyDrive/Shiny/ICRISAT/Results1/model_performance_summary.csv\n",
            "  - Statistical tests: /content/drive/MyDrive/Shiny/ICRISAT/Results1/statistical_significance_tests.csv\n",
            "  - Temporal stability: /content/drive/MyDrive/Shiny/ICRISAT/Results1/temporal_stability_analysis.csv\n",
            "  - Feature importance: /content/drive/MyDrive/Shiny/ICRISAT/Results1/feature_importance_summary.csv\n",
            "  - Best models: /content/drive/MyDrive/Shiny/ICRISAT/Results1/best_models_advanced_only.csv\n",
            "  - Diagnostic plots: /content/drive/MyDrive/Shiny/ICRISAT/Results1/*.pdf\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import warnings\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "\n",
        "from scipy import stats\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# CONFIG\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "RAW_CSV_PATH = \"/content/drive/MyDrive/Shiny/ICRISAT/Data/icrisat_raw.csv\"\n",
        "CLEANED_CSV_PATH = \"/content/drive/MyDrive/Shiny/ICRISAT/Results1/icrisat_cleaned_with_features.csv\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Shiny/ICRISAT/Results1\"\n",
        "\n",
        "SUPERVISED_PANEL_PREFIX = os.path.join(OUTPUT_DIR, \"supervised_panel_\")\n",
        "MODEL_PER_FOLD_CSV = os.path.join(OUTPUT_DIR, \"model_per_fold_raw.csv\")\n",
        "MODEL_PERF_SUMMARY_CSV = os.path.join(OUTPUT_DIR, \"model_performance_summary.csv\")\n",
        "BEST_MODELS_CSV = os.path.join(OUTPUT_DIR, \"best_models_advanced_only.csv\")\n",
        "FEATURE_IMPORTANCE_CSV = os.path.join(OUTPUT_DIR, \"feature_importance_summary.csv\")\n",
        "STATISTICAL_TESTS_CSV = os.path.join(OUTPUT_DIR, \"statistical_significance_tests.csv\")\n",
        "TEMPORAL_STABILITY_CSV = os.path.join(OUTPUT_DIR, \"temporal_stability_analysis.csv\")\n",
        "\n",
        "CROPS = [\"RICE\", \"WHEAT\", \"MAIZE\", \"GROUNDNUT\", \"COTTON\", \"SUGARCANE\"]\n",
        "RANDOM_STATE = 42\n",
        "N_FOLDS = 3\n",
        "\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# UTILS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def safe_mape(y_true: np.ndarray, y_pred: np.ndarray, min_threshold: float = 100.0) -> float:\n",
        "    \"\"\"\n",
        "    Mean Absolute Percentage Error in %, with minimum threshold to avoid\n",
        "    division by near-zero values (especially important for cotton).\n",
        "    \"\"\"\n",
        "    y_true = np.array(y_true, dtype=float)\n",
        "    y_pred = np.array(y_pred, dtype=float)\n",
        "    mask = y_true > min_threshold\n",
        "    if not np.any(mask):\n",
        "        return np.nan\n",
        "    return np.mean(np.abs(y_true[mask] - y_pred[mask]) / y_true[mask]) * 100.0\n",
        "\n",
        "\n",
        "def median_ae(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
        "    return float(np.median(np.abs(np.array(y_true) - np.array(y_pred))))\n",
        "\n",
        "\n",
        "def safe_print(*args, **kwargs):\n",
        "    try:\n",
        "        print(*args, **kwargs)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# LOADING + BASIC EDA\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def load_data() -> Tuple[pd.DataFrame, str]:\n",
        "    if os.path.exists(RAW_CSV_PATH):\n",
        "        safe_print(f\"RAW_CSV_PATH found: {RAW_CSV_PATH}\")\n",
        "        df = pd.read_csv(RAW_CSV_PATH)\n",
        "        source_type = \"raw\"\n",
        "    elif os.path.exists(CLEANED_CSV_PATH):\n",
        "        safe_print(\"RAW_CSV_PATH not found.\")\n",
        "        safe_print(f\"Falling back to existing CLEANED dataset: {CLEANED_CSV_PATH}\\n\")\n",
        "        df = pd.read_csv(CLEANED_CSV_PATH)\n",
        "        source_type = \"cleaned\"\n",
        "    else:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Neither raw ({RAW_CSV_PATH}) nor cleaned ({CLEANED_CSV_PATH}) dataset is available.\"\n",
        "        )\n",
        "    return df, source_type\n",
        "\n",
        "\n",
        "def basic_eda(df: pd.DataFrame) -> None:\n",
        "    safe_print(\"===== BASIC EDA =====\")\n",
        "    key_cols = [\"Dist Code\", \"Year\"]\n",
        "    if all(k in df.columns for k in key_cols):\n",
        "        dup = df.duplicated(subset=key_cols).sum()\n",
        "        safe_print(f\"Duplicate (Dist Code, Year) rows: {dup}\")\n",
        "        safe_print(f\"Key (Dist Code, Year) is {'NOT ' if dup>0 else ''}unique.\\n\")\n",
        "\n",
        "    safe_print(f\"Rows: {len(df):d}, Columns: {df.shape[1]:d}\")\n",
        "\n",
        "    if \"Year\" in df.columns:\n",
        "        safe_print(f\"Time range: {int(df['Year'].min())} - {int(df['Year'].max())}\")\n",
        "\n",
        "    state_cols = [c for c in df.columns if \"STATE\" in c.upper() or \"STATE NAME\" in c.upper()]\n",
        "    if state_cols:\n",
        "        safe_print(f\"Unique States: {df[state_cols[0]].nunique()}\")\n",
        "\n",
        "    yield_cols = [c for c in df.columns if \"YIELD (Kg per ha)\" in c]\n",
        "    crops = sorted(list({c.split(\" YIELD\")[0].strip() for c in yield_cols}))\n",
        "    safe_print(f\"Detected crops (count={len(crops)}): {crops[:23]}...\\n\")\n",
        "\n",
        "    if yield_cols:\n",
        "        miss_info = pd.DataFrame({\n",
        "            \"YieldColumn\": yield_cols,\n",
        "            \"MissingPct\": [df[col].isna().mean() * 100.0 for col in yield_cols],\n",
        "        }).sort_values(\"MissingPct\").reset_index(drop=True)\n",
        "        safe_print(\"Yield missingness (% of NaN):\")\n",
        "        safe_print(miss_info.to_string(index=False))\n",
        "        safe_print()\n",
        "\n",
        "        for col in [\"RICE YIELD (Kg per ha)\", \"WHEAT YIELD (Kg per ha)\",\n",
        "                    \"MAIZE YIELD (Kg per ha)\", \"GROUNDNUT YIELD (Kg per ha)\",\n",
        "                    \"COTTON YIELD (Kg per ha)\", \"SUGARCANE YIELD (Kg per ha)\"]:\n",
        "            if col in df.columns:\n",
        "                safe_print(f\"Summary for {col.split(' YIELD')[0]} yield:\")\n",
        "                safe_print(df[col].describe())\n",
        "                safe_print()\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# CLEANING YIELDS + DIVERSIFICATION\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def clean_yields(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    safe_print(\"===== CLEANING DATA =====\")\n",
        "    df = df.copy()\n",
        "    yield_cols = [c for c in df.columns if \"YIELD (Kg per ha)\" in c]\n",
        "\n",
        "    for col in yield_cols:\n",
        "        s = df[col].copy()\n",
        "        old_max = s.max()\n",
        "        s = s.clip(lower=0)\n",
        "        if (s > 0).sum() > 0:\n",
        "            q = s[s > 0].quantile(0.995)\n",
        "            s = s.clip(upper=q)\n",
        "            new_max = float(s.max())\n",
        "            if new_max < old_max:\n",
        "                safe_print(f\"Clipped {col.split(' YIELD')[0]} yield: \"\n",
        "                          f\"old max={old_max:.2f}, new max={new_max:.2f}\")\n",
        "        df[col] = s\n",
        "\n",
        "    safe_print()\n",
        "    return df\n",
        "\n",
        "\n",
        "def compute_diversification_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    safe_print(\"===== COMPUTING DIVERSIFICATION =====\")\n",
        "    df = df.copy()\n",
        "\n",
        "    yield_cols = [c for c in df.columns if \"YIELD (Kg per ha)\" in c]\n",
        "    crop_names = [c.split(\" YIELD\")[0].strip() for c in yield_cols]\n",
        "\n",
        "    crop_area_cols = {}\n",
        "    for crop in crop_names:\n",
        "        candidates = [c for c in df.columns if crop in c and \"AREA\" in c.upper()]\n",
        "        if candidates:\n",
        "            crop_area_cols[crop] = candidates[0]\n",
        "\n",
        "    if not crop_area_cols:\n",
        "        safe_print(\"No AREA columns detected  diversification features will be zeros.\\n\")\n",
        "        df[\"diversity_simpson\"] = 0.0\n",
        "        df[\"num_active_crops\"] = 0\n",
        "        return df\n",
        "\n",
        "    area_mat = df[[crop_area_cols[c] for c in crop_area_cols]].fillna(0.0).values\n",
        "    total_area = area_mat.sum(axis=1)\n",
        "    total_area_safe = np.where(total_area == 0, 1.0, total_area)\n",
        "    shares = area_mat / total_area_safe[:, None]\n",
        "    hhi = (shares ** 2).sum(axis=1)\n",
        "    simpson = 1.0 - hhi\n",
        "    num_active = (area_mat > 0).sum(axis=1)\n",
        "\n",
        "    df[\"diversity_simpson\"] = simpson\n",
        "    df[\"num_active_crops\"] = num_active\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# ENHANCED NETWORK CONSTRUCTION\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def build_district_network(df: pd.DataFrame) -> Tuple[nx.Graph, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    IMPROVED: Build district similarity network with:\n",
        "    - Higher correlation threshold (0.80) for meaningful connections\n",
        "    - Top-k pruning to maintain sparse, interpretable network\n",
        "    - Additional centrality measures\n",
        "    \"\"\"\n",
        "    safe_print(\"===== BUILDING ENHANCED DISTRICT SIMILARITY NETWORK =====\")\n",
        "    df_ref = df.copy()\n",
        "    if \"Year\" in df_ref.columns:\n",
        "        df_ref = df_ref[(df_ref[\"Year\"] >= 2008) & (df_ref[\"Year\"] <= 2017)]\n",
        "\n",
        "    if \"Dist Code\" not in df_ref.columns:\n",
        "        safe_print(\"No 'Dist Code' column: cannot build district network.\")\n",
        "        return nx.Graph(), pd.DataFrame(columns=[\"Dist Code\"])\n",
        "\n",
        "    yield_cols = [c for c in df_ref.columns if \"YIELD (Kg per ha)\" in c]\n",
        "    if not yield_cols:\n",
        "        safe_print(\"No YIELD columns found: cannot build district network.\")\n",
        "        return nx.Graph(), pd.DataFrame(columns=[\"Dist Code\"])\n",
        "\n",
        "    # Aggregate to district-level mean yields\n",
        "    prof = df_ref.groupby(\"Dist Code\")[yield_cols].mean().fillna(0.0)\n",
        "\n",
        "    if prof.shape[0] == 0:\n",
        "        safe_print(\"No district profiles after filtering.\")\n",
        "        return nx.Graph(), pd.DataFrame(columns=[\"Dist Code\"])\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    arr = prof.values\n",
        "    norms = np.linalg.norm(arr, axis=1)\n",
        "    norms_safe = np.where(norms == 0, 1.0, norms)\n",
        "    arr_norm = arr / norms_safe[:, None]\n",
        "    sim = arr_norm @ arr_norm.T\n",
        "\n",
        "    dist_codes = prof.index.tolist()\n",
        "    G = nx.Graph()\n",
        "    for di in dist_codes:\n",
        "        G.add_node(di)\n",
        "\n",
        "    # IMPROVED: Higher threshold for more meaningful connections\n",
        "    threshold = 0.80\n",
        "    n = sim.shape[0]\n",
        "    edges_added = []\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            w = float(sim[i, j])\n",
        "            if w >= threshold:\n",
        "                edges_added.append((dist_codes[i], dist_codes[j], w))\n",
        "\n",
        "    # IMPROVED: Keep only top-k strongest edges per node\n",
        "    max_edges_per_node = 15\n",
        "    node_edges = {node: [] for node in dist_codes}\n",
        "\n",
        "    for d1, d2, w in edges_added:\n",
        "        node_edges[d1].append((d2, w))\n",
        "        node_edges[d2].append((d1, w))\n",
        "\n",
        "    for node in dist_codes:\n",
        "        edges = sorted(node_edges[node], key=lambda x: x[1], reverse=True)[:max_edges_per_node]\n",
        "        for neighbor, weight in edges:\n",
        "            if not G.has_edge(node, neighbor):\n",
        "                G.add_edge(node, neighbor, weight=weight)\n",
        "\n",
        "    density = nx.density(G) if G.number_of_nodes() > 0 else 0.0\n",
        "    safe_print(f\"Network reference window: 2008-2017\")\n",
        "    safe_print(f\"District network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
        "    safe_print(f\"Network density: {density:.1%} (target: 5-20%)\\n\")\n",
        "\n",
        "    if G.number_of_nodes() == 0:\n",
        "        return G, pd.DataFrame(columns=[\"Dist Code\"])\n",
        "\n",
        "    # IMPROVED: Multiple centrality measures\n",
        "    deg = dict(G.degree())\n",
        "    strength = {n: sum(d[\"weight\"] for _, _, d in G.edges(n, data=True)) for n in G.nodes}\n",
        "\n",
        "    # Only compute closeness/betweenness if network is connected enough\n",
        "    if nx.is_connected(G):\n",
        "        closeness = nx.closeness_centrality(G)\n",
        "        betw = nx.betweenness_centrality(G, normalized=True)\n",
        "    else:\n",
        "        # For disconnected graphs, compute per component\n",
        "        closeness = {}\n",
        "        betw = {}\n",
        "        for component in nx.connected_components(G):\n",
        "            subG = G.subgraph(component)\n",
        "            comp_close = nx.closeness_centrality(subG)\n",
        "            comp_betw = nx.betweenness_centrality(subG, normalized=True)\n",
        "            closeness.update(comp_close)\n",
        "            betw.update(comp_betw)\n",
        "\n",
        "    eigenvector = nx.eigenvector_centrality(G, max_iter=1000, weight='weight')\n",
        "    clustering = nx.clustering(G, weight='weight')\n",
        "\n",
        "    dist_features = pd.DataFrame({\n",
        "        \"Dist Code\": list(G.nodes),\n",
        "        \"net_degree\": [deg[d] for d in G.nodes],\n",
        "        \"net_strength\": [strength[d] for d in G.nodes],\n",
        "        \"net_closeness\": [closeness[d] for d in G.nodes],\n",
        "        \"net_betweenness\": [betw[d] for d in G.nodes],\n",
        "        \"net_eigenvector\": [eigenvector[d] for d in G.nodes],\n",
        "        \"net_clustering\": [clustering[d] for d in G.nodes],\n",
        "    })\n",
        "\n",
        "    return G, dist_features\n",
        "\n",
        "\n",
        "def build_crop_cooccurrence_network(df: pd.DataFrame) -> nx.Graph:\n",
        "    safe_print(\"===== BUILDING CROP-COOCCURRENCE NETWORK =====\")\n",
        "    yield_cols = [c for c in df.columns if \"YIELD (Kg per ha)\" in c]\n",
        "    if not yield_cols:\n",
        "        safe_print(\"No YIELD columns, skipping crop network.\\n\")\n",
        "        return nx.Graph()\n",
        "\n",
        "    crop_names = [c.split(\" YIELD\")[0].strip() for c in yield_cols]\n",
        "    crop_idx = {col: crop_names[i] for i, col in enumerate(yield_cols)}\n",
        "\n",
        "    G = nx.Graph()\n",
        "    for crop in crop_names:\n",
        "        G.add_node(crop)\n",
        "\n",
        "    key_cols = [c for c in [\"Dist Code\", \"Year\"] if c in df.columns]\n",
        "    if not key_cols:\n",
        "        rows = [df]\n",
        "    else:\n",
        "        rows = [g for _, g in df.groupby(key_cols)]\n",
        "\n",
        "    from itertools import combinations\n",
        "\n",
        "    for sub in rows:\n",
        "        vals = sub[yield_cols].fillna(0.0)\n",
        "        active_mask = (vals > 0).any(axis=0)\n",
        "        active_cols = [c for c, m in zip(yield_cols, active_mask) if m]\n",
        "        active_crops = [crop_idx[c] for c in active_cols]\n",
        "        for c1, c2 in combinations(sorted(set(active_crops)), 2):\n",
        "            if G.has_edge(c1, c2):\n",
        "                G[c1][c2][\"weight\"] += 1\n",
        "            else:\n",
        "                G.add_edge(c1, c2, weight=1)\n",
        "\n",
        "    safe_print(f\"Crop network: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\\n\")\n",
        "    return G\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# SUPERVISED PANEL PREPARATION WITH FEATURE ENGINEERING\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def prepare_panel_for_crop(df: pd.DataFrame, crop: str) -> Tuple[pd.DataFrame, str, List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    IMPROVED: Enhanced feature engineering with:\n",
        "    - Robust handling of multicollinearity\n",
        "    - Removal of near-zero variance features\n",
        "    - Proper scaling indicators\n",
        "    \"\"\"\n",
        "    yield_candidates = [c for c in df.columns if c.startswith(crop) and \"YIELD (Kg per ha)\" in c]\n",
        "    if not yield_candidates:\n",
        "        raise ValueError(f\"Yield column for crop '{crop}' not found.\")\n",
        "    yield_col = yield_candidates[0]\n",
        "\n",
        "    if \"Dist Code\" not in df.columns or \"Year\" not in df.columns:\n",
        "        raise ValueError(\"Both 'Dist Code' and 'Year' must be present in the dataset.\")\n",
        "\n",
        "    panel = df.copy()\n",
        "    panel = panel.sort_values([\"Dist Code\", \"Year\"])\n",
        "    grp = panel.groupby(\"Dist Code\")[yield_col]\n",
        "\n",
        "    # Temporal features\n",
        "    panel[f\"{crop}_lag1\"] = grp.shift(1)\n",
        "    panel[f\"{crop}_lag2\"] = grp.shift(2)\n",
        "    panel[f\"{crop}_lag3\"] = grp.shift(3)\n",
        "    panel[f\"{crop}_roll3\"] = grp.shift(1).rolling(window=3, min_periods=1).mean()\n",
        "\n",
        "    # IMPROVED: Year-over-year change\n",
        "    panel[f\"{crop}_yoy_change\"] = grp.diff(1)\n",
        "\n",
        "    # IMPROVED: Volatility measure (rolling std)\n",
        "    panel[f\"{crop}_roll3_std\"] = grp.shift(1).rolling(window=3, min_periods=2).std()\n",
        "\n",
        "    excluded = {\"Dist Code\", \"Year\", yield_col}\n",
        "    feature_cols = []\n",
        "    for col in panel.columns:\n",
        "        if col in excluded:\n",
        "            continue\n",
        "        if np.issubdtype(panel[col].dtype, np.number):\n",
        "            # IMPROVED: Check for near-zero variance\n",
        "            if panel[col].std() > 1e-6:\n",
        "                feature_cols.append(col)\n",
        "            else:\n",
        "                safe_print(f\"  Excluding near-zero variance feature: {col}\")\n",
        "\n",
        "    # IMPROVED: Check for perfect multicollinearity\n",
        "    numeric_panel = panel[feature_cols].fillna(0.0)\n",
        "    corr_matrix = numeric_panel.corr().abs()\n",
        "\n",
        "    # Find highly correlated pairs\n",
        "    upper_tri = corr_matrix.where(\n",
        "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
        "    )\n",
        "    to_drop = [col for col in upper_tri.columns if any(upper_tri[col] > 0.99)]\n",
        "\n",
        "    if to_drop:\n",
        "        safe_print(f\"  Removing highly correlated features: {to_drop}\")\n",
        "        feature_cols = [c for c in feature_cols if c not in to_drop]\n",
        "\n",
        "    network_feature_cols = [\n",
        "        c for c in feature_cols\n",
        "        if c.lower().startswith(\"net_\")\n",
        "        or \"network\" in c.lower()\n",
        "        or \"centrality\" in c.lower()\n",
        "    ]\n",
        "\n",
        "    safe_print(f\"  Total features: {len(feature_cols)}, Network features: {len(network_feature_cols)}\")\n",
        "\n",
        "    return panel, yield_col, feature_cols, network_feature_cols\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# TIME-SERIES CROSS-VALIDATION SPLITS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def time_series_folds(years: np.ndarray, n_folds: int = N_FOLDS) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
        "    years_unique = np.sort(np.unique(years))\n",
        "    n_years = len(years_unique)\n",
        "    if n_years < n_folds + 1:\n",
        "        warnings.warn(f\"Too few years ({n_years}) for {n_folds} folds; using single split.\")\n",
        "        mid = n_years // 2\n",
        "        return [(years_unique[:mid], years_unique[mid:])]\n",
        "\n",
        "    split_indices = [int((i + 1) * n_years / (n_folds + 1)) for i in range(n_folds)]\n",
        "\n",
        "    folds = []\n",
        "    for i in range(n_folds):\n",
        "        train_end_idx = split_indices[i]\n",
        "        test_start_idx = train_end_idx\n",
        "        test_end_idx = split_indices[i + 1] if i + 1 < len(split_indices) else n_years\n",
        "\n",
        "        train_years = years_unique[:train_end_idx]\n",
        "        test_years = years_unique[test_start_idx:test_end_idx]\n",
        "        if len(train_years) == 0 or len(test_years) == 0:\n",
        "            continue\n",
        "        folds.append((train_years, test_years))\n",
        "\n",
        "    return folds\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# IMPROVED MODEL TRAINING WITH ROBUST RIDGE\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def create_robust_ridge(alpha: float = 10.0) -> Ridge:\n",
        "    \"\"\"IMPROVED: Ridge with higher regularization to handle multicollinearity\"\"\"\n",
        "    return Ridge(alpha=alpha, max_iter=10000, random_state=RANDOM_STATE)\n",
        "\n",
        "\n",
        "def evaluate_models_for_crop(\n",
        "    crop: str,\n",
        "    panel: pd.DataFrame,\n",
        "    yield_col: str,\n",
        "    feature_cols: List[str],\n",
        "    network_feature_cols: List[str],\n",
        ") -> Tuple[List[Dict], Dict]:\n",
        "    \"\"\"\n",
        "    IMPROVED: Returns both records and feature importance info\n",
        "    \"\"\"\n",
        "    records = []\n",
        "    feature_importance_data = {}\n",
        "\n",
        "    mask_valid = panel[yield_col].notna() & (panel[yield_col] > 0)\n",
        "    panel_valid = panel.loc[mask_valid].copy()\n",
        "\n",
        "    years = panel_valid[\"Year\"].values\n",
        "    folds = time_series_folds(years, n_folds=N_FOLDS)\n",
        "    if not folds:\n",
        "        warnings.warn(f\"No valid folds for crop {crop}; skipping.\")\n",
        "        return records, feature_importance_data\n",
        "\n",
        "    non_network_feature_cols = [c for c in feature_cols if c not in network_feature_cols]\n",
        "    if not non_network_feature_cols:\n",
        "        non_network_feature_cols = feature_cols\n",
        "        network_feature_cols = []\n",
        "\n",
        "    fold_id = 0\n",
        "    all_importances_gb_no_net = []\n",
        "    all_importances_gb_with_net = []\n",
        "\n",
        "    for train_years, test_years in folds:\n",
        "        fold_id += 1\n",
        "        train_mask = panel_valid[\"Year\"].isin(train_years)\n",
        "        test_mask = panel_valid[\"Year\"].isin(test_years)\n",
        "\n",
        "        train_df = panel_valid.loc[train_mask]\n",
        "        test_df = panel_valid.loc[test_mask]\n",
        "\n",
        "        if len(train_df) == 0 or len(test_df) == 0:\n",
        "            continue\n",
        "\n",
        "        y_train = train_df[yield_col].values\n",
        "        y_test = test_df[yield_col].values\n",
        "\n",
        "        lag_col = f\"{crop}_lag1\"\n",
        "        roll3_col = f\"{crop}_roll3\"\n",
        "\n",
        "        # Baseline 1: Naive\n",
        "        if lag_col in test_df.columns:\n",
        "            y_pred_naive = test_df[lag_col].values.astype(float)\n",
        "            mean_train = y_train.mean()\n",
        "            y_pred_naive = np.where(np.isnan(y_pred_naive), mean_train, y_pred_naive)\n",
        "        else:\n",
        "            y_pred_naive = np.full_like(y_test, y_train.mean(), dtype=float)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred_naive)\n",
        "        rmse = mean_squared_error(y_test, y_pred_naive) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred_naive)\n",
        "        medae = median_ae(y_test, y_pred_naive)\n",
        "        r2 = r2_score(y_test, y_pred_naive)\n",
        "\n",
        "        safe_print(f\"{crop} | Naive | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"Naive\", \"FeatureSet\": \"no_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # Baseline 2: RollingMean3\n",
        "        if roll3_col in test_df.columns:\n",
        "            y_pred_roll3 = test_df[roll3_col].values.astype(float)\n",
        "            mean_train = y_train.mean()\n",
        "            y_pred_roll3 = np.where(np.isnan(y_pred_roll3), mean_train, y_pred_roll3)\n",
        "        else:\n",
        "            y_pred_roll3 = np.full_like(y_test, y_train.mean(), dtype=float)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred_roll3)\n",
        "        rmse = mean_squared_error(y_test, y_pred_roll3) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred_roll3)\n",
        "        medae = median_ae(y_test, y_pred_roll3)\n",
        "        r2 = r2_score(y_test, y_pred_roll3)\n",
        "\n",
        "        safe_print(f\"{crop} | RollingMean3 | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"RollingMean3\", \"FeatureSet\": \"no_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # Advanced models: no_network\n",
        "        X_train_no_net = train_df[non_network_feature_cols].fillna(0.0).values\n",
        "        X_test_no_net = test_df[non_network_feature_cols].fillna(0.0).values\n",
        "\n",
        "        # IMPROVED: Robust scaling for Ridge\n",
        "        scaler_no_net = RobustScaler()\n",
        "        X_train_no_net_scaled = scaler_no_net.fit_transform(X_train_no_net)\n",
        "        X_test_no_net_scaled = scaler_no_net.transform(X_test_no_net)\n",
        "\n",
        "        # Ridge no_network\n",
        "        ridge_no_net = create_robust_ridge(alpha=10.0)\n",
        "        ridge_no_net.fit(X_train_no_net_scaled, y_train)\n",
        "        y_pred = ridge_no_net.predict(X_test_no_net_scaled)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        safe_print(f\"{crop} | Ridge | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"Ridge\", \"FeatureSet\": \"no_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # RandomForest no_network\n",
        "        rf_no_net = RandomForestRegressor(\n",
        "            n_estimators=300, max_depth=None, min_samples_leaf=1,\n",
        "            random_state=RANDOM_STATE, n_jobs=-1\n",
        "        )\n",
        "        rf_no_net.fit(X_train_no_net, y_train)\n",
        "        y_pred = rf_no_net.predict(X_test_no_net)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        safe_print(f\"{crop} | RandomForest | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"RandomForest\", \"FeatureSet\": \"no_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # GradientBoosting no_network\n",
        "        gb_no_net = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
        "        gb_no_net.fit(X_train_no_net, y_train)\n",
        "        y_pred = gb_no_net.predict(X_test_no_net)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        safe_print(f\"{crop} | GradientBoosting | no_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"GradientBoosting\", \"FeatureSet\": \"no_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # Store feature importance\n",
        "        all_importances_gb_no_net.append(gb_no_net.feature_importances_)\n",
        "\n",
        "        # Advanced models: with_network\n",
        "        if network_feature_cols:\n",
        "            feature_cols_with_net = non_network_feature_cols + network_feature_cols\n",
        "        else:\n",
        "            feature_cols_with_net = non_network_feature_cols\n",
        "\n",
        "        X_train_with_net = train_df[feature_cols_with_net].fillna(0.0).values\n",
        "        X_test_with_net = test_df[feature_cols_with_net].fillna(0.0).values\n",
        "\n",
        "        # IMPROVED: Robust scaling for Ridge\n",
        "        scaler_with_net = RobustScaler()\n",
        "        X_train_with_net_scaled = scaler_with_net.fit_transform(X_train_with_net)\n",
        "        X_test_with_net_scaled = scaler_with_net.transform(X_test_with_net)\n",
        "\n",
        "        # Ridge with_network\n",
        "        ridge_with_net = create_robust_ridge(alpha=10.0)\n",
        "        ridge_with_net.fit(X_train_with_net_scaled, y_train)\n",
        "        y_pred = ridge_with_net.predict(X_test_with_net_scaled)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        safe_print(f\"{crop} | Ridge | with_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"Ridge\", \"FeatureSet\": \"with_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # RandomForest with_network\n",
        "        rf_with_net = RandomForestRegressor(\n",
        "            n_estimators=300, max_depth=None, min_samples_leaf=1,\n",
        "            random_state=RANDOM_STATE, n_jobs=-1\n",
        "        )\n",
        "        rf_with_net.fit(X_train_with_net, y_train)\n",
        "        y_pred = rf_with_net.predict(X_test_with_net)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        safe_print(f\"{crop} | RandomForest | with_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"RandomForest\", \"FeatureSet\": \"with_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # GradientBoosting with_network\n",
        "        gb_with_net = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
        "        gb_with_net.fit(X_train_with_net, y_train)\n",
        "        y_pred = gb_with_net.predict(X_test_with_net)\n",
        "\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        rmse = mean_squared_error(y_test, y_pred) ** 0.5\n",
        "        mape_val = safe_mape(y_test, y_pred)\n",
        "        medae = median_ae(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        safe_print(f\"{crop} | GradientBoosting | with_network | Fold {fold_id}: \"\n",
        "                   f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape_val:.2f}, MedAE={medae:.2f}, R2={r2:.3f}\")\n",
        "        records.append({\n",
        "            \"Crop\": crop, \"Model\": \"GradientBoosting\", \"FeatureSet\": \"with_network\", \"Fold\": fold_id,\n",
        "            \"MAE\": mae, \"RMSE\": rmse, \"MAPE\": mape_val, \"MedAE\": medae, \"R2\": r2,\n",
        "        })\n",
        "\n",
        "        # Store feature importance\n",
        "        all_importances_gb_with_net.append(gb_with_net.feature_importances_)\n",
        "\n",
        "    # Compute average feature importance across folds\n",
        "    if all_importances_gb_no_net:\n",
        "        avg_imp_no_net = np.mean(all_importances_gb_no_net, axis=0)\n",
        "        feature_importance_data['no_network'] = {\n",
        "            'features': non_network_feature_cols,\n",
        "            'importance': avg_imp_no_net\n",
        "        }\n",
        "\n",
        "    if all_importances_gb_with_net:\n",
        "        avg_imp_with_net = np.mean(all_importances_gb_with_net, axis=0)\n",
        "        feature_importance_data['with_network'] = {\n",
        "            'features': feature_cols_with_net,\n",
        "            'importance': avg_imp_with_net\n",
        "        }\n",
        "\n",
        "    return records, feature_importance_data\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# STATISTICAL SIGNIFICANCE TESTING\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def perform_statistical_tests(per_fold_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    IMPROVED: Test if GradientBoosting with_network significantly outperforms\n",
        "    GradientBoosting no_network and baselines using paired t-tests.\n",
        "    \"\"\"\n",
        "    safe_print(\"\\n===== STATISTICAL SIGNIFICANCE TESTS =====\")\n",
        "    test_results = []\n",
        "\n",
        "    for crop in CROPS:\n",
        "        crop_data = per_fold_df[per_fold_df[\"Crop\"] == crop]\n",
        "\n",
        "        # Get GradientBoosting scores\n",
        "        gb_with_net = crop_data[\n",
        "            (crop_data[\"Model\"] == \"GradientBoosting\") &\n",
        "            (crop_data[\"FeatureSet\"] == \"with_network\")\n",
        "        ][\"MAE\"].values\n",
        "\n",
        "        gb_no_net = crop_data[\n",
        "            (crop_data[\"Model\"] == \"GradientBoosting\") &\n",
        "            (crop_data[\"FeatureSet\"] == \"no_network\")\n",
        "        ][\"MAE\"].values\n",
        "\n",
        "        naive = crop_data[crop_data[\"Model\"] == \"Naive\"][\"MAE\"].values\n",
        "        rolling = crop_data[crop_data[\"Model\"] == \"RollingMean3\"][\"MAE\"].values\n",
        "\n",
        "        if len(gb_with_net) > 0 and len(gb_no_net) > 0 and len(gb_with_net) == len(gb_no_net):\n",
        "            # Test: GB with_network vs GB no_network\n",
        "            t_stat, p_val = stats.ttest_rel(gb_with_net, gb_no_net)\n",
        "            improvement = ((gb_no_net.mean() - gb_with_net.mean()) / gb_no_net.mean()) * 100\n",
        "\n",
        "            test_results.append({\n",
        "                \"Crop\": crop,\n",
        "                \"Comparison\": \"GB_with_net vs GB_no_net\",\n",
        "                \"Mean_MAE_1\": gb_with_net.mean(),\n",
        "                \"Mean_MAE_2\": gb_no_net.mean(),\n",
        "                \"Improvement_%\": improvement,\n",
        "                \"t_statistic\": t_stat,\n",
        "                \"p_value\": p_val,\n",
        "                \"Significant_05\": \"Yes\" if p_val < 0.05 else \"No\"\n",
        "            })\n",
        "\n",
        "            safe_print(f\"{crop}: GB with_network vs no_network: \"\n",
        "                      f\"Improvement={improvement:.2f}%, p={p_val:.4f}\")\n",
        "\n",
        "        if len(gb_with_net) > 0 and len(naive) > 0 and len(gb_with_net) == len(naive):\n",
        "            # Test: GB with_network vs Naive\n",
        "            t_stat, p_val = stats.ttest_rel(gb_with_net, naive)\n",
        "            improvement = ((naive.mean() - gb_with_net.mean()) / naive.mean()) * 100\n",
        "\n",
        "            test_results.append({\n",
        "                \"Crop\": crop,\n",
        "                \"Comparison\": \"GB_with_net vs Naive\",\n",
        "                \"Mean_MAE_1\": gb_with_net.mean(),\n",
        "                \"Mean_MAE_2\": naive.mean(),\n",
        "                \"Improvement_%\": improvement,\n",
        "                \"t_statistic\": t_stat,\n",
        "                \"p_value\": p_val,\n",
        "                \"Significant_05\": \"Yes\" if p_val < 0.05 else \"No\"\n",
        "            })\n",
        "\n",
        "            safe_print(f\"{crop}: GB with_network vs Naive: \"\n",
        "                      f\"Improvement={improvement:.2f}%, p={p_val:.4f}\")\n",
        "\n",
        "    safe_print()\n",
        "    return pd.DataFrame(test_results)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# TEMPORAL STABILITY ANALYSIS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def analyze_temporal_stability(\n",
        "    per_fold_df: pd.DataFrame,\n",
        "    panels_by_crop: Dict\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    IMPROVED: Analyze how model performance varies over time\n",
        "    to detect potential concept drift or temporal instability.\n",
        "    \"\"\"\n",
        "    safe_print(\"\\n===== TEMPORAL STABILITY ANALYSIS =====\")\n",
        "    stability_results = []\n",
        "\n",
        "    for crop in CROPS:\n",
        "        if crop not in panels_by_crop:\n",
        "            continue\n",
        "\n",
        "        panel = panels_by_crop[crop][\"panel\"]\n",
        "        yield_col = panels_by_crop[crop][\"yield_col\"]\n",
        "\n",
        "        # Get per-fold results\n",
        "        crop_folds = per_fold_df[\n",
        "            (per_fold_df[\"Crop\"] == crop) &\n",
        "            (per_fold_df[\"Model\"] == \"GradientBoosting\") &\n",
        "            (per_fold_df[\"FeatureSet\"] == \"with_network\")\n",
        "        ]\n",
        "\n",
        "        if len(crop_folds) == 0:\n",
        "            continue\n",
        "\n",
        "        # Check if performance degrades over folds (time)\n",
        "        mae_by_fold = crop_folds.sort_values(\"Fold\")[\"MAE\"].values\n",
        "        r2_by_fold = crop_folds.sort_values(\"Fold\")[\"R2\"].values\n",
        "\n",
        "        if len(mae_by_fold) >= 2:\n",
        "            # Compute trend (positive slope = degrading performance)\n",
        "            fold_nums = np.arange(len(mae_by_fold))\n",
        "            mae_slope, mae_intercept, mae_r, _, _ = stats.linregress(fold_nums, mae_by_fold)\n",
        "            r2_slope, r2_intercept, r2_r, _, _ = stats.linregress(fold_nums, r2_by_fold)\n",
        "\n",
        "            stability_results.append({\n",
        "                \"Crop\": crop,\n",
        "                \"MAE_Fold1\": mae_by_fold[0],\n",
        "                \"MAE_Fold_Last\": mae_by_fold[-1],\n",
        "                \"MAE_Slope\": mae_slope,\n",
        "                \"MAE_Trend_R2\": mae_r**2,\n",
        "                \"R2_Fold1\": r2_by_fold[0],\n",
        "                \"R2_Fold_Last\": r2_by_fold[-1],\n",
        "                \"R2_Slope\": r2_slope,\n",
        "                \"Performance_Stable\": \"Yes\" if abs(mae_slope) < 10 else \"No\"\n",
        "            })\n",
        "\n",
        "            safe_print(f\"{crop}: MAE slope={mae_slope:.2f} (trend R={mae_r**2:.3f}), \"\n",
        "                      f\"R slope={r2_slope:.4f}\")\n",
        "\n",
        "    safe_print()\n",
        "    return pd.DataFrame(stability_results)\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# FEATURE IMPORTANCE ANALYSIS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def analyze_feature_importance(\n",
        "    feature_importance_by_crop: Dict,\n",
        "    output_path: str\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    IMPROVED: Comprehensive feature importance analysis with network contribution.\n",
        "    \"\"\"\n",
        "    safe_print(\"\\n===== FEATURE IMPORTANCE ANALYSIS =====\")\n",
        "    all_importance_records = []\n",
        "\n",
        "    for crop, imp_data in feature_importance_by_crop.items():\n",
        "        for feature_set in [\"no_network\", \"with_network\"]:\n",
        "            if feature_set not in imp_data:\n",
        "                continue\n",
        "\n",
        "            features = imp_data[feature_set]['features']\n",
        "            importances = imp_data[feature_set]['importance']\n",
        "\n",
        "            # Sort by importance\n",
        "            sorted_idx = np.argsort(importances)[::-1]\n",
        "\n",
        "            for rank, idx in enumerate(sorted_idx, 1):\n",
        "                is_network = any(x in features[idx].lower()\n",
        "                                for x in ['net_', 'network', 'centrality'])\n",
        "                is_temporal = any(x in features[idx].lower()\n",
        "                                 for x in ['lag', 'roll', 'yoy'])\n",
        "                is_diversity = any(x in features[idx].lower()\n",
        "                                  for x in ['diversity', 'num_active'])\n",
        "\n",
        "                all_importance_records.append({\n",
        "                    \"Crop\": crop,\n",
        "                    \"FeatureSet\": feature_set,\n",
        "                    \"Feature\": features[idx],\n",
        "                    \"Importance\": importances[idx],\n",
        "                    \"Rank\": rank,\n",
        "                    \"IsNetwork\": is_network,\n",
        "                    \"IsTemporal\": is_temporal,\n",
        "                    \"IsDiversity\": is_diversity\n",
        "                })\n",
        "\n",
        "        # Calculate network contribution\n",
        "        if \"with_network\" in imp_data:\n",
        "            features = imp_data[\"with_network\"]['features']\n",
        "            importances = imp_data[\"with_network\"]['importance']\n",
        "\n",
        "            network_mask = [any(x in f.lower() for x in ['net_', 'network', 'centrality'])\n",
        "                           for f in features]\n",
        "            network_importance = importances[network_mask].sum() if any(network_mask) else 0.0\n",
        "            total_importance = importances.sum()\n",
        "            network_pct = (network_importance / total_importance * 100) if total_importance > 0 else 0.0\n",
        "\n",
        "            safe_print(f\"{crop}: Network features contribute {network_pct:.1f}% of total importance\")\n",
        "\n",
        "    importance_df = pd.DataFrame(all_importance_records)\n",
        "    importance_df.to_csv(output_path, index=False)\n",
        "    safe_print(f\"\\nSaved feature importance to: {output_path}\\n\")\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# MODEL SELECTION + SUMMARY\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def summarise_performance(per_fold_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    agg = (\n",
        "        per_fold_df\n",
        "        .groupby([\"Crop\", \"Model\", \"FeatureSet\"])\n",
        "        .agg(\n",
        "            MAE_mean=(\"MAE\", \"mean\"),\n",
        "            MAE_std=(\"MAE\", \"std\"),\n",
        "            RMSE_mean=(\"RMSE\", \"mean\"),\n",
        "            RMSE_std=(\"RMSE\", \"std\"),\n",
        "            MAPE_mean=(\"MAPE\", \"mean\"),\n",
        "            MAPE_std=(\"MAPE\", \"std\"),\n",
        "            MedAE_mean=(\"MedAE\", \"mean\"),\n",
        "            MedAE_std=(\"MedAE\", \"std\"),\n",
        "            R2_mean=(\"R2\", \"mean\"),\n",
        "            R2_std=(\"R2\", \"std\"),\n",
        "        )\n",
        "        .reset_index()\n",
        "    )\n",
        "    return agg\n",
        "\n",
        "\n",
        "def select_best_advanced_models(perf_summary: pd.DataFrame) -> pd.DataFrame:\n",
        "    advanced_models = [\"Ridge\", \"RandomForest\", \"GradientBoosting\"]\n",
        "    best_rows = []\n",
        "\n",
        "    for crop in sorted(perf_summary[\"Crop\"].unique()):\n",
        "        sub = perf_summary[\n",
        "            (perf_summary[\"Crop\"] == crop)\n",
        "            & (perf_summary[\"Model\"].isin(advanced_models))\n",
        "        ]\n",
        "        if sub.empty:\n",
        "            continue\n",
        "\n",
        "        sub_with_net = sub[sub[\"FeatureSet\"] == \"with_network\"]\n",
        "        if not sub_with_net.empty:\n",
        "            cand = sub_with_net\n",
        "        else:\n",
        "            cand = sub\n",
        "\n",
        "        min_mae = cand[\"MAE_mean\"].min()\n",
        "        mae_tol = min_mae * 1.01\n",
        "        cand = cand[cand[\"MAE_mean\"] <= mae_tol]\n",
        "\n",
        "        best_idx = cand[\"R2_mean\"].idxmax()\n",
        "        best_row = cand.loc[best_idx].copy()\n",
        "        best_rows.append(best_row)\n",
        "\n",
        "    best_df = pd.DataFrame(best_rows).reset_index(drop=True)\n",
        "    if not best_df.empty:\n",
        "        best_df[\"ModelLabel\"] = [\n",
        "            f\"Proposed_{m}_{fs}\"\n",
        "            for m, fs in zip(best_df[\"Model\"], best_df[\"FeatureSet\"])\n",
        "        ]\n",
        "    return best_df\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# ENHANCED DIAGNOSTIC PLOTS\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def save_enhanced_diagnostic_plots(\n",
        "    crop: str,\n",
        "    model_name: str,\n",
        "    feature_set: str,\n",
        "    y_true: np.ndarray,\n",
        "    y_pred: np.ndarray,\n",
        "    output_dir: str\n",
        "):\n",
        "    \"\"\"\n",
        "    IMPROVED: Enhanced diagnostic plots with publication-quality visualizations\n",
        "    \"\"\"\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = mean_squared_error(y_true, y_pred) ** 0.5\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    residuals = y_true - y_pred\n",
        "\n",
        "    # Create 2x2 subplot figure\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "    # 1. Predicted vs Observed\n",
        "    ax = axes[0, 0]\n",
        "    ax.scatter(y_true, y_pred, alpha=0.4, s=20, edgecolors='none')\n",
        "    lims = [min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())]\n",
        "    ax.plot(lims, lims, 'r--', linewidth=2, label='Perfect prediction')\n",
        "    ax.set_xlabel('Observed Yield (kg/ha)', fontsize=11)\n",
        "    ax.set_ylabel('Predicted Yield (kg/ha)', fontsize=11)\n",
        "    ax.set_title(f'{crop} - Predicted vs Observed\\nMAE={mae:.1f}, RMSE={rmse:.1f}, R={r2:.3f}',\n",
        "                 fontsize=12)\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    # 2. Residuals vs Predicted\n",
        "    ax = axes[0, 1]\n",
        "    ax.scatter(y_pred, residuals, alpha=0.4, s=20, edgecolors='none')\n",
        "    ax.axhline(0, color='r', linestyle='--', linewidth=2)\n",
        "    ax.set_xlabel('Predicted Yield (kg/ha)', fontsize=11)\n",
        "    ax.set_ylabel('Residual (kg/ha)', fontsize=11)\n",
        "    ax.set_title('Residual Plot', fontsize=12)\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    # 3. Residual Distribution\n",
        "    ax = axes[1, 0]\n",
        "    ax.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
        "    ax.axvline(0, color='r', linestyle='--', linewidth=2)\n",
        "    ax.set_xlabel('Residual (kg/ha)', fontsize=11)\n",
        "    ax.set_ylabel('Frequency', fontsize=11)\n",
        "    ax.set_title(f'Residual Distribution\\nMean={residuals.mean():.1f}, Std={residuals.std():.1f}',\n",
        "                 fontsize=12)\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    # 4. Q-Q Plot\n",
        "    ax = axes[1, 1]\n",
        "    stats.probplot(residuals, dist=\"norm\", plot=ax)\n",
        "    ax.set_title('Q-Q Plot (Normality Check)', fontsize=12)\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plot_path = os.path.join(\n",
        "        output_dir,\n",
        "        f\"{crop}_{model_name}_{feature_set}_comprehensive_diagnostics.pdf\"\n",
        "    )\n",
        "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    safe_print(f\"Saved enhanced diagnostic plots for {crop} ({model_name}, {feature_set}) to {output_dir}.\")\n",
        "\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# MAIN PIPELINE\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "def main():\n",
        "    safe_print(\"=\"*70)\n",
        "    safe_print(\"ENHANCED AGRICULTURAL YIELD PREDICTION PIPELINE\")\n",
        "    safe_print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    df, source_type = load_data()\n",
        "    safe_print(f\"Data source type: {source_type}\")\n",
        "    basic_eda(df)\n",
        "\n",
        "    df = clean_yields(df)\n",
        "    df = compute_diversification_features(df)\n",
        "\n",
        "    dist_graph, dist_feats = build_district_network(df)\n",
        "    crop_graph = build_crop_cooccurrence_network(df)\n",
        "\n",
        "    if not dist_feats.empty:\n",
        "        df = df.merge(dist_feats, on=\"Dist Code\", how=\"left\")\n",
        "\n",
        "    df.to_csv(CLEANED_CSV_PATH, index=False)\n",
        "    safe_print(f\"Saved cleaned dataset with features to: {CLEANED_CSV_PATH}\\n\")\n",
        "\n",
        "    all_records = []\n",
        "    panels_by_crop: Dict[str, Dict] = {}\n",
        "    feature_importance_by_crop: Dict[str, Dict] = {}\n",
        "\n",
        "    for crop in CROPS:\n",
        "        safe_print(f\"\\n{'='*70}\")\n",
        "        safe_print(f\"PROCESSING {crop}\")\n",
        "        safe_print(f\"{'='*70}\")\n",
        "\n",
        "        panel, y_col, feat_cols, net_cols = prepare_panel_for_crop(df, crop)\n",
        "\n",
        "        panel_path = f\"{SUPERVISED_PANEL_PREFIX}{crop.lower()}.csv\"\n",
        "        panel.to_csv(panel_path, index=False)\n",
        "        safe_print(f\"Saved supervised panel for {crop} to: {panel_path}\\n\")\n",
        "\n",
        "        panels_by_crop[crop] = {\n",
        "            \"panel\": panel,\n",
        "            \"yield_col\": y_col,\n",
        "            \"feature_cols\": feat_cols,\n",
        "            \"network_feature_cols\": net_cols,\n",
        "        }\n",
        "\n",
        "        crop_records, feat_imp = evaluate_models_for_crop(\n",
        "            crop=crop,\n",
        "            panel=panel,\n",
        "            yield_col=y_col,\n",
        "            feature_cols=feat_cols,\n",
        "            network_feature_cols=net_cols,\n",
        "        )\n",
        "        all_records.extend(crop_records)\n",
        "        feature_importance_by_crop[crop] = feat_imp\n",
        "\n",
        "    per_fold_df = pd.DataFrame(all_records)\n",
        "    per_fold_df.to_csv(MODEL_PER_FOLD_CSV, index=False)\n",
        "    safe_print(f\"\\nSaved per-fold model results to: {MODEL_PER_FOLD_CSV}\")\n",
        "\n",
        "    perf_summary = summarise_performance(per_fold_df)\n",
        "    perf_summary.to_csv(MODEL_PERF_SUMMARY_CSV, index=False)\n",
        "    safe_print(f\"Saved model performance summary to: {MODEL_PERF_SUMMARY_CSV}\\n\")\n",
        "\n",
        "    # NEW: Statistical significance tests\n",
        "    stat_tests = perform_statistical_tests(per_fold_df)\n",
        "    stat_tests.to_csv(STATISTICAL_TESTS_CSV, index=False)\n",
        "    safe_print(f\"Saved statistical tests to: {STATISTICAL_TESTS_CSV}\\n\")\n",
        "\n",
        "    # NEW: Temporal stability analysis\n",
        "    stability_analysis = analyze_temporal_stability(per_fold_df, panels_by_crop)\n",
        "    stability_analysis.to_csv(TEMPORAL_STABILITY_CSV, index=False)\n",
        "    safe_print(f\"Saved temporal stability analysis to: {TEMPORAL_STABILITY_CSV}\\n\")\n",
        "\n",
        "    # NEW: Feature importance analysis\n",
        "    analyze_feature_importance(feature_importance_by_crop, FEATURE_IMPORTANCE_CSV)\n",
        "\n",
        "    for crop in CROPS:\n",
        "        for fs in [\"no_network\", \"with_network\"]:\n",
        "            sub = perf_summary[(perf_summary[\"Crop\"] == crop) & (perf_summary[\"FeatureSet\"] == fs)]\n",
        "            if sub.empty:\n",
        "                continue\n",
        "            safe_print(f\"\\nPerformance summary for {crop} ({fs}):\")\n",
        "            safe_print(sub.sort_values(\"MAE_mean\").to_string(index=False))\n",
        "\n",
        "    best_df = select_best_advanced_models(perf_summary)\n",
        "    best_df.to_csv(BEST_MODELS_CSV, index=False)\n",
        "\n",
        "    safe_print(\"\\n\" + \"=\"*70)\n",
        "    safe_print(\"FINAL SUMMARY (BEST ADVANCED MODELS)\")\n",
        "    safe_print(\"=\"*70)\n",
        "    for row in best_df.itertuples(index=False):\n",
        "        safe_print(\n",
        "            f\"  {row.Crop}: {row.Model} ({row.FeatureSet}) | \"\n",
        "            f\"MAE={row.MAE_mean:.2f} ({row.MAE_std:.2f}), R={row.R2_mean:.3f} ({row.R2_std:.3f})\"\n",
        "        )\n",
        "\n",
        "    # Generate enhanced diagnostic plots\n",
        "    safe_print(\"\\n\" + \"=\"*70)\n",
        "    safe_print(\"GENERATING ENHANCED DIAGNOSTIC PLOTS\")\n",
        "    safe_print(\"=\"*70)\n",
        "\n",
        "    for row in best_df.itertuples(index=False):\n",
        "        crop = row.Crop\n",
        "        meta = panels_by_crop[crop]\n",
        "        panel = meta[\"panel\"]\n",
        "        y_col = meta[\"yield_col\"]\n",
        "        feat_cols = meta[\"feature_cols\"]\n",
        "        net_cols = meta[\"network_feature_cols\"]\n",
        "\n",
        "        # Fit on full data for diagnostics\n",
        "        mask_valid = panel[y_col].notna() & (panel[y_col] > 0)\n",
        "        panel_valid = panel.loc[mask_valid].copy()\n",
        "\n",
        "        non_net_cols = [c for c in feat_cols if c not in net_cols]\n",
        "        if row.FeatureSet == \"with_network\" and net_cols:\n",
        "            use_cols = non_net_cols + net_cols\n",
        "        else:\n",
        "            use_cols = non_net_cols\n",
        "\n",
        "        X = panel_valid[use_cols].fillna(0.0).values\n",
        "        y = panel_valid[y_col].values\n",
        "\n",
        "        if row.Model == \"GradientBoosting\":\n",
        "            model = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
        "        elif row.Model == \"RandomForest\":\n",
        "            model = RandomForestRegressor(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1)\n",
        "        elif row.Model == \"Ridge\":\n",
        "            scaler = RobustScaler()\n",
        "            X = scaler.fit_transform(X)\n",
        "            model = create_robust_ridge(alpha=10.0)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        model.fit(X, y)\n",
        "        y_pred = model.predict(X)\n",
        "\n",
        "        save_enhanced_diagnostic_plots(\n",
        "            crop=crop,\n",
        "            model_name=row.Model,\n",
        "            feature_set=row.FeatureSet,\n",
        "            y_true=y,\n",
        "            y_pred=y_pred,\n",
        "            output_dir=OUTPUT_DIR\n",
        "        )\n",
        "\n",
        "    safe_print(\"\\n\" + \"=\"*70)\n",
        "    safe_print(\"PIPELINE COMPLETE\")\n",
        "    safe_print(\"=\"*70)\n",
        "    safe_print(f\"Rows after cleaning: {len(df)}\")\n",
        "    if \"Year\" in df.columns:\n",
        "        safe_print(f\"Years: {int(df['Year'].min())} - {int(df['Year'].max())}\")\n",
        "    safe_print(f\"Districts: {df['Dist Code'].nunique() if 'Dist Code' in df.columns else 'N/A'}\")\n",
        "    safe_print(f\"Crops modeled: {CROPS}\")\n",
        "    safe_print(f\"\\nKey outputs:\")\n",
        "    safe_print(f\"  - Cleaned dataset: {CLEANED_CSV_PATH}\")\n",
        "    safe_print(f\"  - Performance summary: {MODEL_PERF_SUMMARY_CSV}\")\n",
        "    safe_print(f\"  - Statistical tests: {STATISTICAL_TESTS_CSV}\")\n",
        "    safe_print(f\"  - Temporal stability: {TEMPORAL_STABILITY_CSV}\")\n",
        "    safe_print(f\"  - Feature importance: {FEATURE_IMPORTANCE_CSV}\")\n",
        "    safe_print(f\"  - Best models: {BEST_MODELS_CSV}\")\n",
        "    safe_print(f\"  - Diagnostic plots: {OUTPUT_DIR}/*.pdf\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}